{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adc257/info4940-sitcom/blob/main/sitcom_T5_(with_nContext).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "id": "view-in-github"
    },
    {
      "cell_type": "markdown",
      "id": "37361edd-f18b-455e-a306-289e42a489e4",
      "metadata": {
        "id": "37361edd-f18b-455e-a306-289e42a489e4"
      },
      "source": [
        "# The Big Bang Theory T5 nContext"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e29354-f5cd-4a30-8cbe-abc0f4c50ed3",
      "metadata": {
        "tags": [],
        "id": "91e29354-f5cd-4a30-8cbe-abc0f4c50ed3"
      },
      "source": [
        "# Imports:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LSbyj3J0ugVj"
      },
      "id": "LSbyj3J0ugVj",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/adc257/info4940-sitcom.git"
      ],
      "metadata": {
        "id": "BrUbqiIntXth",
        "outputId": "45ff06d2-8e1e-428f-fa45-8721bb1630be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BrUbqiIntXth",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'info4940-sitcom' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENEIQ-sCPJfb",
        "outputId": "a2dd9b4d-f79a-4770-ac59-c8bbf3cad612"
      },
      "id": "ENEIQ-sCPJfb",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m venv 3350\n",
        "!source 3350/bin/activate"
      ],
      "metadata": {
        "id": "jKPk26plSJNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cec920-9a47-44a0-def7-001aaa62c973"
      },
      "id": "jKPk26plSJNy",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/local/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/venv/__main__.py\", line 6, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.10/venv/__init__.py\", line 516, in main\n",
            "    builder.create(d)\n",
            "  File \"/usr/local/lib/python3.10/venv/__init__.py\", line 75, in create\n",
            "    self._setup_pip(context)\n",
            "  File \"/usr/local/lib/python3.10/venv/__init__.py\", line 328, in _setup_pip\n",
            "    self._call_new_python(context, '-m', 'ensurepip', '--upgrade',\n",
            "  File \"/usr/local/lib/python3.10/venv/__init__.py\", line 324, in _call_new_python\n",
            "    subprocess.check_output(args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/subprocess.py\", line 421, in check_output\n",
            "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
            "  File \"/usr/local/lib/python3.10/subprocess.py\", line 505, in run\n",
            "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/subprocess.py\", line 1141, in communicate\n",
            "    stdout = self.stdout.read()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "# !pip install transformers[torch]\n",
        "# !pip install accelerate -U\n",
        "# !pip install accelerate>=0.21.0\n",
        "# !pip install --upgrade pip"
      ],
      "metadata": {
        "id": "-wa9rUhV4HWM"
      },
      "id": "-wa9rUhV4HWM",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip uninstall transformers accelerate\n",
        "# pip install transformers[torch]\n",
        "# !pip install --upgrade setuptools"
      ],
      "metadata": {
        "id": "zftPtQ7PNNeT"
      },
      "id": "zftPtQ7PNNeT",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "f5c043b3-5369-4a0d-a3ea-ccb6b5f74949",
      "metadata": {
        "tags": [],
        "id": "f5c043b3-5369-4a0d-a3ea-ccb6b5f74949",
        "ExecuteTime": {
          "end_time": "2024-03-18T17:36:54.219587Z",
          "start_time": "2024-03-18T17:36:54.211176Z"
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta, time\n",
        "from pathlib import Path\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import os\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
      ],
      "metadata": {
        "id": "HO9kUogg4F8-",
        "ExecuteTime": {
          "end_time": "2024-03-18T17:36:57.363182Z",
          "start_time": "2024-03-18T17:36:57.339429Z"
        }
      },
      "id": "HO9kUogg4F8-",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formatting the Dialogue:"
      ],
      "metadata": {
        "id": "MryDd8sEnEZl"
      },
      "id": "MryDd8sEnEZl"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e533b5d1",
      "metadata": {
        "id": "e533b5d1",
        "ExecuteTime": {
          "end_time": "2024-03-18T17:36:58.611344Z",
          "start_time": "2024-03-18T17:36:58.587028Z"
        }
      },
      "outputs": [],
      "source": [
        "def list_files(start_path):\n",
        "    file_paths = []\n",
        "    for root, dirs, files in os.walk(start_path):\n",
        "        for file in files:\n",
        "            file_paths.append(os.path.join(root, file))\n",
        "\n",
        "    file_paths.sort()\n",
        "    return file_paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformContextTarget(context, target):\n",
        "  separator = \"\\n\"\n",
        "  quotation_token = '\"'\n",
        "\n",
        "  formatted_input = \"\"\n",
        "\n",
        "  current_scene = context[0]['Scene']\n",
        "\n",
        "  formatted_input += \"Use the following as context:\" + separator*2\n",
        "  formatted_input += \"The scene is: \" + current_scene + separator\n",
        "\n",
        "  for entry in context:\n",
        "    if current_scene != entry['Scene']:\n",
        "      current_scene = entry[\"Scene\"]\n",
        "      formatted_input += \"The scene changes to: \" + current_scene + separator\n",
        "\n",
        "    recipients = entry['Recipients']\n",
        "    recipients_str = \"\"\n",
        "    if len(recipients) == 0:\n",
        "      recipients_str += \"to themselves\"\n",
        "    elif len(recipients) == 1:\n",
        "      recipients_str += recipients[0]\n",
        "    else:\n",
        "      recipients_str += \", \".join(recipients[:-1]) + \" and \" + recipients[-1]\n",
        "\n",
        "    formatted_input += f\"{entry['Speaker']} says {quotation_token}{entry['Dialogue']}{quotation_token} to {recipients_str}.\"\n",
        "    formatted_input += separator\n",
        "\n",
        "\n",
        "  formatted_input += separator + \"-\" *20 + separator*2\n",
        "\n",
        "  formatted_input += \"Using the previous dialogues above as context, classify the following dialogue below as humorous or not humorous:\" + separator*2\n",
        "\n",
        "\n",
        "  entry = target\n",
        "  if entry['Scene'] != current_scene:\n",
        "    current_scene = entry[\"Scene\"]\n",
        "    formatted_input += \"The scene changes to: \"\n",
        "  else:\n",
        "    formatted_input += \"The Scene is still: \"\n",
        "\n",
        "  formatted_input += current_scene + separator\n",
        "\n",
        "\n",
        "  recipients = entry['Recipients']\n",
        "  recipients_str = \"\"\n",
        "  if len(recipients) == 0:\n",
        "    recipients_str += \"to themselves\"\n",
        "  elif len(recipients) == 1:\n",
        "    recipients_str += recipients[0]\n",
        "  else:\n",
        "    recipients_str += \", \".join(recipients[:-1]) + \" and \" + recipients[-1]\n",
        "\n",
        "  formatted_input += f\"{entry['Speaker']} says {quotation_token}{entry['Dialogue']}{quotation_token} to {recipients_str}.\"\n",
        "  formatted_input += separator*2 + \"Classify: [humorous] or [not humorous].\"\n",
        "\n",
        "  return formatted_input\n",
        "\n",
        "# context = [data[0], data[1], data[2]]\n",
        "# target = data[3]\n",
        "# transformContextTarget(context, target)"
      ],
      "metadata": {
        "id": "qejriLpzL9zV"
      },
      "id": "qejriLpzL9zV",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/info4940-sitcom/cleaned-data/S1\"\n",
        "nSentenceContext = 3\n",
        "\n",
        "episodePath = list_files(filePath)[0]\n",
        "\n",
        "with open(episodePath, 'r') as file:\n",
        "  data = json.load(file)\n",
        "  data = [info for (_, info) in data.items()]\n",
        "\n",
        "print(f\"Example raw entry:\")\n",
        "display(data[3])\n",
        "\n",
        "print(\"\\n\\nExample formatted entry (3context):\\n\")\n",
        "print(transformContextTarget(data[:3], data[3]))\n",
        "\n",
        "print(f'Actual: {(\"isHumor\" in data[3])}')"
      ],
      "metadata": {
        "id": "jgfO1ADv6sx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "1fe89820-fa66-4744-99bf-12179a1e677b"
      },
      "id": "jgfO1ADv6sx8",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example raw entry:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'EpisodeID': 'The Big Bang_S0101',\n",
              " 'Scene': 'A corridor at a sperm bank.',\n",
              " 'Recipients': ['Sheldon', 'Receptionist'],\n",
              " 'Speaker': 'Leonard',\n",
              " 'Dialogue': 'Excuse me.',\n",
              " 'Dialogue Start Time': '00:00:23:140000',\n",
              " 'Dialogue End Time': '00:00:25:060000'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Example formatted entry (3context):\n",
            "\n",
            "Use the following as context:\n",
            "\n",
            "The scene is: A corridor at a sperm bank.\n",
            "Sheldon says \"So if a photon is directed through a plane with two slits in it and either slit is observed, it will not go through both slits. If it's unobserved, it will. However, if it's observed after it's left the plane but before it hits its target, it won't have gone through both slits.\" to Leonard.\n",
            "Leonard says \"Agreed. What's your point?\" to Sheldon.\n",
            "Sheldon says \"There's no point, I just think it's a good idea for a T-shirt.\" to Leonard.\n",
            "\n",
            "--------------------\n",
            "\n",
            "Using the previous dialogues above as context, classify the following dialogue below as humorous or not humorous:\n",
            "\n",
            "The Scene is still: A corridor at a sperm bank.\n",
            "Leonard says \"Excuse me.\" to Sheldon and Receptionist.\n",
            "\n",
            "Classify: [humorous] or [not humorous].\n",
            "Actual: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split:"
      ],
      "metadata": {
        "id": "IkEDU1FV6vJA"
      },
      "id": "IkEDU1FV6vJA"
    },
    {
      "cell_type": "code",
      "source": [
        "def generateDialogueWithContext(filePath, nSentenceContext):\n",
        "  formatted_inputs = []\n",
        "  labels = []\n",
        "\n",
        "  for episodePath in list_files(filePath):\n",
        "\n",
        "    with open(episodePath, 'r') as file:\n",
        "      data = json.load(file)\n",
        "      data = [info for (_, info) in data.items()]\n",
        "\n",
        "\n",
        "      i = nSentenceContext\n",
        "      while i < len(data):\n",
        "        context = [data[j] for j in range(i-nSentenceContext, i)]\n",
        "        target = data[i]\n",
        "\n",
        "        formatted_inputs.append(transformContextTarget(context, target))\n",
        "\n",
        "        if \"isHumor\" in target:\n",
        "          labels.append(1)\n",
        "        else:\n",
        "          labels.append(0)\n",
        "\n",
        "        i += 1\n",
        "  return formatted_inputs, labels"
      ],
      "metadata": {
        "id": "QKV3_0Hc6M1L"
      },
      "id": "QKV3_0Hc6M1L",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue_list1, label_list1 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S1', 3)\n",
        "dialogue_list2, label_list2 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S2', 3)\n",
        "dialogue_list3, label_list3 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S3', 3)\n",
        "dialogue_list4, label_list4 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S4', 3)\n",
        "dialogue_list5, label_list5 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S5', 3)"
      ],
      "metadata": {
        "id": "RnvrEKjEGGqY"
      },
      "id": "RnvrEKjEGGqY",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = dialogue_list1 + dialogue_list2 + dialogue_list3 + dialogue_list4\n",
        "test_texts = dialogue_list5\n",
        "train_labels = label_list1 + label_list2 + label_list3 + label_list4\n",
        "test_labels = label_list5"
      ],
      "metadata": {
        "id": "mQDtMqo1Hn2F"
      },
      "id": "mQDtMqo1Hn2F",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5:"
      ],
      "metadata": {
        "id": "xEidNKdmYjQo"
      },
      "id": "xEidNKdmYjQo"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dCxf9t2R08K3"
      },
      "id": "dCxf9t2R08K3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}