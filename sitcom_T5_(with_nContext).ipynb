{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adc257/info4940-sitcom/blob/main/sitcom_T5_(with_nContext).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37361edd-f18b-455e-a306-289e42a489e4",
      "metadata": {
        "id": "37361edd-f18b-455e-a306-289e42a489e4"
      },
      "source": [
        "# The Big Bang Theory Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e29354-f5cd-4a30-8cbe-abc0f4c50ed3",
      "metadata": {
        "tags": [],
        "id": "91e29354-f5cd-4a30-8cbe-abc0f4c50ed3"
      },
      "source": [
        "### Imports:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSbyj3J0ugVj",
        "outputId": "7b1a79a6-786a-4078-87e2-f4e3487583fe"
      },
      "id": "LSbyj3J0ugVj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/adc257/info4940-sitcom.git"
      ],
      "metadata": {
        "id": "BrUbqiIntXth",
        "outputId": "c5f96be0-ccc6-4697-fe66-b1bca6e43e58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BrUbqiIntXth",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'info4940-sitcom'...\n",
            "remote: Enumerating objects: 1082, done.\u001b[K\n",
            "remote: Counting objects: 100% (1082/1082), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 1082 (delta 948), reused 1038 (delta 915), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1082/1082), 14.59 MiB | 12.75 MiB/s, done.\n",
            "Resolving deltas: 100% (948/948), done.\n",
            "Updating files: 100% (922/922), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENEIQ-sCPJfb",
        "outputId": "0808c473-376d-40fa-fe51-ceb73e150b57"
      },
      "id": "ENEIQ-sCPJfb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:19\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m venv 3350\n",
        "!source 3350/bin/activate"
      ],
      "metadata": {
        "id": "jKPk26plSJNy"
      },
      "id": "jKPk26plSJNy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "# !pip install transformers[torch]\n",
        "# !pip install accelerate -U\n",
        "# !pip install accelerate>=0.21.0\n",
        "# !pip install --upgrade pip"
      ],
      "metadata": {
        "id": "-wa9rUhV4HWM"
      },
      "id": "-wa9rUhV4HWM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip uninstall transformers accelerate\n",
        "# pip install transformers[torch]\n",
        "# !pip install --upgrade setuptools"
      ],
      "metadata": {
        "id": "zftPtQ7PNNeT"
      },
      "id": "zftPtQ7PNNeT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f5c043b3-5369-4a0d-a3ea-ccb6b5f74949",
      "metadata": {
        "tags": [],
        "id": "f5c043b3-5369-4a0d-a3ea-ccb6b5f74949",
        "ExecuteTime": {
          "end_time": "2024-03-18T17:36:54.219587Z",
          "start_time": "2024-03-18T17:36:54.211176Z"
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta, time\n",
        "from pathlib import Path\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import os\n",
        "from sklearn.metrics import f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "HO9kUogg4F8-",
        "ExecuteTime": {
          "end_time": "2024-03-18T17:36:57.363182Z",
          "start_time": "2024-03-18T17:36:57.339429Z"
        }
      },
      "id": "HO9kUogg4F8-",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n"
      ],
      "metadata": {
        "id": "kpXUI0JKHT24"
      },
      "id": "kpXUI0JKHT24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEdoB8VkH-cz"
      },
      "id": "iEdoB8VkH-cz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e533b5d1",
      "metadata": {
        "id": "e533b5d1",
        "ExecuteTime": {
          "end_time": "2024-03-18T17:36:58.611344Z",
          "start_time": "2024-03-18T17:36:58.587028Z"
        }
      },
      "outputs": [],
      "source": [
        "def list_files(start_path):\n",
        "    file_paths = []\n",
        "    for root, dirs, files in os.walk(start_path):\n",
        "        for file in files:\n",
        "            file_paths.append(os.path.join(root, file))\n",
        "\n",
        "    file_paths.sort()\n",
        "    return file_paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7GKrT6EBMxPa"
      },
      "id": "7GKrT6EBMxPa",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w3L1oZg7OFRc"
      },
      "id": "w3L1oZg7OFRc",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MB9c9NJnQkyg"
      },
      "id": "MB9c9NJnQkyg",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformContextTarget(context, target):\n",
        "  separator = \"\\n\"\n",
        "  quotation_token = '\"'\n",
        "\n",
        "  formatted_input = \"\"\n",
        "\n",
        "  current_scene = context[0]['Scene']\n",
        "\n",
        "  formatted_input += \"Use the following as context:\" + separator*2\n",
        "  formatted_input += \"The scene is: \" + current_scene + separator\n",
        "\n",
        "  for entry in context:\n",
        "    if current_scene != entry['Scene']:\n",
        "      current_scene = entry[\"Scene\"]\n",
        "      formatted_input += \"The scene changes to: \" + current_scene + separator\n",
        "\n",
        "    recipients = entry['Recipients']\n",
        "    recipients_str = \"\"\n",
        "    if len(recipients) == 0:\n",
        "      recipients_str += \"to themselves\"\n",
        "    elif len(recipients) == 1:\n",
        "      recipients_str += recipients[0]\n",
        "    else:\n",
        "      recipients_str += \", \".join(recipients[:-1]) + \" and \" + recipients[-1]\n",
        "\n",
        "    formatted_input += f\"{entry['Speaker']} says {quotation_token}{entry['Dialogue']}{quotation_token} to {recipients_str}.\"\n",
        "    formatted_input += separator\n",
        "\n",
        "\n",
        "  formatted_input += separator + \"-\" *20 + separator*2\n",
        "\n",
        "  formatted_input += \"Using the previous dialogues above as context, classify the following dialogue below as humorous or not humorous:\" + separator*2\n",
        "\n",
        "\n",
        "  entry = target\n",
        "  if entry['Scene'] != current_scene:\n",
        "    current_scene = entry[\"Scene\"]\n",
        "    formatted_input += \"The scene changes to: \"\n",
        "  else:\n",
        "    formatted_input += \"The Scene is still: \"\n",
        "\n",
        "  formatted_input += current_scene + separator\n",
        "\n",
        "\n",
        "  recipients = entry['Recipients']\n",
        "  recipients_str = \"\"\n",
        "  if len(recipients) == 0:\n",
        "    recipients_str += \"to themselves\"\n",
        "  elif len(recipients) == 1:\n",
        "    recipients_str += recipients[0]\n",
        "  else:\n",
        "    recipients_str += \", \".join(recipients[:-1]) + \" and \" + recipients[-1]\n",
        "\n",
        "  formatted_input += f\"{entry['Speaker']} says {quotation_token}{entry['Dialogue']}{quotation_token} to {recipients_str}.\"\n",
        "  formatted_input += separator*2 + \"Classify: [humorous] or [not humorous].\"\n",
        "\n",
        "  return formatted_input\n",
        "\n",
        "# context = [data[0], data[1], data[2]]\n",
        "# target = data[3]\n",
        "# transformContextTarget(context, target)"
      ],
      "metadata": {
        "id": "qejriLpzL9zV"
      },
      "id": "qejriLpzL9zV",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title # Formatting the input\n",
        "# @markdown ### Example raw entry:\n",
        "print(data[3])\n",
        "# @markdown ### Example formatted entry (3Context):\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "RTcw9mvRftKf",
        "outputId": "68ce96b0-9fcf-4385-d591-dd182f3dc9a1"
      },
      "id": "RTcw9mvRftKf",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-589548acf08b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title # Formatting the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# @markdown ### Example raw entry:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# @markdown ### Example formatted entry (3Context):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = \"/content/info4940-sitcom/cleaned-data/S1\"\n",
        "nSentenceContext = 3\n",
        "\n",
        "episodePath = list_files(filePath)[0]\n",
        "\n",
        "with open(episodePath, 'r') as file:\n",
        "  data = json.load(file)\n",
        "  data = [info for (_, info) in data.items()]\n",
        "\n",
        "print(f\"Example raw entry:\")\n",
        "display(data[3])\n",
        "print(\"\\n\\nExample formatted entry (3context):\\n\")\n",
        "print(transformContextTarget(data[:3], data[3]))\n",
        "\n",
        "print(f'Actual: {(\"isHumor\" in data[3])}')"
      ],
      "metadata": {
        "id": "jgfO1ADv6sx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "e7f9894e-63ae-46cb-8511-f848e07ff57b"
      },
      "id": "jgfO1ADv6sx8",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example raw entry:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'EpisodeID': 'The Big Bang_S0101',\n",
              " 'Scene': 'A corridor at a sperm bank.',\n",
              " 'Recipients': ['Sheldon', 'Receptionist'],\n",
              " 'Speaker': 'Leonard',\n",
              " 'Dialogue': 'Excuse me.',\n",
              " 'Dialogue Start Time': '00:00:23:140000',\n",
              " 'Dialogue End Time': '00:00:25:060000'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Example formatted entry (3context):\n",
            "\n",
            "Use the following as context:\n",
            "\n",
            "The scene is: A corridor at a sperm bank.\n",
            "Sheldon says \"So if a photon is directed through a plane with two slits in it and either slit is observed, it will not go through both slits. If it's unobserved, it will. However, if it's observed after it's left the plane but before it hits its target, it won't have gone through both slits.\" to Leonard.\n",
            "Leonard says \"Agreed. What's your point?\" to Sheldon.\n",
            "Sheldon says \"There's no point, I just think it's a good idea for a T-shirt.\" to Leonard.\n",
            "\n",
            "--------------------\n",
            "\n",
            "Using the previous dialogues above as context, classify the following dialogue below as humorous or not humorous:\n",
            "\n",
            "The Scene is still: A corridor at a sperm bank.\n",
            "Leonard says \"Excuse me.\" to Sheldon and Receptionist.\n",
            "\n",
            "Classify: [humorous] or [not humorous].\n",
            "Actual: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formatting the input\n",
        "\n",
        "### Ex raw entry:"
      ],
      "metadata": {
        "id": "IkEDU1FV6vJA"
      },
      "id": "IkEDU1FV6vJA"
    },
    {
      "cell_type": "code",
      "source": [
        "# example entry\n",
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "3leD8AnSOdUf",
        "outputId": "514fbd5c-f5b2-4fbf-eb5d-08df1f3791c8"
      },
      "id": "3leD8AnSOdUf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6f56a54a8e7d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# example entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generateDialogueWithContext(filePath, nSentenceContext):\n",
        "  formatted_inputs = []\n",
        "  labels = []\n",
        "\n",
        "  for episodePath in list_files(filePath):\n",
        "\n",
        "    with open(episodePath, 'r') as file:\n",
        "      data = json.load(file)\n",
        "      data = [info for (_, info) in data.items()]\n",
        "\n",
        "\n",
        "      i = nSentenceContext\n",
        "      while i < len(data):\n",
        "        context = [data[j] for j in range(i-nSentenceContext, i)]\n",
        "        target = data[i]\n",
        "        # formatted_entry = transformContextTarget(context, target)\n",
        "\n",
        "        formatted_inputs.append(transformContextTarget(context, target))\n",
        "\n",
        "        if \"isHumor\" in info:\n",
        "          labels.append(1)\n",
        "        else:\n",
        "          labels.append(0)\n",
        "\n",
        "        i += 1\n",
        "  return formatted_inputs, labels"
      ],
      "metadata": {
        "id": "QKV3_0Hc6M1L"
      },
      "id": "QKV3_0Hc6M1L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue_list1, label_list1 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S1', 3)\n",
        "dialogue_list2, label_list2 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S2', 3)\n",
        "dialogue_list3, label_list3 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S3', 3)\n",
        "dialogue_list4, label_list4 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S4', 3)\n",
        "dialogue_list5, label_list5 = generateDialogueWithContext('/content/info4940-sitcom/cleaned-data/S5', 3)"
      ],
      "metadata": {
        "id": "RnvrEKjEGGqY"
      },
      "id": "RnvrEKjEGGqY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dialogue_list2[3])\n",
        "print(\"\\n\\n\")\n",
        "print(\"Actual humor label: \", label_list2[3])"
      ],
      "metadata": {
        "id": "S-pp8Bf8sYtC",
        "outputId": "a62f6f57-400c-4fb8-f8df-d30d8d6c933b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "S-pp8Bf8sYtC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use the following as context:\n",
            "\n",
            "The scene is: The stairwell.\n",
            "Penny says \"Yeah, but it doesn't really answer my question.\" to Leonard.\n",
            "Leonard says \"- What was your question again? \" to Penny.\n",
            "Leonard says \"- Right. No. I'm lactose intolerant. \" to Penny.\n",
            "\n",
            "--------------------\n",
            "\n",
            "Using the previous dialogues above as context, classify the following dialogue below as humorous or not humorous:\n",
            "\n",
            "The Scene is still: The stairwell.\n",
            "Leonard says \"- So, gas. \" to Penny.\n",
            "\n",
            "Classify: [humorous] or [not humorous].\n",
            "\n",
            "\n",
            "\n",
            "Actual humor label:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = dialogue_list1 + dialogue_list2 + dialogue_list3 + dialogue_list4\n",
        "test_texts = dialogue_list5\n",
        "train_labels = label_list1 + label_list2 + label_list3 + label_list4\n",
        "test_labels = label_list5"
      ],
      "metadata": {
        "id": "mQDtMqo1Hn2F"
      },
      "id": "mQDtMqo1Hn2F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all the dialogues are strings:\n",
        "\n",
        "# for i in range(len(test_texts)):\n",
        "#   if type(test_texts[i]) != str:\n",
        "#     print(\"NOT A STRING\")\n",
        "#     print(\"index:\",i)\n",
        "#     print(\"string:\",test_texts[i])\n",
        "\n",
        "\n",
        "\n",
        "# Change this Dialogue from a number to a string\n",
        "test_texts[2106] = \"1863.0\""
      ],
      "metadata": {
        "id": "9LGu8RbPJRJB"
      },
      "id": "9LGu8RbPJRJB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline:"
      ],
      "metadata": {
        "id": "xEidNKdmYjQo"
      },
      "id": "xEidNKdmYjQo"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "RxL91CnsYitU"
      },
      "id": "RxL91CnsYitU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(use_idf=True,lowercase=True,stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test = vectorizer.transform(test_texts)"
      ],
      "metadata": {
        "id": "ne4seJeXZW1n"
      },
      "id": "ne4seJeXZW1n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "predictions = []\n",
        "clf = RandomForestClassifier(max_depth=5,n_jobs=-1).fit(X_train, train_labels)\n",
        "\n",
        "predictions.append(clf.predict(X_test))\n",
        "scores.append(clf.score(X_test, test_labels))"
      ],
      "metadata": {
        "id": "pdbK2eZRYdrM"
      },
      "id": "pdbK2eZRYdrM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Cross validated score: ', np.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STyphdNfY_N-",
        "outputId": "72cfab43-98f0-4c6d-f5ca-27787a9b20a5"
      },
      "id": "STyphdNfY_N-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validated score:  0.5373617994662601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Text Embeddings:"
      ],
      "metadata": {
        "id": "JecHN7wK9su-"
      },
      "id": "JecHN7wK9su-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize Data for BERT:\n",
        "model_name = 'distilbert-base-cased'\n",
        "device_name = 'cuda' # (you can use 'cpu' or 'mps')\n",
        "max_length = 512\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings  = tokenizer(test_texts, truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "      self.encodings = encodings\n",
        "      self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "      item['labels'] = torch.tensor(self.labels[idx])\n",
        "      return item\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.labels)\n",
        "\n",
        "train_dataset = MyDataset(train_encodings, train_labels)\n",
        "test_dataset = MyDataset(test_encodings, test_labels)\n"
      ],
      "metadata": {
        "id": "zc4KaDuFNjt2"
      },
      "id": "zc4KaDuFNjt2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained BERT Model:\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name,\n",
        "                                                            num_labels=2).to(device_name)"
      ],
      "metadata": {
        "id": "YpQK_lcWPcrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb0026a-1157-4bfc-c52f-af1414fc8d1e"
      },
      "id": "YpQK_lcWPcrq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_training_steps = len(train_dataloader) * num_train_epochs\n",
        "warmup_proportion = 0.1"
      ],
      "metadata": {
        "id": "YM6ZBv58cdE_"
      },
      "id": "YM6ZBv58cdE_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "  num_train_epochs=3,              # total number of training epochs\n",
        "  per_device_train_batch_size=16,  # batch size per device during training\n",
        "  per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "  learning_rate=5e-5,              # initial learning rate for Adam optimizer\n",
        "  warmup_steps= 1000,                # number of warmup steps for learning rate scheduler (set lower because of small dataset size)\n",
        "  weight_decay=0.01,               # strength of weight decay\n",
        "  output_dir='./results',          # output directory\n",
        "  logging_dir='./logs',            # directory for storing logs\n",
        "  logging_steps= 0.2,               # number of steps to output logging (set lower because of small dataset size)\n",
        "  evaluation_strategy='steps',     # evaluate during fine-tuning so that we can see progress\n",
        ")"
      ],
      "metadata": {
        "id": "aJVB8YzrgvsJ"
      },
      "id": "aJVB8YzrgvsJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning our BERT model:\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  #score = accuracy_score(labels, preds)\n",
        "  score = f1_score(labels, preds, average='weighted')\n",
        "  return {\n",
        "      'f1': score,\n",
        "  }"
      ],
      "metadata": {
        "id": "tYHRlKsjgz8Z"
      },
      "id": "tYHRlKsjgz8Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "  model=model,\n",
        "  args=training_args,\n",
        "  train_dataset=train_dataset,\n",
        "  eval_dataset=test_dataset,\n",
        "  compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "hAlpX7BJg8u6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d4030835-5884-4512-bd5d-b34f9d484adf"
      },
      "id": "hAlpX7BJg8u6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3837' max='3837' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3837/3837 15:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>768</td>\n",
              "      <td>0.651400</td>\n",
              "      <td>0.622280</td>\n",
              "      <td>0.658335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1536</td>\n",
              "      <td>0.617200</td>\n",
              "      <td>0.655059</td>\n",
              "      <td>0.601530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2304</td>\n",
              "      <td>0.586300</td>\n",
              "      <td>0.609760</td>\n",
              "      <td>0.665335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3072</td>\n",
              "      <td>0.450800</td>\n",
              "      <td>0.776657</td>\n",
              "      <td>0.655003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3837, training_loss=0.5361927898407977, metrics={'train_runtime': 959.8334, 'train_samples_per_second': 63.933, 'train_steps_per_second': 3.998, 'total_flos': 2397379198627620.0, 'train_loss': 0.5361927898407977, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cached_model_directory_name = 'distill-bert-tuned-no-context'\n",
        "trainer.save_model(cached_model_directory_name)"
      ],
      "metadata": {
        "id": "N2qOgPFEg_u_"
      },
      "id": "N2qOgPFEg_u_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the model above:\n",
        "# current_directory = os.getcwd()\n",
        "# model_directory = os.path.join(current_directory, cached_model_directory_name)\n",
        "\n",
        "# saved_model_directory = \"/path/to/your/directory/distill-bert-tuned-no-context\"\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(model_directory)"
      ],
      "metadata": {
        "id": "k66745wihyiX"
      },
      "id": "k66745wihyiX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating our Fine-Tuned Model:\n",
        "trainer.evaluate()\n",
        "predicted_results = trainer.predict(test_dataset)\n",
        "\n",
        "predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
        "predicted_labels = predicted_labels.flatten().tolist()      # Flatten the predictions into a 1D list\n",
        "\n",
        "print(classification_report(test_labels, predicted_labels))\n",
        "print(classification_report(test_labels, predicted_labels, output_dict = True)['weighted avg']['f1-score'])"
      ],
      "metadata": {
        "id": "egttSBk-hFhF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "185103b8-d0b9-4846-c6f8-1d96dcb1a156"
      },
      "id": "egttSBk-hFhF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.79      0.71      2819\n",
            "           1       0.67      0.49      0.57      2427\n",
            "\n",
            "    accuracy                           0.65      5246\n",
            "   macro avg       0.66      0.64      0.64      5246\n",
            "weighted avg       0.66      0.65      0.64      5246\n",
            "\n",
            "0.6445252731111133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01S1aEKGis6s"
      },
      "id": "01S1aEKGis6s",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}