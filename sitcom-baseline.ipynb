{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37361edd-f18b-455e-a306-289e42a489e4",
      "metadata": {
        "id": "37361edd-f18b-455e-a306-289e42a489e4"
      },
      "source": [
        "# The Big Bang Theory Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e29354-f5cd-4a30-8cbe-abc0f4c50ed3",
      "metadata": {
        "tags": [],
        "id": "91e29354-f5cd-4a30-8cbe-abc0f4c50ed3"
      },
      "source": [
        "### Imports:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSbyj3J0ugVj",
        "outputId": "d2eb145c-4344-4ac7-a2a8-f1e7478f026a"
      },
      "id": "LSbyj3J0ugVj",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENEIQ-sCPJfb",
        "outputId": "c797af57-7747-4a23-d6e6-6472ca835f3b"
      },
      "id": "ENEIQ-sCPJfb",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mâœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m venv 3350\n",
        "!source 3350/bin/activate"
      ],
      "metadata": {
        "id": "jKPk26plSJNy"
      },
      "id": "jKPk26plSJNy",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "# !pip install transformers[torch]\n",
        "# !pip install accelerate -U\n",
        "# !pip install accelerate>=0.21.0\n",
        "# !pip install --upgrade pip"
      ],
      "metadata": {
        "id": "-wa9rUhV4HWM"
      },
      "id": "-wa9rUhV4HWM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip uninstall transformers accelerate\n",
        "# pip install transformers[torch]\n",
        "# !pip install --upgrade setuptools"
      ],
      "metadata": {
        "id": "zftPtQ7PNNeT"
      },
      "id": "zftPtQ7PNNeT",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "f5c043b3-5369-4a0d-a3ea-ccb6b5f74949",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-05T08:05:04.798902Z",
          "start_time": "2024-03-05T08:05:04.795466Z"
        },
        "tags": [],
        "id": "f5c043b3-5369-4a0d-a3ea-ccb6b5f74949"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta, time\n",
        "from pathlib import Path\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import os\n",
        "from sklearn.metrics import f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "HO9kUogg4F8-"
      },
      "id": "HO9kUogg4F8-",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "51db49bb-fd2a-4501-a25f-1197f02b94f4",
      "metadata": {
        "id": "51db49bb-fd2a-4501-a25f-1197f02b94f4"
      },
      "source": [
        "## Loading sample data file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e533b5d1",
      "metadata": {
        "id": "e533b5d1"
      },
      "outputs": [],
      "source": [
        "def list_files(start_path):\n",
        "    file_paths = []\n",
        "    for root, dirs, files in os.walk(start_path):\n",
        "        for file in files:\n",
        "            file_paths.append(os.path.join(root, file))\n",
        "\n",
        "    file_paths.sort()\n",
        "    return file_paths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generateDialogue(filePath):\n",
        "  dialogue_list = []\n",
        "  label_list = []\n",
        "\n",
        "  for episodePath in list_files(filePath):\n",
        "    with open(episodePath, 'r') as file:\n",
        "      data = json.load(file)\n",
        "\n",
        "      for index, info in data.items():\n",
        "        dialogue_list.append(info[\"Dialogue\"])\n",
        "        if \"isHumor\" in info:\n",
        "          label_list.append(1)\n",
        "        else:\n",
        "          label_list.append(0)\n",
        "\n",
        "  return dialogue_list, label_list"
      ],
      "metadata": {
        "id": "QKV3_0Hc6M1L"
      },
      "id": "QKV3_0Hc6M1L",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue_list1, label_list1 = generateDialogue('/content/drive/My Drive/Sitcom/cleaned-data/S1')\n",
        "dialogue_list2, label_list2 = generateDialogue('/content/drive/My Drive/Sitcom/cleaned-data/S2')\n",
        "dialogue_list3, label_list3 = generateDialogue('/content/drive/My Drive/Sitcom/cleaned-data/S3')\n",
        "dialogue_list4, label_list4 = generateDialogue('/content/drive/My Drive/Sitcom/cleaned-data/S4')\n",
        "dialogue_list5, label_list5 = generateDialogue('/content/drive/My Drive/Sitcom/cleaned-data/S5')"
      ],
      "metadata": {
        "id": "RnvrEKjEGGqY"
      },
      "id": "RnvrEKjEGGqY",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = dialogue_list1 + dialogue_list2 + dialogue_list3 + dialogue_list4\n",
        "test_texts = dialogue_list5\n",
        "train_labels = label_list1 + label_list2 + label_list3 + label_list4\n",
        "test_labels = label_list5"
      ],
      "metadata": {
        "id": "mQDtMqo1Hn2F"
      },
      "id": "mQDtMqo1Hn2F",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all the dialogues are strings:\n",
        "\n",
        "# for i in range(len(test_texts)):\n",
        "#   if type(test_texts[i]) != str:\n",
        "#     print(\"NOT A STRING\")\n",
        "#     print(\"index:\",i)\n",
        "#     print(\"string:\",test_texts[i])\n",
        "\n",
        "\n",
        "\n",
        "# Change this Dialogue from a number to a string\n",
        "test_texts[2106] = \"1863.0\""
      ],
      "metadata": {
        "id": "9LGu8RbPJRJB"
      },
      "id": "9LGu8RbPJRJB",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline:"
      ],
      "metadata": {
        "id": "xEidNKdmYjQo"
      },
      "id": "xEidNKdmYjQo"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "RxL91CnsYitU"
      },
      "id": "RxL91CnsYitU",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(use_idf=True,lowercase=True,stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test = vectorizer.transform(test_texts)"
      ],
      "metadata": {
        "id": "ne4seJeXZW1n"
      },
      "id": "ne4seJeXZW1n",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "predictions = []\n",
        "clf = RandomForestClassifier(max_depth=5,n_jobs=-1).fit(X_train, train_labels)\n",
        "\n",
        "predictions.append(clf.predict(X_test))\n",
        "scores.append(clf.score(X_test, test_labels))"
      ],
      "metadata": {
        "id": "pdbK2eZRYdrM"
      },
      "id": "pdbK2eZRYdrM",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Cross validated score: ', np.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STyphdNfY_N-",
        "outputId": "72cfab43-98f0-4c6d-f5ca-27787a9b20a5"
      },
      "id": "STyphdNfY_N-",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validated score:  0.5373617994662601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Text Embeddings:"
      ],
      "metadata": {
        "id": "JecHN7wK9su-"
      },
      "id": "JecHN7wK9su-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize Data for BERT:\n",
        "model_name = 'distilbert-base-cased'\n",
        "device_name = 'cuda' # (you can use 'cpu' or 'mps')\n",
        "max_length = 512\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings  = tokenizer(test_texts, truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "      self.encodings = encodings\n",
        "      self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "      item['labels'] = torch.tensor(self.labels[idx])\n",
        "      return item\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.labels)\n",
        "\n",
        "train_dataset = MyDataset(train_encodings, train_labels)\n",
        "test_dataset = MyDataset(test_encodings, test_labels)\n"
      ],
      "metadata": {
        "id": "zc4KaDuFNjt2"
      },
      "id": "zc4KaDuFNjt2",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained BERT Model:\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name,\n",
        "                                                            num_labels=2).to(device_name)"
      ],
      "metadata": {
        "id": "YpQK_lcWPcrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb0026a-1157-4bfc-c52f-af1414fc8d1e"
      },
      "id": "YpQK_lcWPcrq",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_training_steps = len(train_dataloader) * num_train_epochs\n",
        "warmup_proportion = 0.1"
      ],
      "metadata": {
        "id": "YM6ZBv58cdE_"
      },
      "id": "YM6ZBv58cdE_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "  num_train_epochs=3,              # total number of training epochs\n",
        "  per_device_train_batch_size=16,  # batch size per device during training\n",
        "  per_device_eval_batch_size=8,   # batch size for evaluation\n",
        "  learning_rate=5e-5,              # initial learning rate for Adam optimizer\n",
        "  warmup_steps= 1000,                # number of warmup steps for learning rate scheduler (set lower because of small dataset size)\n",
        "  weight_decay=0.01,               # strength of weight decay\n",
        "  output_dir='./results',          # output directory\n",
        "  logging_dir='./logs',            # directory for storing logs\n",
        "  logging_steps= 0.2,               # number of steps to output logging (set lower because of small dataset size)\n",
        "  evaluation_strategy='steps',     # evaluate during fine-tuning so that we can see progress\n",
        ")"
      ],
      "metadata": {
        "id": "aJVB8YzrgvsJ"
      },
      "id": "aJVB8YzrgvsJ",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning our BERT model:\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  #score = accuracy_score(labels, preds)\n",
        "  score = f1_score(labels, preds, average='weighted')\n",
        "  return {\n",
        "      'f1': score,\n",
        "  }"
      ],
      "metadata": {
        "id": "tYHRlKsjgz8Z"
      },
      "id": "tYHRlKsjgz8Z",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "  model=model,\n",
        "  args=training_args,\n",
        "  train_dataset=train_dataset,\n",
        "  eval_dataset=test_dataset,\n",
        "  compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "hAlpX7BJg8u6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d4030835-5884-4512-bd5d-b34f9d484adf"
      },
      "id": "hAlpX7BJg8u6",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3837' max='3837' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3837/3837 15:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>768</td>\n",
              "      <td>0.651400</td>\n",
              "      <td>0.622280</td>\n",
              "      <td>0.658335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1536</td>\n",
              "      <td>0.617200</td>\n",
              "      <td>0.655059</td>\n",
              "      <td>0.601530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2304</td>\n",
              "      <td>0.586300</td>\n",
              "      <td>0.609760</td>\n",
              "      <td>0.665335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3072</td>\n",
              "      <td>0.450800</td>\n",
              "      <td>0.776657</td>\n",
              "      <td>0.655003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3837, training_loss=0.5361927898407977, metrics={'train_runtime': 959.8334, 'train_samples_per_second': 63.933, 'train_steps_per_second': 3.998, 'total_flos': 2397379198627620.0, 'train_loss': 0.5361927898407977, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cached_model_directory_name = 'distill-bert-tuned-no-context'\n",
        "trainer.save_model(cached_model_directory_name)"
      ],
      "metadata": {
        "id": "N2qOgPFEg_u_"
      },
      "id": "N2qOgPFEg_u_",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the model above:\n",
        "# current_directory = os.getcwd()\n",
        "# model_directory = os.path.join(current_directory, cached_model_directory_name)\n",
        "\n",
        "# saved_model_directory = \"/path/to/your/directory/distill-bert-tuned-no-context\"\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(model_directory)"
      ],
      "metadata": {
        "id": "k66745wihyiX"
      },
      "id": "k66745wihyiX",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating our Fine-Tuned Model:\n",
        "trainer.evaluate()\n",
        "predicted_results = trainer.predict(test_dataset)\n",
        "\n",
        "predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
        "predicted_labels = predicted_labels.flatten().tolist()      # Flatten the predictions into a 1D list\n",
        "\n",
        "print(classification_report(test_labels, predicted_labels))\n",
        "print(classification_report(test_labels, predicted_labels, output_dict = True)['weighted avg']['f1-score'])"
      ],
      "metadata": {
        "id": "egttSBk-hFhF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "185103b8-d0b9-4846-c6f8-1d96dcb1a156"
      },
      "id": "egttSBk-hFhF",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.79      0.71      2819\n",
            "           1       0.67      0.49      0.57      2427\n",
            "\n",
            "    accuracy                           0.65      5246\n",
            "   macro avg       0.66      0.64      0.64      5246\n",
            "weighted avg       0.66      0.65      0.64      5246\n",
            "\n",
            "0.6445252731111133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01S1aEKGis6s"
      },
      "id": "01S1aEKGis6s",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}