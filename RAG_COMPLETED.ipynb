{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "264a2312137249d7925a6e5f591a38a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_316d4af66b51422fbb10c150f8258e51",
              "IPY_MODEL_247f03b053ab4f06a854cb60d8d1b718",
              "IPY_MODEL_784f08749e3347289a4fb474e4c42c1e"
            ],
            "layout": "IPY_MODEL_689daff078f14982bf8cf4aa20bd111d"
          }
        },
        "316d4af66b51422fbb10c150f8258e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b0335f875d43038fe1ad44d53f7092",
            "placeholder": "​",
            "style": "IPY_MODEL_c78ba0681f334578b00a6fe73991349a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "247f03b053ab4f06a854cb60d8d1b718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dcf08aef71d49efb80904a314b7e87e",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec257fbffcf44b448df60a6cf72bfcbb",
            "value": 2324
          }
        },
        "784f08749e3347289a4fb474e4c42c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ff69ce47ee488f9ff512b6d18d9905",
            "placeholder": "​",
            "style": "IPY_MODEL_580f4805fe5645f387bc5917be6d6e42",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 29.8kB/s]"
          }
        },
        "689daff078f14982bf8cf4aa20bd111d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b0335f875d43038fe1ad44d53f7092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78ba0681f334578b00a6fe73991349a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dcf08aef71d49efb80904a314b7e87e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec257fbffcf44b448df60a6cf72bfcbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7ff69ce47ee488f9ff512b6d18d9905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "580f4805fe5645f387bc5917be6d6e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "143a4da64daa418e8c7e14eb9603d640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c0d35e9ff854dedb36fa4b3d697a3d3",
              "IPY_MODEL_6fb7fd92e0734179b26a924229891c82",
              "IPY_MODEL_51a018683a7e4dd1941f6776d0e40050"
            ],
            "layout": "IPY_MODEL_a89ac27e70024746b73ab3c1f9302b1d"
          }
        },
        "3c0d35e9ff854dedb36fa4b3d697a3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca8460b81924098867307ad6dbd52b2",
            "placeholder": "​",
            "style": "IPY_MODEL_fe396bd468a1426bb55501a919fcbdee",
            "value": "spiece.model: 100%"
          }
        },
        "6fb7fd92e0734179b26a924229891c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5513549644cb4dbe9f7fe20971752c0c",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dff3686432844ba83d9b2bb8306caaa",
            "value": 791656
          }
        },
        "51a018683a7e4dd1941f6776d0e40050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f2b4ba002b44754b9c1b5d59a852634",
            "placeholder": "​",
            "style": "IPY_MODEL_bdfef004b22145a9a012ee4448f2e536",
            "value": " 792k/792k [00:00&lt;00:00, 1.32MB/s]"
          }
        },
        "a89ac27e70024746b73ab3c1f9302b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca8460b81924098867307ad6dbd52b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe396bd468a1426bb55501a919fcbdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5513549644cb4dbe9f7fe20971752c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dff3686432844ba83d9b2bb8306caaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f2b4ba002b44754b9c1b5d59a852634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdfef004b22145a9a012ee4448f2e536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c53a5bfc9c434630b483252d3f7023be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2292ca9f9eb94a5db92d44da94f99c57",
              "IPY_MODEL_30f453fb8550458eb177bfd7caa36e1c",
              "IPY_MODEL_a2d20558f20a45c19fe8907860f08ea4"
            ],
            "layout": "IPY_MODEL_0daf52ee89274570bddaee6f8320acd9"
          }
        },
        "2292ca9f9eb94a5db92d44da94f99c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dfafeeb841e40ef84c4675af7b6af13",
            "placeholder": "​",
            "style": "IPY_MODEL_3c8afac9bad6470689f170b6a5481c46",
            "value": "tokenizer.json: 100%"
          }
        },
        "30f453fb8550458eb177bfd7caa36e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6eb258eeb14ad29947aa07247ef024",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b574774e2d54d4aa18a42fd0c3551d9",
            "value": 1389353
          }
        },
        "a2d20558f20a45c19fe8907860f08ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8769e0174104b01bfd7880e756248fe",
            "placeholder": "​",
            "style": "IPY_MODEL_f6702ca7604b441faf917ac087d4aa1f",
            "value": " 1.39M/1.39M [00:01&lt;00:00, 1.40MB/s]"
          }
        },
        "0daf52ee89274570bddaee6f8320acd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dfafeeb841e40ef84c4675af7b6af13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c8afac9bad6470689f170b6a5481c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a6eb258eeb14ad29947aa07247ef024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b574774e2d54d4aa18a42fd0c3551d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8769e0174104b01bfd7880e756248fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6702ca7604b441faf917ac087d4aa1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e858ede7866d4c5ba43635b741606ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe441432ca6048978923ef00ec474408",
              "IPY_MODEL_a652202fb6044b30b0aaf391b23807f1",
              "IPY_MODEL_bd21d0f9d5014774940e764457789bea"
            ],
            "layout": "IPY_MODEL_267ed3410c894f71b5365c69079e8bf7"
          }
        },
        "fe441432ca6048978923ef00ec474408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3b8296dbf214b058aea26008dc65733",
            "placeholder": "​",
            "style": "IPY_MODEL_723fb799497342999046e4f0d0e5d6da",
            "value": "config.json: 100%"
          }
        },
        "a652202fb6044b30b0aaf391b23807f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f287b3cc710e4a63ae16672ba887a7b1",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9757bce8473c4214a477eedb83de45a8",
            "value": 1206
          }
        },
        "bd21d0f9d5014774940e764457789bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0bbb4a42274221b379085a5cbf2054",
            "placeholder": "​",
            "style": "IPY_MODEL_292dc31b6d864e4ebb6765cafa6e8669",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 19.9kB/s]"
          }
        },
        "267ed3410c894f71b5365c69079e8bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b8296dbf214b058aea26008dc65733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "723fb799497342999046e4f0d0e5d6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f287b3cc710e4a63ae16672ba887a7b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9757bce8473c4214a477eedb83de45a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee0bbb4a42274221b379085a5cbf2054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292dc31b6d864e4ebb6765cafa6e8669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8089333ef4944b3acbe1561331705c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_206d6477f559460591dbd0b917e436dc",
              "IPY_MODEL_d24b609db1a14bcca0b0ec1d67cb5ee2",
              "IPY_MODEL_812f5a69376641f18734e507843f1bc9"
            ],
            "layout": "IPY_MODEL_dbbb5fd8abea438b8e4bfe3b2fd593d9"
          }
        },
        "206d6477f559460591dbd0b917e436dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bee257f3ef524bc1b26a04412d559518",
            "placeholder": "​",
            "style": "IPY_MODEL_0918b5dbc6754e19a89d12e7d5629258",
            "value": "model.safetensors: 100%"
          }
        },
        "d24b609db1a14bcca0b0ec1d67cb5ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7ca1e6b22a74e39a559c2b7f2956c57",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b7fdd50509d453183165e4f5c241469",
            "value": 242043056
          }
        },
        "812f5a69376641f18734e507843f1bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a484768aac41c585c9ccfdc8b2246b",
            "placeholder": "​",
            "style": "IPY_MODEL_efd69e544caf4e4d85af4fe1c111d58d",
            "value": " 242M/242M [00:03&lt;00:00, 74.1MB/s]"
          }
        },
        "dbbb5fd8abea438b8e4bfe3b2fd593d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee257f3ef524bc1b26a04412d559518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0918b5dbc6754e19a89d12e7d5629258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7ca1e6b22a74e39a559c2b7f2956c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b7fdd50509d453183165e4f5c241469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6a484768aac41c585c9ccfdc8b2246b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd69e544caf4e4d85af4fe1c111d58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6SPjUazYNi6",
        "outputId": "41451965-bd21-4d68-85fd-b59d40697f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'info4940-sitcom'...\n",
            "remote: Enumerating objects: 1079, done.\u001b[K\n",
            "remote: Counting objects: 100% (1079/1079), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 1079 (delta 946), reused 1038 (delta 915), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1079/1079), 14.57 MiB | 10.93 MiB/s, done.\n",
            "Resolving deltas: 100% (946/946), done.\n",
            "Updating files: 100% (921/921), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/adc257/info4940-sitcom.git\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE FOR LATER USE #CODE that extracts all humor dialogues in the whole SEASON 1\n",
        "import os\n",
        "import json\n",
        "\n",
        "root_dir = \"/content/info4940-sitcom/cleaned-data/S1\"\n",
        "episode_humor_data = {}\n",
        "\n",
        "# Iterate over each episode file in the S1 folder\n",
        "for episode_file in os.listdir(root_dir):\n",
        "    episode_path = os.path.join(root_dir, episode_file)\n",
        "    if os.path.isfile(episode_path):\n",
        "        with open(episode_path, 'r') as file:\n",
        "            try:\n",
        "                data = json.load(file)\n",
        "                humor_dialogues = [dialogue for timestamp, dialogue in data.items() if dialogue.get('isHumor', False)]\n",
        "                episode_humor_data[episode_file] = humor_dialogues\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Error decoding JSON from file: {episode_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Unexpected error processing file {episode_path}: {e}\")\n",
        "\n",
        "# Process the humor data for each episode as needed\n",
        "for episode, humor_dialogues in episode_humor_data.items():\n",
        "    print(f\"Episode: {episode}, Number of Humor Dialogues: {len(humor_dialogues)}\")\n",
        "\n",
        "#for dialogue in humor_dialogues[:4]:\n",
        "#        print(dialogue)\n",
        "#        print(\"\\n\")"
      ],
      "metadata": {
        "id": "UEcUjmOKr3HM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ebc3f1d-f537-4428-ee2c-383ac1ca087d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: The Big Bang_S0117.json, Number of Humor Dialogues: 102\n",
            "Episode: The Big Bang_S0111.json, Number of Humor Dialogues: 123\n",
            "Episode: The Big Bang_S0107.json, Number of Humor Dialogues: 126\n",
            "Episode: The Big Bang_S0112.json, Number of Humor Dialogues: 119\n",
            "Episode: The Big Bang_S0108.json, Number of Humor Dialogues: 116\n",
            "Episode: The Big Bang_S0101.json, Number of Humor Dialogues: 125\n",
            "Episode: The Big Bang_S0104.json, Number of Humor Dialogues: 114\n",
            "Episode: The Big Bang_S0105.json, Number of Humor Dialogues: 114\n",
            "Episode: The Big Bang_S0110.json, Number of Humor Dialogues: 100\n",
            "Episode: The Big Bang_S0103.json, Number of Humor Dialogues: 109\n",
            "Episode: The Big Bang_S0102.json, Number of Humor Dialogues: 97\n",
            "Episode: The Big Bang_S0115.json, Number of Humor Dialogues: 130\n",
            "Episode: The Big Bang_S0116.json, Number of Humor Dialogues: 94\n",
            "Episode: The Big Bang_S0113.json, Number of Humor Dialogues: 111\n",
            "Episode: The Big Bang_S0114.json, Number of Humor Dialogues: 97\n",
            "Episode: The Big Bang_S0109.json, Number of Humor Dialogues: 95\n",
            "Episode: The Big Bang_S0106.json, Number of Humor Dialogues: 91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK: Humor detection using rag on S1E5\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "def create_episode_dataset(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        episode_data = json.load(file)\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    for timestamp, dialogue in episode_data.items():\n",
        "        # Add current dialogue and its humor classification to the dataset\n",
        "        dataset.append({\n",
        "            \"episode\": file_path.split('/')[-1],\n",
        "            \"timestamp\": timestamp,\n",
        "            \"scene\": dialogue['Scene'],\n",
        "            \"recipients\": dialogue['Recipients'],\n",
        "            \"speaker\": dialogue['Speaker'],\n",
        "            \"dialogue\": dialogue['Dialogue'],\n",
        "            \"is_joke\": dialogue.get('isHumor', False)\n",
        "        })\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Path to your episode 5 file\n",
        "episode_file = \"/content/info4940-sitcom/cleaned-data/S1/The Big Bang_S0105.json\"\n",
        "episode_dataset = create_episode_dataset(episode_file)\n",
        "\n",
        "# Example: Print the first few entries from the dataset\n",
        "#for entry in episode_dataset[:4]:\n",
        "#    print(entry)\n",
        "\n",
        "\n",
        "#create a textual piece that combines all the scenes and dialogues\n",
        "\n",
        "formatted_entries = []\n",
        "for entry in episode_dataset:\n",
        "    formatted_entry = (\n",
        "        f\"The time is {entry['timestamp']}. \"\n",
        "        f\"The scene is {entry['scene']}. \"\n",
        "        f\"The recipients are {', '.join(entry['recipients'])}. \"\n",
        "        f\"The speaker is {entry['speaker']}. \"\n",
        "        f\"{entry['speaker']} says \\\"{entry['dialogue']}\\\"\\n\"\n",
        "    )\n",
        "    formatted_entries.append(formatted_entry)\n",
        "\n",
        "#save as text file\n",
        "output_file_path = \"/content/info4940-sitcom/episode_5_formatted.txt\"\n",
        "with open(output_file_path, 'w') as file:\n",
        "    for formatted_entry in formatted_entries:\n",
        "        file.write(formatted_entry)\n",
        "\n",
        "print(f\"Formatted entries saved to {output_file_path}\")\n",
        "\n",
        "#for formatted_entry in formatted_entries[:4]:\n",
        "#    print(formatted_entry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd6o7Kn45YJd",
        "outputId": "1803a2cc-d22d-4b26-f0ef-adee7c7edf38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'episode': 'The Big Bang_S0105.json', 'timestamp': '00:00:00:220000', 'scene': 'The Cheesecake Factory', 'recipients': ['Leonard', 'Raj', 'Howard'], 'speaker': 'Sheldon', 'dialogue': \"All right! I'm moving my infantry division. Augmented by bataillon of orcs from Lord of the Rings. We flank the Tennessee volunteers and the North, once again, wins the battle of Gettysburg.\", 'is_joke': False}\n",
            "{'episode': 'The Big Bang_S0105.json', 'timestamp': '00:00:12:110000', 'scene': 'The Cheesecake Factory', 'recipients': ['Sheldon', 'Leonard', 'Raj'], 'speaker': 'Howard', 'dialogue': 'Not so fast! Remember, the South still has two infantry divisions, plus Superman and Godzilla.', 'is_joke': True}\n",
            "{'episode': 'The Big Bang_S0105.json', 'timestamp': '00:00:18:100000', 'scene': 'The Cheesecake Factory', 'recipients': ['Sheldon', 'Raj', 'Howard'], 'speaker': 'Leonard', 'dialogue': 'No, orcs are magic. Superman is vulnerable to magic. Not to mention you already lost Godzilla to the Illinois cavalry and Hulk.', 'is_joke': False}\n",
            "{'episode': 'The Big Bang_S0105.json', 'timestamp': '00:00:26:150000', 'scene': 'The Cheesecake Factory', 'recipients': ['Sheldon', 'Leonard', 'Howard'], 'speaker': 'Raj', 'dialogue': \"Why don't you just have Robert E. Lee charge the line with Shiva and Ganesh?\", 'is_joke': False}\n",
            "Formatted entries saved to /content/info4940-sitcom/episode_5_formatted.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RAG IMPLEMENTATION ON PREVIOUS CODE CHUNK - formatted_entry\n",
        "\n",
        "#Installing libraries\n",
        "\n",
        "!pip install torch transformers\n",
        "from transformers import T5Tokenizer, T5EncoderModel\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l23rtr3SRhtU",
        "outputId": "da422b26-1244-4af7-cc21-a2a8f80074d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m897.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RAG IMPLEMENTATION ON PREVIOUS CODE CHUNK - Setting up our tokenizer and model\n",
        "import os\n",
        "hf_token = os.environ.get('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')\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "# Load the pre-trained model\n",
        "model = T5EncoderModel.from_pretrained('t5-small')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "264a2312137249d7925a6e5f591a38a3",
            "316d4af66b51422fbb10c150f8258e51",
            "247f03b053ab4f06a854cb60d8d1b718",
            "784f08749e3347289a4fb474e4c42c1e",
            "689daff078f14982bf8cf4aa20bd111d",
            "f4b0335f875d43038fe1ad44d53f7092",
            "c78ba0681f334578b00a6fe73991349a",
            "6dcf08aef71d49efb80904a314b7e87e",
            "ec257fbffcf44b448df60a6cf72bfcbb",
            "e7ff69ce47ee488f9ff512b6d18d9905",
            "580f4805fe5645f387bc5917be6d6e42",
            "143a4da64daa418e8c7e14eb9603d640",
            "3c0d35e9ff854dedb36fa4b3d697a3d3",
            "6fb7fd92e0734179b26a924229891c82",
            "51a018683a7e4dd1941f6776d0e40050",
            "a89ac27e70024746b73ab3c1f9302b1d",
            "eca8460b81924098867307ad6dbd52b2",
            "fe396bd468a1426bb55501a919fcbdee",
            "5513549644cb4dbe9f7fe20971752c0c",
            "4dff3686432844ba83d9b2bb8306caaa",
            "9f2b4ba002b44754b9c1b5d59a852634",
            "bdfef004b22145a9a012ee4448f2e536",
            "c53a5bfc9c434630b483252d3f7023be",
            "2292ca9f9eb94a5db92d44da94f99c57",
            "30f453fb8550458eb177bfd7caa36e1c",
            "a2d20558f20a45c19fe8907860f08ea4",
            "0daf52ee89274570bddaee6f8320acd9",
            "3dfafeeb841e40ef84c4675af7b6af13",
            "3c8afac9bad6470689f170b6a5481c46",
            "8a6eb258eeb14ad29947aa07247ef024",
            "7b574774e2d54d4aa18a42fd0c3551d9",
            "f8769e0174104b01bfd7880e756248fe",
            "f6702ca7604b441faf917ac087d4aa1f",
            "e858ede7866d4c5ba43635b741606ada",
            "fe441432ca6048978923ef00ec474408",
            "a652202fb6044b30b0aaf391b23807f1",
            "bd21d0f9d5014774940e764457789bea",
            "267ed3410c894f71b5365c69079e8bf7",
            "a3b8296dbf214b058aea26008dc65733",
            "723fb799497342999046e4f0d0e5d6da",
            "f287b3cc710e4a63ae16672ba887a7b1",
            "9757bce8473c4214a477eedb83de45a8",
            "ee0bbb4a42274221b379085a5cbf2054",
            "292dc31b6d864e4ebb6765cafa6e8669",
            "b8089333ef4944b3acbe1561331705c6",
            "206d6477f559460591dbd0b917e436dc",
            "d24b609db1a14bcca0b0ec1d67cb5ee2",
            "812f5a69376641f18734e507843f1bc9",
            "dbbb5fd8abea438b8e4bfe3b2fd593d9",
            "bee257f3ef524bc1b26a04412d559518",
            "0918b5dbc6754e19a89d12e7d5629258",
            "d7ca1e6b22a74e39a559c2b7f2956c57",
            "5b7fdd50509d453183165e4f5c241469",
            "f6a484768aac41c585c9ccfdc8b2246b",
            "efd69e544caf4e4d85af4fe1c111d58d"
          ]
        },
        "id": "94dN3QTHR8wI",
        "outputId": "51de54b4-71c8-45ac-d4bd-e4415491f12d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "264a2312137249d7925a6e5f591a38a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "143a4da64daa418e8c7e14eb9603d640"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c53a5bfc9c434630b483252d3f7023be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e858ede7866d4c5ba43635b741606ada"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8089333ef4944b3acbe1561331705c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1K9Ac6s1Z1N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embeddings(text_list):\n",
        "    embeddings = []\n",
        "    for text in text_list:\n",
        "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():  # Disable gradient calculations\n",
        "            outputs = model(**inputs)\n",
        "        # Use the mean of the last hidden states as the embedding\n",
        "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
        "    return embeddings\n",
        "\n",
        "embeddings = generate_embeddings(formatted_entries)\n"
      ],
      "metadata": {
        "id": "VpE7Jg9DiUGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LANGCHAIN ATTEMPT**\n"
      ],
      "metadata": {
        "id": "x_KFa9y2s24w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install torch\n",
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install huggingface-hub\n",
        "!pip install pypdf\n",
        "!pip -q install accelerate\n",
        "!pip install llama-cpp-python\n",
        "!pip -q install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghdzMfB8h8Cg",
        "outputId": "3e3eff22-f8c1-4be2-e0d9-ab8e2830172f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.31)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.40)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.40)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.37->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-2.6.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.10.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.60.tar.gz (37.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/37.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.10.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.60-cp310-cp310-manylinux_2_35_x86_64.whl size=2980460 sha256=b51bfa1c01f545e3c86ca6b06c713e599099a60959ee373ab5308da4b1544d55\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/7b/02/5200ea3612eca540182654a0b72f0b2a90c0f32d1633c931e4\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.60\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader"
      ],
      "metadata": {
        "id": "t9fWTBCKi0gP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/info4940-sitcom/MJ RAG Work/sample_data/episode_5_formatted.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split the text content based on \"The time is\"\n",
        "chunks = text.split(\"The time is\")\n",
        "chunks = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
        "\n",
        "# Print out the resulting chunks\n",
        "for chunk in chunks:\n",
        "    print(chunk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDQ0O6r9i4cR",
        "outputId": "30996d96-0dc8-4752-c183-1db23a6910fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00:00:00:220000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard. The speaker is Sheldon. Sheldon says \"All right! I'm moving my infantry division. Augmented by bataillon of orcs from Lord of the Rings. We flank the Tennessee volunteers and the North, once again, wins the battle of Gettysburg.\"\n",
            "00:00:12:110000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj. The speaker is Howard. Howard says \"Not so fast! Remember, the South still has two infantry divisions, plus Superman and Godzilla.\"\n",
            "00:00:18:100000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard. The speaker is Leonard. Leonard says \"No, orcs are magic. Superman is vulnerable to magic. Not to mention you already lost Godzilla to the Illinois cavalry and Hulk.\"\n",
            "00:00:26:150000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard. The speaker is Raj. Raj says \"Why don't you just have Robert E. Lee charge the line with Shiva and Ganesh?\"\n",
            "00:00:30:200000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"You guys ready to order? \"\n",
            "00:00:33:000000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj. The speaker is Howard. Howard says \"Shiva and Ganesh, the Hindu gods, against the entire Union army?\"\n",
            "00:00:36:220000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard. The speaker is Leonard. Leonard says \"And orcs.\"\n",
            "00:00:38:190000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"I'll be back.\"\n",
            "00:00:40:080000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard, Penny. The speaker is Raj. Raj says \"Excuse me. Ganesh is the Remover of Obstacles and Shiva is the Destroyer. When the smoke clears, Abraham Lincoln will be speaking Hindi and drinking mint juleps.\"\n",
            "00:00:49:040000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"My boss says you have to either order or leave and never come back.\"\n",
            "00:00:53:090000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"What do you recommend for someone who worked up a man-sized appetite from a morning of weight training and cardio funk?\"\n",
            "00:00:58:180000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"A shower.\"\n",
            "00:01:00:200000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"I'll take the Heart Smart platter.\"\n",
            "00:01:03:170000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"All right, thank you, and Sheldon?\"\n",
            "00:01:05:200000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"We don't eat here. I don't know what's good.\"\n",
            "00:01:08:030000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"It's all good. \"\n",
            "00:01:11:180000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Just get a hamburger. You like hamburgers.\"\n",
            "00:01:13:210000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"I like hamburgers where we usually have them. You can't make the assumption that I'll like them here.\"\n",
            "00:01:19:030000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"I'm sorry. Give him a hamburger. \"\n",
            "00:01:20:090000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Which one? The Classic Burger, the Ranch House Burger, the Barbecue Burger, or the Kobe Burger?\"\n",
            "00:01:26:100000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"Can't we just go to Big Boy? They only have one burger... the Big Boy.\"\n",
            "00:01:31:130000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"The Barbecue Burger's like the Big Boy.\"\n",
            "00:01:33:080000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"Excuse me, in a world that already includes a Big Boy, why would I settle for something like a Big Boy?\"\n",
            "00:01:38:060000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Because you're not at Big Boy!\"\n",
            "00:01:41:130000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Make it two.\"\n",
            "00:01:44:060000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"Waitresses don't yell at you at Big Boy.\"\n",
            "00:01:47:140000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny, Lesley. The speaker is Lesley . Lesley  says \"Hey, Leonard. Hi, guys.\"\n",
            "00:01:49:100000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Hi, Leslie.\"\n",
            "00:01:50:150000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"I didn't know you ate here.\"\n",
            "00:01:52:010000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny, Lesley. The speaker is Sheldon. Sheldon says \"We don't. This is a disturbing aberration.\"\n",
            "00:01:54:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Leslie, this is Penny. She lives across the hall from Sheldon and me.\"\n",
            "00:01:57:200000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny, Lesley. The speaker is Howard. Howard says \"And walks in quiet beauty like the night.\"\n",
            "00:02:01:090000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Lesley. The speaker is Penny. Penny says \"Howard, I've asked you not to do that.\"\n",
            "00:02:04:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Leslie and I do research together at the university.\"\n",
            "00:02:07:140000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Lesley. The speaker is Penny. Penny says \"Wow, a girl scientist.\"\n",
            "00:02:09:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"Yep, come for the breasts, stay for the brains.\"\n",
            "00:02:13:070000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"Glad I ran into you. The Physics Department string quartet needs a new cellist.\"\n",
            "00:02:16:220000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"What happened to Elliot Wong?\"\n",
            "00:02:18:110000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"He switched over to high-energy radiation research, had a little mishap, and now the other guys are uncomfortable sitting next to him. You're in?\"\n",
            "00:02:24:180000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Yeah, sure, why not?\"\n",
            "00:02:27:020000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"Great, we rehearse on Tuesdays at your place.\"\n",
            "00:02:29:080000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Why at my place?\"\n",
            "00:02:30:130000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"Department of Energy said our regular space is kind of a hot zone.\"\n",
            "00:02:34:150000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Yeah, you, too. I didn't know you played the cello.\"\n",
            "00:02:39:050000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Yeah, my parents felt that naming me Leonard and putting me in Advanced Placement classes wasn't getting me beaten up enough.\"\n",
            "00:02:46:150000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"If you're into music, I happen to be a human beatbox.\"\n",
            "00:02:49:180000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Really?\"\n",
            "00:02:57:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"I'm actually not that into music.\"\n",
            "00:03:00:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Your friend's really cute. Anything going on with you two?\"\n",
            "00:03:04:030000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Leslie? No, no. What, are you kidding?\"\n",
            "00:03:06:180000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"He asked her out once. It was an embarrassing failure.\"\n",
            "00:03:11:030000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Thank you, Sheldon.\"\n",
            "00:03:15:160000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"That's too bad. You guys'd make a cute couple.\"\n",
            "00:03:20:000000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard, Penny. The speaker is Raj. Raj says \"Oh, dear.\"\n",
            "00:03:21:090000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard, Penny. The speaker is Raj. Raj says \"She didn't take my order.\"\n",
            "00:03:23:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"How can she take your order when you're too neurotic to talk to her?\"\n",
            "00:03:27:080000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard, Penny. The speaker is Raj. Raj says \"Nevertheless, this will be reflected in her tip.\"\n",
            "00:03:33:120000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"What did Penny mean, You'd make a cute couple?\"\n",
            "00:03:36:110000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I assume she meant the two of you together would constitute a couple that others might consider cute.\"\n",
            "00:03:43:060000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"An alternate and somewhat less likely interpretation is that you could manufacture one.\"\n",
            "00:03:49:060000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"As in, Look, Leonard and Leslie made Mr. and Mrs. Goldfarb. Aren't they adorable?\"\n",
            "00:03:54:130000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"If Penny didn't know that Leslie had turned me down, then it would unambiguously mean that she, Penny, thought I should ask her, Leslie, out, indicating that she had no interest in me asking her, Penny, out. But, because she did know that I had asked Leslie out and that she, Leslie, had turned me down, then she, Penny, could be offering consolation.\"\n",
            "00:04:13:180000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"That's too bad, you would have made a cute couple, but while thinking: Good, Leonard remains available.\"\n",
            "00:04:22:090000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"You're a lucky man, Leonard.\"\n",
            "00:04:26:040000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"How so?\"\n",
            "00:04:32:220000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Well, what do you think?\"\n",
            "00:04:34:130000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I said I could follow it. I didn't say I care.\"\n",
            "00:05:07:210000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"I admire your fingering.\"\n",
            "00:05:10:180000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Thank you.\"\n",
            "00:05:13:110000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Maybe sometime you can try that on my instrument.\"\n",
            "00:05:25:070000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"G'night, guys. Good job.\"\n",
            "00:05:26:230000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley, Leonard. The speaker is Female string quartettist. Female string quartettist says \"See you next week.\"\n",
            "00:05:28:210000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"That was fun. Thanks for including me.\"\n",
            "00:05:35:030000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Sure, why not?\"\n",
            "00:05:42:220000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Just so we're clear, you understand that me hanging back to practice with you is a pretext for letting you know that I'm sexually available.\"\n",
            "00:05:56:130000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Really?\"\n",
            "00:05:57:200000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Yeah, I'm good to go.\"\n",
            "00:06:00:010000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"I thought you weren't interested in me.\"\n",
            "00:06:02:040000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"That was before I saw you handling that beautiful piece of wood between your legs.\"\n",
            "00:06:08:120000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"You mean my cello?\"\n",
            "00:06:10:030000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"No, I mean the obvious, crude, double entendre. I'm seducing you.\"\n",
            "00:06:16:020000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"No kidding.\"\n",
            "00:06:18:090000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"What can I say? I'm a passionate and impulsive woman.\"\n",
            "00:06:22:150000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"So how about it? Is it the waitress?\"\n",
            "00:06:29:110000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"What about her?\"\n",
            "00:06:30:170000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"I thought I saw your pupils dilate when you looked at her. Which, unless you're a heroin addict, points to sexual attraction.\"\n",
            "00:06:37:230000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"I did have a poppy seed bagel for breakfast. Which could cause a positive urine test for opiates, but certainly not dilate my pupils. So I guess there was no point in bringing it up.\"\n",
            "00:06:48:180000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"You and the waitress then.\"\n",
            "00:06:50:170000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"No... no. There's nothing going on between Penny and me.\"\n",
            "00:06:54:230000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"So you're open to a sexual relationship?\"\n",
            "00:06:58:110000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Yeah, yeah, I guess I am.\"\n",
            "00:07:00:110000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Good.\"\n",
            "00:07:07:100000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Why don't we finish the section first?\"\n",
            "00:07:10:150000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"A little musical foreplay. Terrific.\"\n",
            "00:07:34:030000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"I'm good to go.\"\n",
            "00:07:35:090000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Me, too.\"\n",
            "00:07:48:080000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Penny. The speaker is Penny . Penny  says \"Hey, Sheldon. What's going on?\"\n",
            "00:07:50:020000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"I need your opinion on a matter of semiotics.\"\n",
            "00:07:52:210000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"I'm sorry?\"\n",
            "00:07:54:100000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Semiotics. The study of signs and symbols. It's a branch of philosophy related to linguistics.\"\n",
            "00:08:01:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Okay, sweetie, I know you think you're explaing yourself, but you're really not.\"\n",
            "00:08:08:220000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Just come with me.\"\n",
            "00:08:14:230000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Well, what?\"\n",
            "00:08:17:110000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"What does it mean?\"\n",
            "00:08:19:160000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Oh, come on, you went to college.\"\n",
            "00:08:21:200000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Yes, but I was 11.\"\n",
            "00:08:26:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"All right, look, a tie on the doorknob usually means someone doesn't want to be disturbed because, they're... you know, gettin' busy.\"\n",
            "00:08:35:080000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"So you're saying Leonard has a girl in there?\"\n",
            "00:08:37:110000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Well, either that or he's lost his tie rack and gotten really into Bryan Adams.\"\n",
            "00:08:43:070000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Penny. The speaker is Lesley . Lesley  says \"Oh, Leonard, you magnificent beast.\"\n",
            "00:08:48:080000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"We really shouldn't be standing here.\"\n",
            "00:08:52:210000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Penny. The speaker is Sheldon . Sheldon  says \"This is very awkward.\"\n",
            "00:08:54:220000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Oh, come on, Leonard's had girls over before, right?\"\n",
            "00:08:58:180000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Yes, but there's usually planning, courtship, advance notice...\"\n",
            "00:09:03:160000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Last time, I was able to book a cruise to the Arctic to see a solar eclipse.\"\n",
            "00:09:08:230000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"You had to leave the state because your roommate was having sex?\"\n",
            "00:09:12:130000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"I didn't have to. The dates just happened to coincide.\"\n",
            "00:09:18:100000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"So, do you know who's in there?\"\n",
            "00:09:21:140000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Well, there's Leonard.\"\n",
            "00:09:26:180000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"And he's either with Leslie Winkle or a 1930s gangster.\"\n",
            "00:09:34:090000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Good for him. Good for Leonard. Okay, g'night.\"\n",
            "00:09:41:060000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"No, no, wait, hold on.\"\n",
            "00:09:42:220000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"What's the matter?\"\n",
            "00:09:44:140000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"I don't know what the protocol is here.\"\n",
            "00:09:48:060000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Do I stay? Do I leave? Do I wait to greet them with a refreshing beverage?\"\n",
            "00:09:55:200000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"You're asking the wrong girl. I'm usually on the other side of the tie.\"\n",
            "00:10:20:100000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Hi, Leonard?\"\n",
            "00:10:25:000000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"It's me, Sheldon...\"\n",
            "00:10:29:150000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"In the living room. I just... I wanted you to know I saw the tie. Message received.\"\n",
            "00:10:39:080000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"You're welcome.\"\n",
            "00:10:42:100000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"You carry on. Give my best to Leslie.\"\n",
            "00:10:45:000000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Lesley, Leonard. The speaker is -----. ----- says \"Laughing \"\n",
            "00:11:22:030000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Big Boy...\"\n",
            "00:11:48:120000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Someone touched my board.\"\n",
            "00:11:53:210000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Oh, God, my board!\"\n",
            "00:12:01:160000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Leonard . Leonard  says \"Hey, what's the matter?\"\n",
            "00:12:03:110000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"My equations, someone's tampered with my equations.\"\n",
            "00:12:06:000000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Are you sure?\"\n",
            "00:12:12:090000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Oh, yeah. But doesn't that fix the problem you've been having?\"\n",
            "00:12:16:020000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Are you insane? Are you out of your mind? Are you-- Look! That fixes the problem I've been having.\"\n",
            "00:12:23:060000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"You're welcome.\"\n",
            "00:12:26:070000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"You did this?\"\n",
            "00:12:28:230000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"I noticed it when I got up to get a glass of water. So I fixed it. Now you can show that quarks are asymptotically free at high energies. Pretty cool, huh?\"\n",
            "00:12:38:070000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"Cool?\"\n",
            "00:12:40:130000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"Listen, I've got to get to the lab. Thanks for a great night.\"\n",
            "00:12:45:050000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Lesley. The speaker is Leonard. Leonard says \"Thank you. I'll see you at work.\"\n",
            "00:12:47:040000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"Hold on. Hold on!\"\n",
            "00:12:49:190000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"What?\"\n",
            "00:12:52:150000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"No one.\"\n",
            "00:12:53:160000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"I don't come into your house and touch your board.\"\n",
            "00:12:56:060000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"There are no incorrect equations on my board.\"\n",
            "00:13:02:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"Oh, that is so... so...\"\n",
            "00:13:07:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"Sorry, I've got to run. If you come up with an adjective, text me.\"\n",
            "00:13:14:050000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Inconsiderate. That is the adjective, inconsiderate. \"\n",
            "00:13:19:210000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"You can stare at your board all day. She's still going to be right.\"\n",
            "00:13:22:220000. The scene is The hallway.. The recipients are Leonard, Penny. The speaker is Sheldon. Sheldon says \"I'm not staring, I'm hauling.\"\n",
            "00:13:27:060000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"So... how's it going?\"\n",
            "00:13:33:100000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"Pretty good.\"\n",
            "00:13:35:220000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"Just pretty good? I'd think you were doing very good.\"\n",
            "00:13:40:220000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"Pretty, very... there's really no objective scale for delineating variations of good. Why do you ask?\"\n",
            "00:13:47:050000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"Well, a little bird told me that you and Leslie hooked up last night.\"\n",
            "00:13:56:010000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"So, is it serious? Do you like her?\"\n",
            "00:13:59:020000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"I don't... That's really two different questions. I'm not... Sheldon, we have to go!\"\n",
            "00:14:07:230000. The scene is The hallway.. The recipients are Leonard, Penny. The speaker is Sheldon. Sheldon says \"You're wound awfully tight for a man who's just had sexual intercourse.\"\n",
            "00:14:13:150000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"All right, I'll talk to you later, but I am so happy for you.\"\n",
            "00:14:18:190000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Thank you. What did she mean she's happy for me? Is she happy that I'm seeing someone? Or is she happy because she thinks that I am? Because anyone who cared for someone would want them to be happy. Even if the reason for their happiness made the first person unhappy.\"\n",
            "00:14:37:090000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Because the second person, though happy, is now romantically unavailable to the first person.\"\n",
            "00:14:43:060000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Do you realize I may have to share a Nobel Prize with your booty call?\"\n",
            "00:14:50:170000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"You know what? I'm being ridiculous. Who cares what Penny thinks? Leslie is a terrific girl. She's attractive. We like each other. She's extremely intelligent...\"\n",
            "00:15:01:230000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"She's not that intelligent.\"\n",
            "00:15:05:000000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"You don't believe in luck.\"\n",
            "00:15:07:030000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I don't have to believe in it for her to be lucky.\"\n",
            "00:15:10:190000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Regardless, I have a chance at a real relationship with Leslie. I'm not going to pass that up for some hypothetical future of happiness with a woman who may or may not want me to be happy, with a woman who is currently making me happy.\"\n",
            "00:15:25:160000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I still don't care.\"\n",
            "00:15:37:130000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Careful, Leonard. Liquid nitrogen, 320 degrees below zero.\"\n",
            "00:15:49:150000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Why are you smashing a flash-frozen banana?\"\n",
            "00:15:52:070000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Because I got a bowl of Cheerios and I couldn't find a knife.\"\n",
            "00:15:57:110000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"So anyway... Hello.\"\n",
            "00:16:03:200000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"What are you doing?\"\n",
            "00:16:05:220000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Just extending the intimacy. Do you want to slip over to the radiation lab and share a decontamination shower?\"\n",
            "00:16:17:050000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"What exactly do you think's going on between us?\"\n",
            "00:16:21:060000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"I'm not sure, but I think I'm about to discover how the banana felt.\"\n",
            "00:16:29:060000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Listen, neither of us are neuroscientists, but we both understand the biochemistry of sex. I mean, dopamine in our brains is released across synapses, causing pleasure. You stick electrodes in a rat's brain, give him an orgasm button, he'll push that thing until he starves to death.\"\n",
            "00:16:43:110000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Well, who wouldn't?\"\n",
            "00:16:45:080000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Well, the only difference between us and the rat is that you can't stick an electrode in our hypothalamus. That's where you come in.\"\n",
            "00:16:53:140000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Yeah, well, I'm just glad to be a part of it.\"\n",
            "00:16:57:170000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"So what happens now?\"\n",
            "00:16:59:020000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"I don't know about your sex drive, but I'm probably good till New Year's.\"\n",
            "00:17:08:050000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Thank you.\"\n",
            "00:17:13:070000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"You want to make plans for New Year's?\"\n",
            "00:17:15:040000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Please. You're smothering me.\"\n",
            "00:17:19:180000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard, Raj. The speaker is Howard. Howard says \"Look. It's Dr. Stud!\"\n",
            "00:17:23:100000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"Dr. What?\"\n",
            "00:17:24:150000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard, Raj. The speaker is Howard. Howard says \"The blogosphere is a-buzzin' with news of you and Leslie Winkle making eine kleine bang-bang musik.\"\n",
            "00:17:31:120000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"How did it get on the Internet?\"\n",
            "00:17:33:010000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard, Raj. The speaker is Howard. Howard says \"I put it there.\"\n",
            "00:17:35:110000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"How did you know about it?\"\n",
            "00:17:37:040000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Leonard. The speaker is Raj. Raj says \"A little bird told us.\"\n",
            "00:17:39:230000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Leonard. The speaker is Raj. Raj says \"Apparently, you are a magnificent beast.\"\n",
            "00:17:45:130000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"That part's true.\"\n",
            "00:17:51:210000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I think I may have misjudged this restaurant.\"\n",
            "00:17:54:080000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"- No kidding. - I don't want to go out on a limb,\"\n",
            "00:18:00:210000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Your old Tuesday hamburger will be so brokenhearted.\"\n",
            "00:18:05:080000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Way ahead of you. I was thinking of moving Big Boy to Thursdays, and just dropping Souplantation.\"\n",
            "00:18:11:130000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Really?\"\n",
            "00:18:13:010000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"The name always confused me anyway. Souplantation. You can't grow soup.\"\n",
            "00:18:21:080000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"So, how's everything?\"\n",
            "00:18:23:110000. The scene is The Cheesecake Factory.. The recipients are Leonard, Penny. The speaker is Sheldon. Sheldon says \"Terrific. You'll be happy to know that I plan to come here every Tuesday night for the foreseeable future.\"\n",
            "00:18:28:110000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"Really?\"\n",
            "00:18:32:040000. The scene is The Cheesecake Factory.. The recipients are Leonard, Penny. The speaker is Sheldon. Sheldon says \"Who do I speak to about permanently reserving this table?\"\n",
            "00:18:35:230000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"I don't know... A psychiatrist?\"\n",
            "00:18:40:050000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"So, hey, how are things with you and Leslie?\"\n",
            "00:18:45:020000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"To be honest, I don't think it's going to work out.\"\n",
            "00:18:49:050000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"Oh, that's too bad. Hey, don't worry. I'm sure there's someone out there who's just right for you.\"\n",
            "00:18:58:150000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"What did she mean by that?!\"\n",
            "00:19:01:110000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Was that just a generic platitude, or was that a subtle bid for attention?\"\n",
            "00:19:07:160000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"You know why this hamburger surpasses the Big Boy?\"\n",
            "00:19:11:100000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"This is a single-decker hamburger, whereas the Big Boy is a double-decker. This has a much more satisfying meat-to-bun-to-condiment ratio.\"\n",
            "00:19:19:100000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Are you even listening to me?\"\n",
            "00:19:21:050000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Of course, I'm listening. Blah, blah, hopeless Penny delusion...\"\n",
            "00:19:27:140000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Okay, then.\"\n",
            "00:19:31:040000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"You know, you can grow the ingredients for soup.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Document:\n",
        "    def __init__(self, page_content, metadata=None):\n",
        "        self.page_content = page_content\n",
        "        self.metadata = metadata\n",
        "\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Create Document objects from the text chunks\n",
        "documents = [Document(chunk, metadata={\"source\": \"custom_source\"}) for chunk in chunks]\n",
        "\n",
        "# Now you can proceed with creating the vector store\n",
        "vector_store = FAISS.from_documents(documents, embedding=embeddings)"
      ],
      "metadata": {
        "id": "9TkcWcX1nhH5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Import Model\n",
        "llm = LlamaCpp(\n",
        "    streaming = True,\n",
        "    model_path=\"/content/drive/MyDrive/mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
        "    temperature=0.75,\n",
        "    top_p=1,\n",
        "    verbose=True,\n",
        "    n_ctx=4096\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thatOnu1mKmP",
        "outputId": "917c8a5c-e27b-47fe-8b89-b73463213236"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /content/drive/MyDrive/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
            "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
            ".................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 8\n",
            "llama_new_context_with_model: n_ubatch   = 8\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.63 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "1bMngHvW7_Tx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",\n",
        "                                 retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}))\n"
      ],
      "metadata": {
        "id": "ARqoQJCHDFIv"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_verbose\n",
        "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\n",
        "\n",
        "# from langchain.prompts import PromptTemplate\n",
        "set_verbose(True)\n",
        "\n",
        "current_dialogue = \"\"\"Why don't you just have Robert E. Lee charge the line with Shiva and Ganesh?\"\"\"\n",
        "retrieved_chunks = [doc.page_content for doc in qa.retriever.get_relevant_documents(current_dialogue)][1:]\n",
        "context = \"\\n\".join(retrieved_chunks)\n",
        "\n",
        "prompt = f\"\"\"\n",
        "    Pretend you are a humor classification assistant. Is the following dialogue humorous or not.\n",
        "    Dialogue: {current_dialogue}\n",
        "    Your output should be either isHumor: True or isHumor: False.\n",
        "\"\"\"\n",
        "\n",
        "qa.invoke(prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzI5xd7p-gXB",
        "outputId": "f40e915e-40a4-4f83-f6a9-7d8aaf5af2b3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "00:00:26:150000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard. The speaker is Raj. Raj says \"Why don't you just have Robert E. Lee charge the line with Shiva and Ganesh?\"\n",
            "\n",
            "00:00:40:080000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard, Penny. The speaker is Raj. Raj says \"Excuse me. Ganesh is the Remover of Obstacles and Shiva is the Destroyer. When the smoke clears, Abraham Lincoln will be speaking Hindi and drinking mint juleps.\"\n",
            "\n",
            "Question: \n",
            "    Pretend you are a humor classification assistant. Is the following dialogue humorous or not.\n",
            "    Dialogue: Why don't you just have Robert E. Lee charge the line with Shiva and Ganesh?\n",
            "    Your output should be either isHumor: True or isHumor: False.\n",
            "\n",
            "Helpful Answer:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    3431.43 ms\n",
            "llama_print_timings:      sample time =       5.87 ms /    10 runs   (    0.59 ms per token,  1704.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =   33639.13 ms /    72 tokens (  467.21 ms per token,     2.14 tokens per second)\n",
            "llama_print_timings:        eval time =    6722.15 ms /    10 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
            "llama_print_timings:       total time =   40428.13 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': \"\\n    Pretend you are a humor classification assistant. Is the following dialogue humorous or not.\\n    Dialogue: Why don't you just have Robert E. Lee charge the line with Shiva and Ganesh?\\n    Your output should be either isHumor: True or isHumor: False.\\n\",\n",
              " 'result': ' \\n    isHumor: True'}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}