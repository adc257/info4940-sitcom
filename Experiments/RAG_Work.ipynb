{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6SPjUazYNi6",
        "outputId": "ac1e952f-d9f3-48b4-aaca-70bf79547c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'info4940-sitcom'...\n",
            "remote: Enumerating objects: 1122, done.\u001b[K\n",
            "remote: Counting objects: 100% (1122/1122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (202/202), done.\u001b[K\n",
            "remote: Total 1122 (delta 972), reused 1046 (delta 917), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1122/1122), 14.75 MiB | 20.60 MiB/s, done.\n",
            "Resolving deltas: 100% (972/972), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/adc257/info4940-sitcom.git\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEcUjmOKr3HM",
        "outputId": "702d70dd-c803-419b-c3a6-fb877c5734c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: The Big Bang_S0117.json, Number of Humor Dialogues: 102\n",
            "Episode: The Big Bang_S0109.json, Number of Humor Dialogues: 95\n",
            "Episode: The Big Bang_S0115.json, Number of Humor Dialogues: 130\n",
            "Episode: The Big Bang_S0114.json, Number of Humor Dialogues: 97\n",
            "Episode: The Big Bang_S0103.json, Number of Humor Dialogues: 109\n",
            "Episode: The Big Bang_S0111.json, Number of Humor Dialogues: 123\n",
            "Episode: The Big Bang_S0101.json, Number of Humor Dialogues: 125\n",
            "Episode: The Big Bang_S0106.json, Number of Humor Dialogues: 91\n",
            "Episode: The Big Bang_S0104.json, Number of Humor Dialogues: 114\n",
            "Episode: The Big Bang_S0107.json, Number of Humor Dialogues: 126\n",
            "Episode: The Big Bang_S0113.json, Number of Humor Dialogues: 111\n",
            "Episode: The Big Bang_S0112.json, Number of Humor Dialogues: 119\n",
            "Episode: The Big Bang_S0108.json, Number of Humor Dialogues: 116\n",
            "Episode: The Big Bang_S0110.json, Number of Humor Dialogues: 100\n",
            "Episode: The Big Bang_S0116.json, Number of Humor Dialogues: 94\n",
            "Episode: The Big Bang_S0102.json, Number of Humor Dialogues: 97\n",
            "Episode: The Big Bang_S0105.json, Number of Humor Dialogues: 114\n"
          ]
        }
      ],
      "source": [
        "#CODE FOR LATER USE #CODE that extracts all humor dialogues in the whole SEASON 1\n",
        "import os\n",
        "import json\n",
        "\n",
        "root_dir = \"/content/info4940-sitcom/cleaned-data/S1\"\n",
        "episode_humor_data = {}\n",
        "\n",
        "# Iterate over each episode file in the S1 folder\n",
        "for episode_file in os.listdir(root_dir):\n",
        "    episode_path = os.path.join(root_dir, episode_file)\n",
        "    if os.path.isfile(episode_path):\n",
        "        with open(episode_path, 'r') as file:\n",
        "            try:\n",
        "                data = json.load(file)\n",
        "                humor_dialogues = [dialogue for timestamp, dialogue in data.items() if dialogue.get('isHumor', False)]\n",
        "                episode_humor_data[episode_file] = humor_dialogues\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Error decoding JSON from file: {episode_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Unexpected error processing file {episode_path}: {e}\")\n",
        "\n",
        "# Process the humor data for each episode as needed\n",
        "for episode, humor_dialogues in episode_humor_data.items():\n",
        "    print(f\"Episode: {episode}, Number of Humor Dialogues: {len(humor_dialogues)}\")\n",
        "\n",
        "#for dialogue in humor_dialogues[:4]:\n",
        "#        print(dialogue)\n",
        "#        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd6o7Kn45YJd",
        "outputId": "bd35f223-1739-47e9-dfb0-443d86cb7a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted entries saved to /content/info4940-sitcom/episode_5_formatted.txt\n"
          ]
        }
      ],
      "source": [
        "#TASK: Humor detection using rag on S1E5\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "def create_episode_dataset(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        episode_data = json.load(file)\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    for timestamp, dialogue in episode_data.items():\n",
        "        # Add current dialogue and its humor classification to the dataset\n",
        "        dataset.append({\n",
        "            \"episode\": file_path.split('/')[-1],\n",
        "            \"timestamp\": timestamp,\n",
        "            \"scene\": dialogue['Scene'],\n",
        "            \"recipients\": dialogue['Recipients'],\n",
        "            \"speaker\": dialogue['Speaker'],\n",
        "            \"dialogue\": dialogue['Dialogue'],\n",
        "            \"is_joke\": dialogue.get('isHumor', False)\n",
        "        })\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Path to your episode 5 file\n",
        "episode_file = \"/content/info4940-sitcom/cleaned-data/S1/The Big Bang_S0105.json\"\n",
        "episode_dataset = create_episode_dataset(episode_file)\n",
        "\n",
        "# Example: Print the first few entries from the dataset\n",
        "#for entry in episode_dataset[:4]:\n",
        "#    print(entry)\n",
        "\n",
        "#create a textual piece that combines all the scenes and dialogues\n",
        "\n",
        "formatted_entries = []\n",
        "for entry in episode_dataset:\n",
        "    formatted_entry = (\n",
        "        f\"The time is {entry['timestamp']}. \"\n",
        "        f\"The scene is {entry['scene']}. \"\n",
        "        f\"The recipients are {', '.join(entry['recipients'])}. \"\n",
        "        f\"The speaker is {entry['speaker']}. \"\n",
        "        f\"{entry['speaker']} says \\\"{entry['dialogue']}\\\"\\n\"\n",
        "    )\n",
        "    formatted_entries.append(formatted_entry)\n",
        "\n",
        "#save as text file\n",
        "output_file_path = \"/content/info4940-sitcom/episode_5_formatted.txt\"\n",
        "with open(output_file_path, 'w') as file:\n",
        "    for formatted_entry in formatted_entries:\n",
        "        file.write(formatted_entry)\n",
        "\n",
        "print(f\"Formatted entries saved to {output_file_path}\")\n",
        "\n",
        "#for formatted_entry in formatted_entries[:4]:\n",
        "#    print(formatted_entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l23rtr3SRhtU",
        "outputId": "f408f0c9-0695-43e6-8a53-bd074c34c5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "#RAG IMPLEMENTATION ON PREVIOUS CODE CHUNK - formatted_entry\n",
        "\n",
        "#Installing libraries\n",
        "\n",
        "!pip install torch transformers\n",
        "from transformers import T5Tokenizer, T5EncoderModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K9Ac6s1Z1N2"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_KFa9y2s24w"
      },
      "source": [
        "### **LANGCHAIN ATTEMPT**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghdzMfB8h8Cg",
        "outputId": "539a32ae-8f8c-4700-9fa0-ac06d964f88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/817.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/817.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/817.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.46-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.52-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.5 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.46 langchain-text-splitters-0.0.1 langsmith-0.1.52 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 typing-inspect-0.9.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-2.7.0\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.65.tar.gz (38.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.11.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.65-cp310-cp310-linux_x86_64.whl size=3368737 sha256=32691a7e7c0353f748e3127375476d962ab2fa513a3e969e68987a5ee7c93430\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/37/bf/f7c65dbafa5b3845795c23b6634863c1fdf0a9f40678de225e\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.65\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install torch\n",
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install huggingface-hub\n",
        "!pip install pypdf\n",
        "!pip -q install accelerate\n",
        "!pip install llama-cpp-python\n",
        "!pip -q install git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9fWTBCKi0gP"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDQ0O6r9i4cR",
        "outputId": "0dc2bd30-29c1-404e-f62a-0c0a9da2dabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00:00:00:220000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard. The speaker is Sheldon. Sheldon says \"All right! I'm moving my infantry division. Augmented by bataillon of orcs from Lord of the Rings. We flank the Tennessee volunteers and the North, once again, wins the battle of Gettysburg.\"\n",
            "00:00:12:110000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj. The speaker is Howard. Howard says \"Not so fast! Remember, the South still has two infantry divisions, plus Superman and Godzilla.\"\n",
            "00:00:18:100000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard. The speaker is Leonard. Leonard says \"No, orcs are magic. Superman is vulnerable to magic. Not to mention you already lost Godzilla to the Illinois cavalry and Hulk.\"\n",
            "00:00:26:150000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard. The speaker is Raj. Raj says \"Why don't you just have Robert E. Lee charge the line with Shiva and Ganesh?\"\n",
            "00:00:30:200000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"You guys ready to order? \"\n",
            "00:00:33:000000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj. The speaker is Howard. Howard says \"Shiva and Ganesh, the Hindu gods, against the entire Union army?\"\n",
            "00:00:36:220000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard. The speaker is Leonard. Leonard says \"And orcs.\"\n",
            "00:00:38:190000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"I'll be back.\"\n",
            "00:00:40:080000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard, Penny. The speaker is Raj. Raj says \"Excuse me. Ganesh is the Remover of Obstacles and Shiva is the Destroyer. When the smoke clears, Abraham Lincoln will be speaking Hindi and drinking mint juleps.\"\n",
            "00:00:49:040000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"My boss says you have to either order or leave and never come back.\"\n",
            "00:00:53:090000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"What do you recommend for someone who worked up a man-sized appetite from a morning of weight training and cardio funk?\"\n",
            "00:00:58:180000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"A shower.\"\n",
            "00:01:00:200000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"I'll take the Heart Smart platter.\"\n",
            "00:01:03:170000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"All right, thank you, and Sheldon?\"\n",
            "00:01:05:200000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"We don't eat here. I don't know what's good.\"\n",
            "00:01:08:030000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"It's all good. \"\n",
            "00:01:11:180000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Just get a hamburger. You like hamburgers.\"\n",
            "00:01:13:210000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"I like hamburgers where we usually have them. You can't make the assumption that I'll like them here.\"\n",
            "00:01:19:030000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"I'm sorry. Give him a hamburger. \"\n",
            "00:01:20:090000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Which one? The Classic Burger, the Ranch House Burger, the Barbecue Burger, or the Kobe Burger?\"\n",
            "00:01:26:100000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"Can't we just go to Big Boy? They only have one burger... the Big Boy.\"\n",
            "00:01:31:130000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"The Barbecue Burger's like the Big Boy.\"\n",
            "00:01:33:080000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"Excuse me, in a world that already includes a Big Boy, why would I settle for something like a Big Boy?\"\n",
            "00:01:38:060000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Because you're not at Big Boy!\"\n",
            "00:01:41:130000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Make it two.\"\n",
            "00:01:44:060000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"Waitresses don't yell at you at Big Boy.\"\n",
            "00:01:47:140000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny, Lesley. The speaker is Lesley . Lesley  says \"Hey, Leonard. Hi, guys.\"\n",
            "00:01:49:100000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Hi, Leslie.\"\n",
            "00:01:50:150000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"I didn't know you ate here.\"\n",
            "00:01:52:010000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny, Lesley. The speaker is Sheldon. Sheldon says \"We don't. This is a disturbing aberration.\"\n",
            "00:01:54:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Leslie, this is Penny. She lives across the hall from Sheldon and me.\"\n",
            "00:01:57:200000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny, Lesley. The speaker is Howard. Howard says \"And walks in quiet beauty like the night.\"\n",
            "00:02:01:090000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Lesley. The speaker is Penny. Penny says \"Howard, I've asked you not to do that.\"\n",
            "00:02:04:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Leslie and I do research together at the university.\"\n",
            "00:02:07:140000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Lesley. The speaker is Penny. Penny says \"Wow, a girl scientist.\"\n",
            "00:02:09:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"Yep, come for the breasts, stay for the brains.\"\n",
            "00:02:13:070000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"Glad I ran into you. The Physics Department string quartet needs a new cellist.\"\n",
            "00:02:16:220000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"What happened to Elliot Wong?\"\n",
            "00:02:18:110000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"He switched over to high-energy radiation research, had a little mishap, and now the other guys are uncomfortable sitting next to him. You're in?\"\n",
            "00:02:24:180000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Yeah, sure, why not?\"\n",
            "00:02:27:020000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"Great, we rehearse on Tuesdays at your place.\"\n",
            "00:02:29:080000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny, Lesley. The speaker is Leonard. Leonard says \"Why at my place?\"\n",
            "00:02:30:130000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"Department of Energy said our regular space is kind of a hot zone.\"\n",
            "00:02:34:150000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Yeah, you, too. I didn't know you played the cello.\"\n",
            "00:02:39:050000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Yeah, my parents felt that naming me Leonard and putting me in Advanced Placement classes wasn't getting me beaten up enough.\"\n",
            "00:02:46:150000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"If you're into music, I happen to be a human beatbox.\"\n",
            "00:02:49:180000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Really?\"\n",
            "00:02:57:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"I'm actually not that into music.\"\n",
            "00:03:00:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"Your friend's really cute. Anything going on with you two?\"\n",
            "00:03:04:030000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Leslie? No, no. What, are you kidding?\"\n",
            "00:03:06:180000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"He asked her out once. It was an embarrassing failure.\"\n",
            "00:03:11:030000. The scene is The Cheesecake Factory. The recipients are Sheldon, Raj, Howard, Penny. The speaker is Leonard. Leonard says \"Thank you, Sheldon.\"\n",
            "00:03:15:160000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard. The speaker is Penny. Penny says \"That's too bad. You guys'd make a cute couple.\"\n",
            "00:03:20:000000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard, Penny. The speaker is Raj. Raj says \"Oh, dear.\"\n",
            "00:03:21:090000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard, Penny. The speaker is Raj. Raj says \"She didn't take my order.\"\n",
            "00:03:23:120000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Penny. The speaker is Howard. Howard says \"How can she take your order when you're too neurotic to talk to her?\"\n",
            "00:03:27:080000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Howard, Penny. The speaker is Raj. Raj says \"Nevertheless, this will be reflected in her tip.\"\n",
            "00:03:33:120000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"What did Penny mean, You'd make a cute couple?\"\n",
            "00:03:36:110000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I assume she meant the two of you together would constitute a couple that others might consider cute.\"\n",
            "00:03:43:060000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"An alternate and somewhat less likely interpretation is that you could manufacture one.\"\n",
            "00:03:49:060000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"As in, Look, Leonard and Leslie made Mr. and Mrs. Goldfarb. Aren't they adorable?\"\n",
            "00:03:54:130000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"If Penny didn't know that Leslie had turned me down, then it would unambiguously mean that she, Penny, thought I should ask her, Leslie, out, indicating that she had no interest in me asking her, Penny, out. But, because she did know that I had asked Leslie out and that she, Leslie, had turned me down, then she, Penny, could be offering consolation.\"\n",
            "00:04:13:180000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"That's too bad, you would have made a cute couple, but while thinking: Good, Leonard remains available.\"\n",
            "00:04:22:090000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"You're a lucky man, Leonard.\"\n",
            "00:04:26:040000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"How so?\"\n",
            "00:04:32:220000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Well, what do you think?\"\n",
            "00:04:34:130000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I said I could follow it. I didn't say I care.\"\n",
            "00:05:07:210000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"I admire your fingering.\"\n",
            "00:05:10:180000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Thank you.\"\n",
            "00:05:13:110000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Maybe sometime you can try that on my instrument.\"\n",
            "00:05:25:070000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"G'night, guys. Good job.\"\n",
            "00:05:26:230000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley, Leonard. The speaker is Female string quartettist. Female string quartettist says \"See you next week.\"\n",
            "00:05:28:210000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"That was fun. Thanks for including me.\"\n",
            "00:05:35:030000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Sure, why not?\"\n",
            "00:05:42:220000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Just so we're clear, you understand that me hanging back to practice with you is a pretext for letting you know that I'm sexually available.\"\n",
            "00:05:56:130000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Really?\"\n",
            "00:05:57:200000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Yeah, I'm good to go.\"\n",
            "00:06:00:010000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"I thought you weren't interested in me.\"\n",
            "00:06:02:040000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"That was before I saw you handling that beautiful piece of wood between your legs.\"\n",
            "00:06:08:120000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"You mean my cello?\"\n",
            "00:06:10:030000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"No, I mean the obvious, crude, double entendre. I'm seducing you.\"\n",
            "00:06:16:020000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"No kidding.\"\n",
            "00:06:18:090000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"What can I say? I'm a passionate and impulsive woman.\"\n",
            "00:06:22:150000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"So how about it? Is it the waitress?\"\n",
            "00:06:29:110000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"What about her?\"\n",
            "00:06:30:170000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"I thought I saw your pupils dilate when you looked at her. Which, unless you're a heroin addict, points to sexual attraction.\"\n",
            "00:06:37:230000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"I did have a poppy seed bagel for breakfast. Which could cause a positive urine test for opiates, but certainly not dilate my pupils. So I guess there was no point in bringing it up.\"\n",
            "00:06:48:180000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"You and the waitress then.\"\n",
            "00:06:50:170000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"No... no. There's nothing going on between Penny and me.\"\n",
            "00:06:54:230000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"So you're open to a sexual relationship?\"\n",
            "00:06:58:110000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Yeah, yeah, I guess I am.\"\n",
            "00:07:00:110000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Good.\"\n",
            "00:07:07:100000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Why don't we finish the section first?\"\n",
            "00:07:10:150000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"A little musical foreplay. Terrific.\"\n",
            "00:07:34:030000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"I'm good to go.\"\n",
            "00:07:35:090000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Me, too.\"\n",
            "00:07:48:080000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Penny. The speaker is Penny . Penny  says \"Hey, Sheldon. What's going on?\"\n",
            "00:07:50:020000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"I need your opinion on a matter of semiotics.\"\n",
            "00:07:52:210000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"I'm sorry?\"\n",
            "00:07:54:100000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Semiotics. The study of signs and symbols. It's a branch of philosophy related to linguistics.\"\n",
            "00:08:01:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Okay, sweetie, I know you think you're explaing yourself, but you're really not.\"\n",
            "00:08:08:220000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Just come with me.\"\n",
            "00:08:14:230000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Well, what?\"\n",
            "00:08:17:110000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"What does it mean?\"\n",
            "00:08:19:160000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Oh, come on, you went to college.\"\n",
            "00:08:21:200000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Yes, but I was 11.\"\n",
            "00:08:26:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"All right, look, a tie on the doorknob usually means someone doesn't want to be disturbed because, they're... you know, gettin' busy.\"\n",
            "00:08:35:080000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"So you're saying Leonard has a girl in there?\"\n",
            "00:08:37:110000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Well, either that or he's lost his tie rack and gotten really into Bryan Adams.\"\n",
            "00:08:43:070000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Penny. The speaker is Lesley . Lesley  says \"Oh, Leonard, you magnificent beast.\"\n",
            "00:08:48:080000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"We really shouldn't be standing here.\"\n",
            "00:08:52:210000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Penny. The speaker is Sheldon . Sheldon  says \"This is very awkward.\"\n",
            "00:08:54:220000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Oh, come on, Leonard's had girls over before, right?\"\n",
            "00:08:58:180000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Yes, but there's usually planning, courtship, advance notice...\"\n",
            "00:09:03:160000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Last time, I was able to book a cruise to the Arctic to see a solar eclipse.\"\n",
            "00:09:08:230000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"You had to leave the state because your roommate was having sex?\"\n",
            "00:09:12:130000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"I didn't have to. The dates just happened to coincide.\"\n",
            "00:09:18:100000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"So, do you know who's in there?\"\n",
            "00:09:21:140000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"Well, there's Leonard.\"\n",
            "00:09:26:180000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"And he's either with Leslie Winkle or a 1930s gangster.\"\n",
            "00:09:34:090000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"Good for him. Good for Leonard. Okay, g'night.\"\n",
            "00:09:41:060000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"No, no, wait, hold on.\"\n",
            "00:09:42:220000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"What's the matter?\"\n",
            "00:09:44:140000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Penny. The speaker is Sheldon. Sheldon says \"I don't know what the protocol is here.\"\n",
            "00:09:48:060000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Do I stay? Do I leave? Do I wait to greet them with a refreshing beverage?\"\n",
            "00:09:55:200000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"You're asking the wrong girl. I'm usually on the other side of the tie.\"\n",
            "00:10:20:100000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Hi, Leonard?\"\n",
            "00:10:25:000000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"It's me, Sheldon...\"\n",
            "00:10:29:150000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"In the living room. I just... I wanted you to know I saw the tie. Message received.\"\n",
            "00:10:39:080000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"You're welcome.\"\n",
            "00:10:42:100000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"You carry on. Give my best to Leslie.\"\n",
            "00:10:45:000000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Lesley, Leonard. The speaker is -----. ----- says \"Laughing \"\n",
            "00:11:22:030000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Big Boy...\"\n",
            "00:11:48:120000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Someone touched my board.\"\n",
            "00:11:53:210000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Oh, God, my board!\"\n",
            "00:12:01:160000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Leonard . Leonard  says \"Hey, what's the matter?\"\n",
            "00:12:03:110000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"My equations, someone's tampered with my equations.\"\n",
            "00:12:06:000000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Are you sure?\"\n",
            "00:12:12:090000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Oh, yeah. But doesn't that fix the problem you've been having?\"\n",
            "00:12:16:020000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Are you insane? Are you out of your mind? Are you-- Look! That fixes the problem I've been having.\"\n",
            "00:12:23:060000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"You're welcome.\"\n",
            "00:12:26:070000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"You did this?\"\n",
            "00:12:28:230000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"I noticed it when I got up to get a glass of water. So I fixed it. Now you can show that quarks are asymptotically free at high energies. Pretty cool, huh?\"\n",
            "00:12:38:070000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"Cool?\"\n",
            "00:12:40:130000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"Listen, I've got to get to the lab. Thanks for a great night.\"\n",
            "00:12:45:050000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon, Lesley. The speaker is Leonard. Leonard says \"Thank you. I'll see you at work.\"\n",
            "00:12:47:040000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"Hold on. Hold on!\"\n",
            "00:12:49:190000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"What?\"\n",
            "00:12:52:150000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"No one.\"\n",
            "00:12:53:160000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"I don't come into your house and touch your board.\"\n",
            "00:12:56:060000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"There are no incorrect equations on my board.\"\n",
            "00:13:02:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Lesley. The speaker is Sheldon. Sheldon says \"Oh, that is so... so...\"\n",
            "00:13:07:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard, Sheldon. The speaker is Lesley. Lesley says \"Sorry, I've got to run. If you come up with an adjective, text me.\"\n",
            "00:13:14:050000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Inconsiderate. That is the adjective, inconsiderate. \"\n",
            "00:13:19:210000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"You can stare at your board all day. She's still going to be right.\"\n",
            "00:13:22:220000. The scene is The hallway.. The recipients are Leonard, Penny. The speaker is Sheldon. Sheldon says \"I'm not staring, I'm hauling.\"\n",
            "00:13:27:060000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"So... how's it going?\"\n",
            "00:13:33:100000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"Pretty good.\"\n",
            "00:13:35:220000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"Just pretty good? I'd think you were doing very good.\"\n",
            "00:13:40:220000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"Pretty, very... there's really no objective scale for delineating variations of good. Why do you ask?\"\n",
            "00:13:47:050000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"Well, a little bird told me that you and Leslie hooked up last night.\"\n",
            "00:13:56:010000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"So, is it serious? Do you like her?\"\n",
            "00:13:59:020000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"I don't... That's really two different questions. I'm not... Sheldon, we have to go!\"\n",
            "00:14:07:230000. The scene is The hallway.. The recipients are Leonard, Penny. The speaker is Sheldon. Sheldon says \"You're wound awfully tight for a man who's just had sexual intercourse.\"\n",
            "00:14:13:150000. The scene is The hallway.. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"All right, I'll talk to you later, but I am so happy for you.\"\n",
            "00:14:18:190000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Thank you. What did she mean she's happy for me? Is she happy that I'm seeing someone? Or is she happy because she thinks that I am? Because anyone who cared for someone would want them to be happy. Even if the reason for their happiness made the first person unhappy.\"\n",
            "00:14:37:090000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Because the second person, though happy, is now romantically unavailable to the first person.\"\n",
            "00:14:43:060000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Do you realize I may have to share a Nobel Prize with your booty call?\"\n",
            "00:14:50:170000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"You know what? I'm being ridiculous. Who cares what Penny thinks? Leslie is a terrific girl. She's attractive. We like each other. She's extremely intelligent...\"\n",
            "00:15:01:230000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"She's not that intelligent.\"\n",
            "00:15:05:000000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"You don't believe in luck.\"\n",
            "00:15:07:030000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I don't have to believe in it for her to be lucky.\"\n",
            "00:15:10:190000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Regardless, I have a chance at a real relationship with Leslie. I'm not going to pass that up for some hypothetical future of happiness with a woman who may or may not want me to be happy, with a woman who is currently making me happy.\"\n",
            "00:15:25:160000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I still don't care.\"\n",
            "00:15:37:130000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Careful, Leonard. Liquid nitrogen, 320 degrees below zero.\"\n",
            "00:15:49:150000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Why are you smashing a flash-frozen banana?\"\n",
            "00:15:52:070000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Because I got a bowl of Cheerios and I couldn't find a knife.\"\n",
            "00:15:57:110000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"So anyway... Hello.\"\n",
            "00:16:03:200000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"What are you doing?\"\n",
            "00:16:05:220000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Just extending the intimacy. Do you want to slip over to the radiation lab and share a decontamination shower?\"\n",
            "00:16:17:050000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"What exactly do you think's going on between us?\"\n",
            "00:16:21:060000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"I'm not sure, but I think I'm about to discover how the banana felt.\"\n",
            "00:16:29:060000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Listen, neither of us are neuroscientists, but we both understand the biochemistry of sex. I mean, dopamine in our brains is released across synapses, causing pleasure. You stick electrodes in a rat's brain, give him an orgasm button, he'll push that thing until he starves to death.\"\n",
            "00:16:43:110000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Well, who wouldn't?\"\n",
            "00:16:45:080000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Well, the only difference between us and the rat is that you can't stick an electrode in our hypothalamus. That's where you come in.\"\n",
            "00:16:53:140000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Yeah, well, I'm just glad to be a part of it.\"\n",
            "00:16:57:170000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"So what happens now?\"\n",
            "00:16:59:020000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"I don't know about your sex drive, but I'm probably good till New Year's.\"\n",
            "00:17:08:050000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Thank you.\"\n",
            "00:17:13:070000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"You want to make plans for New Year's?\"\n",
            "00:17:15:040000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Please. You're smothering me.\"\n",
            "00:17:19:180000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard, Raj. The speaker is Howard. Howard says \"Look. It's Dr. Stud!\"\n",
            "00:17:23:100000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"Dr. What?\"\n",
            "00:17:24:150000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard, Raj. The speaker is Howard. Howard says \"The blogosphere is a-buzzin' with news of you and Leslie Winkle making eine kleine bang-bang musik.\"\n",
            "00:17:31:120000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"How did it get on the Internet?\"\n",
            "00:17:33:010000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard, Raj. The speaker is Howard. Howard says \"I put it there.\"\n",
            "00:17:35:110000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"How did you know about it?\"\n",
            "00:17:37:040000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Leonard. The speaker is Raj. Raj says \"A little bird told us.\"\n",
            "00:17:39:230000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Leonard. The speaker is Raj. Raj says \"Apparently, you are a magnificent beast.\"\n",
            "00:17:45:130000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"That part's true.\"\n",
            "00:17:51:210000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"I think I may have misjudged this restaurant.\"\n",
            "00:17:54:080000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"- No kidding. - I don't want to go out on a limb,\"\n",
            "00:18:00:210000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Your old Tuesday hamburger will be so brokenhearted.\"\n",
            "00:18:05:080000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Way ahead of you. I was thinking of moving Big Boy to Thursdays, and just dropping Souplantation.\"\n",
            "00:18:11:130000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Really?\"\n",
            "00:18:13:010000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"The name always confused me anyway. Souplantation. You can't grow soup.\"\n",
            "00:18:21:080000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"So, how's everything?\"\n",
            "00:18:23:110000. The scene is The Cheesecake Factory.. The recipients are Leonard, Penny. The speaker is Sheldon. Sheldon says \"Terrific. You'll be happy to know that I plan to come here every Tuesday night for the foreseeable future.\"\n",
            "00:18:28:110000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"Really?\"\n",
            "00:18:32:040000. The scene is The Cheesecake Factory.. The recipients are Leonard, Penny. The speaker is Sheldon. Sheldon says \"Who do I speak to about permanently reserving this table?\"\n",
            "00:18:35:230000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"I don't know... A psychiatrist?\"\n",
            "00:18:40:050000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"So, hey, how are things with you and Leslie?\"\n",
            "00:18:45:020000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"To be honest, I don't think it's going to work out.\"\n",
            "00:18:49:050000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Leonard. The speaker is Penny. Penny says \"Oh, that's too bad. Hey, don't worry. I'm sure there's someone out there who's just right for you.\"\n",
            "00:18:58:150000. The scene is The Cheesecake Factory.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"What did she mean by that?!\"\n",
            "00:19:01:110000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Was that just a generic platitude, or was that a subtle bid for attention?\"\n",
            "00:19:07:160000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"You know why this hamburger surpasses the Big Boy?\"\n",
            "00:19:11:100000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"This is a single-decker hamburger, whereas the Big Boy is a double-decker. This has a much more satisfying meat-to-bun-to-condiment ratio.\"\n",
            "00:19:19:100000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Are you even listening to me?\"\n",
            "00:19:21:050000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Of course, I'm listening. Blah, blah, hopeless Penny delusion...\"\n",
            "00:19:27:140000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Okay, then.\"\n",
            "00:19:31:040000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"You know, you can grow the ingredients for soup.\"\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/info4940-sitcom/episode_5_formatted.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split the text content based on \"The time is\"\n",
        "chunks = text.split(\"The time is\")\n",
        "chunks = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
        "\n",
        "# Print out the resulting chunks\n",
        "for chunk in chunks:\n",
        "    print(chunk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "dc2583b8d98c4a9a84de4a55df7eb213",
            "de08df75dd7444a6ae7b7f1681f41e25",
            "a17932a9c97f4ca38c6a1d44347f876e",
            "c2d3ef9dc25a4d2ba739d16b4a428e82",
            "5cbb34a9f15d410d87780bf467204818",
            "c2e61ac3bbc743369812910c7f1a9786",
            "a79e6e8b8e1d4c8b961f89b97a0b9a3d",
            "51cd3246310f4ebdb6dd8595404595f7",
            "f4a911f0477a46da9295795972038c51",
            "49b88074634e41589642809a24c601aa",
            "e8c5f4f3e15e4637917dddbb94387c13",
            "8169d5aedd624987b3b7419699a3c591",
            "b680e38830134d86bdda56d5575e8476",
            "e6f53479438344788902ccee4455db0b",
            "72430ed20f7e43cea21de3707580a798",
            "e618f7c6974b49a48a6dc09781d51ae6",
            "818e012547744980b2ff5adc358d70bc",
            "3e76b5b8e0a64266a8ad290826ce47bc",
            "b610955208434a27bf5b7696a90e7743",
            "261385358bf34a4a8a7b039ed527c911",
            "0544a9ef7bde4454887e7a25c59bef41",
            "cc2b50b63ac54ea5960ea8438c784027",
            "87e8f581fb1a42c0ba9c1e1b3360970a",
            "bcf25931506a47aa842e171fa4fb9451",
            "cdcc1983de8042558cee968c8b1a5e1d",
            "ce4e5321930b430489c024c1f5d52835",
            "96d8e44c26024f9baea68eea609e8b6a",
            "aa71e9af55e349d9b3ddba49f74dc706",
            "f27be08a60c04a8687095c578b17fac1",
            "5207036509f246b1a6f08ad6397b76b5",
            "dac664cc0c9543c4a37ad008e5fa9fb3",
            "d7a2462be02343b19a460d50d3db7d3c",
            "554422d893214085879d7022777e9bcc",
            "e66a345d67924f57bc541831f18a0fc9",
            "08bfaf697b2e4187aa76761eedc578fe",
            "3c59bf699b48494ca8c6c20df7269316",
            "73d3f42eebba46f5a56f0dbc181f3bd4",
            "761f75f1434f46618ae9a6b77d8ad0ea",
            "0620ce3850eb4c46a89bc8bd414e6d81",
            "56265e0cba9f4301964193c3e588cc19",
            "7cdc21a258464eee94e45ca63f7ecfd0",
            "112417cc4ec946fda0a637201ae2103b",
            "455ef55f35be413382eaac906823200f",
            "7e26b08fc10c4b669cd62baf950758ee",
            "cf801805a6b84cc99230f7dbede5fb86",
            "48bd9b3a28cc4d14bc4952ac9f887e57",
            "669d3790625c40db9b4d648e195d9ba4",
            "64ad0b0bb0a641f29f03f22ca31fb8ef",
            "840ad6169e514c71addb62613143b5fb",
            "adc73f8dc13944e299cad73500daaf33",
            "bc55e106a2184a2e97365fd0f4f792fd",
            "729ea6f94b7943cfa7eddda57dc723e0",
            "d1d3d701e078446da6d899c978c1e1ff",
            "c977a7e0cf6d4d8a9351842914acc636",
            "4cb1490f22704fe3877ce9d11ee16086",
            "a4e3cd70f7a2425c9b6a1983d1e7f1d9",
            "3be74ea7881c4bc78fa13b7b7e54ed50",
            "581b492c32924ff5bd8c0150c4a84369",
            "0635f7f497d344e09332215a038d8f64",
            "0acde0c799884942b8d01e9d57f200fa",
            "12e8e3d16a3248debc7685768ec80955",
            "4cfaf64529b147e892f4b9341191bcfa",
            "16cdfb10622e4f8f9c5342d18d45c16e",
            "b45a8491af854a2d98e46d4f30ef429a",
            "b730fa6fc26440a19f30a2263d5c17ac",
            "f8fc0bfbac92406ca0dd57bce2f128aa",
            "dad1403f92f2435abfa3b02e4301791a",
            "5f27550658964e16aedc509e2ba22caa",
            "395929e14a044aefac6b4579c5646b8c",
            "1ed7e70e0e834a2495e687970d5d9589",
            "14bd88e855f5401f81bb3fb491c27ce1",
            "e2bca6aea8c5454a8e8dd0186251527e",
            "9f33f9f00755459bb0ffe1cc7ad6fe39",
            "5fdad808c4054cf5bc30d290a8825251",
            "7aec731d4e84447c9042172abb1e1a6f",
            "4a4fb25fb3cf42679b2acb79eed79286",
            "2c24fb6ebeb345249a1509fa44e39efd",
            "04bed6f03f62416fb04a6dfb62d9b30f",
            "41ca13ea59ce4d27bb1d6db23c77fd69",
            "730b459a89d94b4a85eb60e935342af4",
            "6fe2b6282aa640219a7848b009df7432",
            "2eb6adee4e134dd699b7bea4793b79a6",
            "aff3f19dc82f44e5ac5c69c595307a75",
            "8257185e87ff4195afc85f666fde8616",
            "3626de066c94416da77dd157bac6b180",
            "247e4d8708fa41aa844f1010229b6cf7",
            "1fb3ed5d0e0a49f19d90eb05c95dddb7",
            "6c390bbdf28b46d1a42e3e4dafd5b3a4",
            "98e3596756b541339fd609c2491095a3",
            "fdf260e098044425b07167487a39efbd",
            "8a962fe0336f443cb666b05d374c95ef",
            "87b6d2674b79435da211bd166049b8eb",
            "47d0ff6c8d2e4970a4a75bbbe8b03c7d",
            "8206026963f6497f83e870c5e52a1508",
            "ad8eb0df7c3b436eb76399cb802faa81",
            "e0790db2667c45ea9799c4be7598447a",
            "7994fb9fd66443a18585234bd1129faf",
            "ff8a6e55c5a0461e969630a464bee0ff",
            "fa121c15ea4d4318a8af9b0f942237ed",
            "f264850d7353445bba622026498c7d07",
            "9596c3a11bda43198a9d874a4badd55b",
            "3dcbe74fe48f4ddfba021aac5ebfaf00",
            "17aecfdbb7784b8a9cfa4f44a6e773ec",
            "fc26f860940741298164852270e744a1",
            "c63caab2c3ad48a78369f733aab1388a",
            "bc4fffd534db4479bcde248fd32edd41",
            "f1ef450f2ba548258bbb5ab5a0ded239",
            "c240bd7b0757426dbadb4481dd575001",
            "ddafb609e15e4145956c4bbdecc3b4ab",
            "3aa06823cf9540d383abfeeea9d23d85",
            "8ef69ff77a8a4e7bbd3b5a5c06aae89b",
            "6eef1054b3ed48da953a816a5136b891",
            "8474bafbd9a1454caac38a75e5fee5e2",
            "7203798c2c504cdc892a757ddd290091",
            "e7b201022b5043ec8e146d6554568af7",
            "913492face674de3a847de96a02e19ec",
            "32e0c3756d754e34aa7e7d228e4b54d0",
            "51bd207594154983a8e7fefbfdbf0cae",
            "56986e2e4d914eac9ba338aff2d3d882",
            "c0bb9bb358704eb4ab209b5ef6eab583",
            "a0baef9851de4341aa708082cd9bedae"
          ]
        },
        "id": "9TkcWcX1nhH5",
        "outputId": "4b59a6e3-3e63-4608-8ceb-e0577eb25379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc2583b8d98c4a9a84de4a55df7eb213"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8169d5aedd624987b3b7419699a3c591"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87e8f581fb1a42c0ba9c1e1b3360970a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e66a345d67924f57bc541831f18a0fc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf801805a6b84cc99230f7dbede5fb86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4e3cd70f7a2425c9b6a1983d1e7f1d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dad1403f92f2435abfa3b02e4301791a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04bed6f03f62416fb04a6dfb62d9b30f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98e3596756b541339fd609c2491095a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f264850d7353445bba622026498c7d07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ef69ff77a8a4e7bbd3b5a5c06aae89b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "class Document:\n",
        "    def __init__(self, page_content, metadata=None):\n",
        "        self.page_content = page_content\n",
        "        self.metadata = metadata\n",
        "\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "#embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create Document objects from the text chunks\n",
        "documents = [Document(chunk, metadata={\"source\": \"custom_source\"}) for chunk in chunks]\n",
        "\n",
        "# Now you can proceed with creating the vector store\n",
        "vector_store = FAISS.from_documents(documents, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c2WRviG-N5E",
        "outputId": "2ca3bfab-92cf-4338-8d2b-d3aa9f488968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<__main__.Document object at 0x7b66a9b89db0>, <__main__.Document object at 0x7b66a9b88250>, <__main__.Document object at 0x7b667f8c2a40>, <__main__.Document object at 0x7b667f8c2d70>, <__main__.Document object at 0x7b667f8c3e50>, <__main__.Document object at 0x7b667f8c2ce0>, <__main__.Document object at 0x7b667f8c33a0>, <__main__.Document object at 0x7b667f8c2bf0>, <__main__.Document object at 0x7b667f8c2b90>, <__main__.Document object at 0x7b667f8c3790>, <__main__.Document object at 0x7b667caadde0>, <__main__.Document object at 0x7b667caadd80>, <__main__.Document object at 0x7b667caae200>, <__main__.Document object at 0x7b667caae290>, <__main__.Document object at 0x7b667caae2f0>, <__main__.Document object at 0x7b667caae3e0>, <__main__.Document object at 0x7b667caad5d0>, <__main__.Document object at 0x7b667caadb40>, <__main__.Document object at 0x7b667caada80>, <__main__.Document object at 0x7b667caad1e0>, <__main__.Document object at 0x7b667caad150>, <__main__.Document object at 0x7b667caad570>, <__main__.Document object at 0x7b667caad600>, <__main__.Document object at 0x7b667caad990>, <__main__.Document object at 0x7b667caadc30>, <__main__.Document object at 0x7b667caadba0>, <__main__.Document object at 0x7b667caad9c0>, <__main__.Document object at 0x7b667caadd50>, <__main__.Document object at 0x7b667caadb10>, <__main__.Document object at 0x7b667caadf00>, <__main__.Document object at 0x7b667caadf60>, <__main__.Document object at 0x7b667caaec80>, <__main__.Document object at 0x7b667caaceb0>, <__main__.Document object at 0x7b667caafa90>, <__main__.Document object at 0x7b667caaee00>, <__main__.Document object at 0x7b667caae650>, <__main__.Document object at 0x7b667caafe80>, <__main__.Document object at 0x7b667caaf730>, <__main__.Document object at 0x7b667caafbe0>, <__main__.Document object at 0x7b667caaf640>, <__main__.Document object at 0x7b667caaf7c0>, <__main__.Document object at 0x7b667caaf9a0>, <__main__.Document object at 0x7b667caaf7f0>, <__main__.Document object at 0x7b667caaee90>, <__main__.Document object at 0x7b667caaf970>, <__main__.Document object at 0x7b667caafe50>, <__main__.Document object at 0x7b667caafb50>, <__main__.Document object at 0x7b667caafeb0>, <__main__.Document object at 0x7b667caaff10>, <__main__.Document object at 0x7b667caaff40>, <__main__.Document object at 0x7b667caaffd0>, <__main__.Document object at 0x7b667caaea10>, <__main__.Document object at 0x7b667caae6e0>, <__main__.Document object at 0x7b667caaeb90>, <__main__.Document object at 0x7b667caad240>, <__main__.Document object at 0x7b667caaee30>, <__main__.Document object at 0x7b667caaf1c0>, <__main__.Document object at 0x7b667caaeb30>, <__main__.Document object at 0x7b667caaef50>, <__main__.Document object at 0x7b667caaf490>, <__main__.Document object at 0x7b667caaf3d0>, <__main__.Document object at 0x7b667caaf460>, <__main__.Document object at 0x7b667caaf2b0>, <__main__.Document object at 0x7b66802027d0>, <__main__.Document object at 0x7b667cb2c040>, <__main__.Document object at 0x7b667cb2c0d0>, <__main__.Document object at 0x7b667cb2c130>, <__main__.Document object at 0x7b667cb2c190>, <__main__.Document object at 0x7b667cb2c1f0>, <__main__.Document object at 0x7b667cb2c250>, <__main__.Document object at 0x7b667cb2c2b0>, <__main__.Document object at 0x7b667cb2c310>, <__main__.Document object at 0x7b667cb2c370>, <__main__.Document object at 0x7b667cb2c3d0>, <__main__.Document object at 0x7b667cb2c430>, <__main__.Document object at 0x7b667cb2c490>, <__main__.Document object at 0x7b667cb2c4f0>, <__main__.Document object at 0x7b667cb2c550>, <__main__.Document object at 0x7b667cb2c5b0>, <__main__.Document object at 0x7b667cb2c610>, <__main__.Document object at 0x7b667cb2c670>, <__main__.Document object at 0x7b667cb2c6d0>, <__main__.Document object at 0x7b667cb2c730>, <__main__.Document object at 0x7b667cb2c790>, <__main__.Document object at 0x7b667cb2c7f0>, <__main__.Document object at 0x7b667cb2c850>, <__main__.Document object at 0x7b667cb2c8b0>, <__main__.Document object at 0x7b667cb2c910>, <__main__.Document object at 0x7b667cb2c970>, <__main__.Document object at 0x7b667cb2c9d0>, <__main__.Document object at 0x7b667cb2ca30>, <__main__.Document object at 0x7b667cb2ca90>, <__main__.Document object at 0x7b667cb2caf0>, <__main__.Document object at 0x7b667cb2cb50>, <__main__.Document object at 0x7b667cb2cbb0>, <__main__.Document object at 0x7b667cb2cc10>, <__main__.Document object at 0x7b667cb2cc70>, <__main__.Document object at 0x7b667cb2ccd0>, <__main__.Document object at 0x7b667cb2cd30>, <__main__.Document object at 0x7b667cb2cd90>, <__main__.Document object at 0x7b667cb2cdf0>, <__main__.Document object at 0x7b667cb2ce50>, <__main__.Document object at 0x7b667cb2ceb0>, <__main__.Document object at 0x7b667cb2cf10>, <__main__.Document object at 0x7b667cb2cf70>, <__main__.Document object at 0x7b667cb2cfd0>, <__main__.Document object at 0x7b667cb2d030>, <__main__.Document object at 0x7b667cb2d090>, <__main__.Document object at 0x7b667cb2d0f0>, <__main__.Document object at 0x7b667cb2d150>, <__main__.Document object at 0x7b667cb2d1b0>, <__main__.Document object at 0x7b667cb2d210>, <__main__.Document object at 0x7b667cb2d270>, <__main__.Document object at 0x7b667cb2d2d0>, <__main__.Document object at 0x7b667cb2d330>, <__main__.Document object at 0x7b667cb2d390>, <__main__.Document object at 0x7b667cb2d3f0>, <__main__.Document object at 0x7b667cb2d450>, <__main__.Document object at 0x7b667cb2d4b0>, <__main__.Document object at 0x7b667cb2d510>, <__main__.Document object at 0x7b667cb2d570>, <__main__.Document object at 0x7b667cb2d5d0>, <__main__.Document object at 0x7b667cb2d630>, <__main__.Document object at 0x7b667cb2d690>, <__main__.Document object at 0x7b667cb2d6f0>, <__main__.Document object at 0x7b667cb2d750>, <__main__.Document object at 0x7b667cb2d7b0>, <__main__.Document object at 0x7b667cb2d810>, <__main__.Document object at 0x7b667cb2d870>, <__main__.Document object at 0x7b667cb2d8d0>, <__main__.Document object at 0x7b667cb2d930>, <__main__.Document object at 0x7b667cb2d990>, <__main__.Document object at 0x7b667cb2d9f0>, <__main__.Document object at 0x7b667cb2da50>, <__main__.Document object at 0x7b667cb2dab0>, <__main__.Document object at 0x7b667cb2db10>, <__main__.Document object at 0x7b667cb2db70>, <__main__.Document object at 0x7b667cb2dbd0>, <__main__.Document object at 0x7b667cb2dc30>, <__main__.Document object at 0x7b667cb2dc90>, <__main__.Document object at 0x7b667cb2dcf0>, <__main__.Document object at 0x7b667cb2dd50>, <__main__.Document object at 0x7b667cb2ddb0>, <__main__.Document object at 0x7b667caaea40>, <__main__.Document object at 0x7b667caaecb0>, <__main__.Document object at 0x7b667caaed40>, <__main__.Document object at 0x7b667caaef20>, <__main__.Document object at 0x7b667caaeef0>, <__main__.Document object at 0x7b667caaeb00>, <__main__.Document object at 0x7b667caaeb60>, <__main__.Document object at 0x7b667caac220>, <__main__.Document object at 0x7b667caac1c0>, <__main__.Document object at 0x7b667caac190>, <__main__.Document object at 0x7b667caac130>, <__main__.Document object at 0x7b667f8c2d40>, <__main__.Document object at 0x7b667f8c3400>, <__main__.Document object at 0x7b667f8c2e60>, <__main__.Document object at 0x7b667f8c2bc0>, <__main__.Document object at 0x7b667f8c2ad0>, <__main__.Document object at 0x7b667f8c05b0>, <__main__.Document object at 0x7b667f8c0550>, <__main__.Document object at 0x7b667f8c04f0>, <__main__.Document object at 0x7b667f8c03a0>, <__main__.Document object at 0x7b667f8c0070>, <__main__.Document object at 0x7b667f8c1b10>, <__main__.Document object at 0x7b667cb2de40>, <__main__.Document object at 0x7b667cb2dea0>, <__main__.Document object at 0x7b667cb2df00>, <__main__.Document object at 0x7b667cb2df60>, <__main__.Document object at 0x7b667cb2dfc0>, <__main__.Document object at 0x7b667cb2e020>, <__main__.Document object at 0x7b667cb2e080>, <__main__.Document object at 0x7b667cb2e0e0>, <__main__.Document object at 0x7b667cb2e140>, <__main__.Document object at 0x7b667cb2e1a0>, <__main__.Document object at 0x7b667cb2e200>, <__main__.Document object at 0x7b667cb2e260>, <__main__.Document object at 0x7b667cb2e2c0>, <__main__.Document object at 0x7b667cb2e320>, <__main__.Document object at 0x7b667cb2e380>, <__main__.Document object at 0x7b667cb2e3e0>, <__main__.Document object at 0x7b667cb2e440>, <__main__.Document object at 0x7b667cb2e4a0>, <__main__.Document object at 0x7b667cb2e500>, <__main__.Document object at 0x7b667cb2e560>, <__main__.Document object at 0x7b667cb2e5c0>, <__main__.Document object at 0x7b667cb2e620>, <__main__.Document object at 0x7b667cb2e680>, <__main__.Document object at 0x7b667cb2e6e0>, <__main__.Document object at 0x7b667cb2e740>, <__main__.Document object at 0x7b667cb2e7a0>, <__main__.Document object at 0x7b667cb2e800>, <__main__.Document object at 0x7b667cb2e860>, <__main__.Document object at 0x7b667cb2e8c0>, <__main__.Document object at 0x7b667cb2e920>, <__main__.Document object at 0x7b667cb2e980>, <__main__.Document object at 0x7b667cb2e9e0>, <__main__.Document object at 0x7b667cb2ea40>, <__main__.Document object at 0x7b667cb2eaa0>, <__main__.Document object at 0x7b667cb2eb00>, <__main__.Document object at 0x7b667cb2eb60>, <__main__.Document object at 0x7b667cb2ebc0>, <__main__.Document object at 0x7b667cb2ec20>, <__main__.Document object at 0x7b667cb2ec80>, <__main__.Document object at 0x7b667cb2ece0>, <__main__.Document object at 0x7b667cb2ed40>, <__main__.Document object at 0x7b667cb2eda0>, <__main__.Document object at 0x7b667cb2ee00>, <__main__.Document object at 0x7b667cb2ee60>, <__main__.Document object at 0x7b667cb2eec0>, <__main__.Document object at 0x7b667cb2ef20>, <__main__.Document object at 0x7b667cb2ef80>, <__main__.Document object at 0x7b667cb2efe0>, <__main__.Document object at 0x7b667cb2f040>, <__main__.Document object at 0x7b667cb2f0a0>, <__main__.Document object at 0x7b667cb2f100>, <__main__.Document object at 0x7b667cb2f160>, <__main__.Document object at 0x7b667cb2f1c0>, <__main__.Document object at 0x7b667cb2f220>, <__main__.Document object at 0x7b667cb2f280>, <__main__.Document object at 0x7b667cb2f2e0>, <__main__.Document object at 0x7b667cb2f340>]\n"
          ]
        }
      ],
      "source": [
        "print(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thatOnu1mKmP",
        "outputId": "65264a27-3ca9-40d8-f67f-442cd1fd3e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /content/drive/MyDrive/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
            ".................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 8\n",
            "llama_new_context_with_model: n_ubatch   = 8\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.63 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LAMMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Import Model\n",
        "llm = LlamaCpp(\n",
        "    streaming = True,\n",
        "    model_path=\"/content/drive/MyDrive/mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
        "    temperature=0.75,\n",
        "    top_p=1,\n",
        "    verbose=True,\n",
        "    n_ctx=4096\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bMngHvW7_Tx",
        "outputId": "5359983c-1e5e-4872-cb7e-0c8094da6542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-openai\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "import getpass\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing if the model even works at all\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "set_verbose(True)\n",
        "template = \"\"\"<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not.\n",
        "Evaluate the dialogue below from context below. Explain your reason. Output should be in the format of \"isHumor: True/False\" or \"Explanation:\".\n",
        "\n",
        "Context: {context}\n",
        "Dialogue: {dialogue}\n",
        "[/INST] </s>\n",
        "\"\"\"\n",
        "\n",
        "def generate_response(dialogue, context):\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"dialogue\", \"context\"])\n",
        "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "  response = llm_chain.run({\"dialogue\":dialogue, \"context\":context})\n",
        "  return response\n",
        "\n",
        "generate_response(\"\"\"Of course, I'm listening. Blah, blah, hopeless Penny delusion...\"\"\",\n",
        "\"\"\"00:08:01:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently. The recipients are Sheldon. The speaker is Penny. Penny says \"Okay, sweetie, I know you think you're explaining yourself, but you're really not.\"\n",
        "00:13:56:010000. The scene is The hallway. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"So, is it serious? Do you like her?\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "57bfelaRgtOr",
        "outputId": "56935363-1fbf-4d8f-87d7-680829508efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. Explain your reason. Output should be in the format of \"isHumor: True/False\" or \"Explanation:\".\n",
            "\n",
            "Context: 00:08:01:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently. The recipients are Sheldon. The speaker is Penny. Penny says \"Okay, sweetie, I know you think you're explaining yourself, but you're really not.\"\n",
            "00:13:56:010000. The scene is The hallway. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"So, is it serious? Do you like her?\n",
            "Dialogue: Of course, I'm listening. Blah, blah, hopeless Penny delusion...\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-7849743858e2>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m generate_response(\"\"\"Of course, I'm listening. Blah, blah, hopeless Penny delusion...\"\"\", \n\u001b[0m\u001b[1;32m     20\u001b[0m \"\"\"00:08:01:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently. The recipients are Sheldon. The speaker is Penny. Penny says \"Okay, sweetie, I know you think you're explaining yourself, but you're really not.\"\n\u001b[1;32m     21\u001b[0m 00:13:56:010000. The scene is The hallway. The recipients are Leonard, Sheldon. The speaker is Penny. Penny says \"So, is it serious? Do you like her?\"\"\")\n",
            "\u001b[0;32m<ipython-input-62-7849743858e2>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(dialogue, context)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dialogue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mllm_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"dialogue\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdialogue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"context\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    570\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    376\u001b[0m         }\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    379\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             outputs = (\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    632\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 )\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[0;32m--> 803\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    804\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             output = (\n\u001b[0;32m--> 657\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    658\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             text = (\n\u001b[0;32m-> 1317\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/llamacpp.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;31m# and return the combined strings from the first choices's text:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mcombined_text_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             for chunk in self._stream(\n\u001b[0m\u001b[1;32m    289\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/llamacpp.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             chunk = GenerationChunk(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36m_create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0mfinish_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"length\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0mmultibyte_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         for token in self.generate(\n\u001b[0m\u001b[1;32m   1037\u001b[0m             \u001b[0mprompt_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;31m# Eval and sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 token = self.sample(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             )\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0;31m# Save tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_past\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mn_past\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/_internals.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         return_code = llama_cpp.llama_decode(\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97yTmti7pjTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#second option for evaluation\n",
        "\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Load episode data\n",
        "episode_file = \"/content/info4940-sitcom/cleaned-data/S1/The Big Bang_S0105.json\"\n",
        "with open(episode_file, 'r') as file:\n",
        "    episode_data = json.load(file)\n",
        "\n",
        "# Check and sample 10 from each, ensure enough data is present\n",
        "if len(humorous) >= 10 and len(not_humorous) >= 10:\n",
        "    random.shuffle(humorous)\n",
        "    random.shuffle(not_humorous)\n",
        "    balanced_dataset = [(True, dialogue) for dialogue in humorous[:10]] + [(False, dialogue) for dialogue in not_humorous[:10]]\n",
        "    humorous_dataset = [(True, dialogue) for dialogue in humorous[:20]]\n",
        "    not_humorous_dataset = [(False, dialogue) for dialogue in not_humorous[:10]]\n",
        "    random.shuffle(balanced_dataset)  # Shuffle to mix humorous and non-humorous dialogues\n",
        "    random.shuffle(humorous_dataset)\n",
        "    random.shuffle(not_humorous_dataset)\n",
        "else:\n",
        "    print(\"Not enough data to sample 10 from each category.\")\n",
        "    # Handle error or exit\n",
        "\n",
        "# Print dataset size\n",
        "print(f\"Dataset size: {len(humorous_dataset)}\")\n",
        "\n",
        "set_verbose(True)\n",
        "template = \"\"\"<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not.\n",
        "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
        "\n",
        "\n",
        "Context: {context}\n",
        "Dialogue: {dialogue}\n",
        "[/INST] </s>\n",
        "\"\"\"\n",
        "\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "def generate_response(dialogue):\n",
        "    # Use retriever to get context\n",
        "    context_documents = retriever.get_relevant_documents(dialogue)\n",
        "    # Filter out the exact dialogue from the context\n",
        "    filtered_documents = context_documents[1:3]\n",
        "    context = \"\\n\".join([doc.page_content for doc in filtered_documents])\n",
        "\n",
        "\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"dialogue\", \"context\"])\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=llm)  # Assuming 'llm' is already defined\n",
        "    response = llm_chain.run({\"dialogue\": dialogue, \"context\": context})\n",
        "    return response\n",
        "\n",
        "import re\n",
        "def extract_classification_and_compare(response_string, actual_is_humorous):\n",
        "    # Updated regex to handle 'true', 'false' in both lowercase and uppercase, and possibly quoted\n",
        "    match = re.search(r'(Classification|isHumor):\\s*\"?(true|false|True|False)\"?', response_string, re.IGNORECASE)\n",
        "    if match:\n",
        "        predicted_is_humorous = match.group(2).lower() == 'true'\n",
        "    else:\n",
        "        predicted_is_humorous = False\n",
        "    is_correct = predicted_is_humorous == actual_is_humorous\n",
        "    return is_correct\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "# Loop over balanced dataset and evaluate each dialogue\n",
        "for is_humorous, dialogue in humorous_dataset:\n",
        "    predicted_humor = generate_response(dialogue)\n",
        "    print(type(predicted_humor))\n",
        "\n",
        "    actual_label = \"Humorous\" if is_humorous else \"Not Humorous\"\n",
        "\n",
        "    print(f\"Predicted: {predicted_humor}\")\n",
        "    print(f\"Actual: {actual_label}\\n\")\n",
        "\n",
        "    # Call the classification extraction and comparison function\n",
        "    is_correct_or_not = extract_classification_and_compare(predicted_humor, is_humorous)\n",
        "    print(\"Prediction Correct:\", is_correct_or_not)  # Print the correctness of each prediction\n",
        "\n",
        "    if is_correct_or_not:\n",
        "        correct_predictions += 1\n",
        "    total_predictions += 1\n",
        "\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "\n",
        "# Output the metrics\n",
        "print(f\"\\nCorrect Predictions: {correct_predictions}\")\n",
        "print(f\"Total Predictions: {total_predictions}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zeT3cJaqEcJ",
        "outputId": "98157cb2-94a0-4e0f-eb68-93897780f248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 20\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:13:14:050000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Inconsiderate. That is the adjective, inconsiderate. \"\n",
            "00:13:40:220000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"Pretty, very... there's really no objective scale for delineating variations of good. Why do you ask?\"\n",
            "Dialogue: Sorry, I've got to run. If you come up with an adjective, text me.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      33.12 ms /    57 runs   (    0.58 ms per token,  1721.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =   42815.85 ms /   189 tokens (  226.54 ms per token,     4.41 tokens per second)\n",
            "llama_print_timings:        eval time =    5611.07 ms /    56 runs   (  100.20 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =   19848.09 ms /   245 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: ```json\n",
            "{\n",
            "  \"Classification\": \"False\",\n",
            "  \"Explanation\": \"The dialogue does not seem to be humorous. It is a brief and straightforward exchange between two characters discussing the meaning of an adjective.\"\n",
            "}\n",
            "```\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:17:31:120000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"How did it get on the Internet?\"\n",
            "00:16:21:060000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"I'm not sure, but I think I'm about to discover how the banana felt.\"\n",
            "Dialogue: How did you know about it?\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      54.77 ms /    93 runs   (    0.59 ms per token,  1698.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10620.20 ms /   130 tokens (   81.69 ms per token,    12.24 tokens per second)\n",
            "llama_print_timings:        eval time =    9695.73 ms /    92 runs   (  105.39 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =   20715.61 ms /   222 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": \"isHumor: True\",\n",
            "\"Explanation\": \"The dialogue is humorous because Leonard is making a reference to a previous incident in which they discovered that a banana was being used to conduct research on the internet. The punchline of 'I'm not sure, but I think I'm about to discover how the banana felt' adds an unexpected twist and humor to the situation.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: True\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:15:01:230000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"She's not that intelligent.\"\n",
            "00:15:05:000000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"You don't believe in luck.\"\n",
            "Dialogue: Well, there's Leonard.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      23.55 ms /    42 runs   (    0.56 ms per token,  1783.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6164.99 ms /   109 tokens (   56.56 ms per token,    17.68 tokens per second)\n",
            "llama_print_timings:        eval time =    4622.07 ms /    41 runs   (  112.73 ms per token,     8.87 tokens per second)\n",
            "llama_print_timings:       total time =   10978.70 ms /   150 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": False,\n",
            "\"Explanation\": \"The dialogue is not funny as it does not contain any humor elements such as punchlines, wit or satire.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:11:22:030000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Big Boy...\"\n",
            "00:01:26:100000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"Can't we just go to Big Boy? They only have one burger... the Big Boy.\"\n",
            "Dialogue: Big Boy...\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      31.25 ms /    54 runs   (    0.58 ms per token,  1728.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8770.36 ms /   152 tokens (   57.70 ms per token,    17.33 tokens per second)\n",
            "llama_print_timings:        eval time =    5855.67 ms /    53 runs   (  110.48 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =   14877.15 ms /   205 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": false,\n",
            "\"Explanation\": \"The dialogue provided lacks context and is not sufficient to determine if it is humorous or not. More information about the situation and characters involved would be needed to accurately classify the humor.\"\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:08:26:010000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Sheldon. The speaker is Penny. Penny says \"All right, look, a tie on the doorknob usually means someone doesn't want to be disturbed because, they're... you know, gettin' busy.\"\n",
            "00:14:07:230000. The scene is The hallway.. The recipients are Leonard, Penny. The speaker is Sheldon. Sheldon says \"You're wound awfully tight for a man who's just had sexual intercourse.\"\n",
            "Dialogue: Well, either that or he's lost his tie rack and gotten really into Bryan Adams.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      48.90 ms /    82 runs   (    0.60 ms per token,  1677.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =   14265.56 ms /   195 tokens (   73.16 ms per token,    13.67 tokens per second)\n",
            "llama_print_timings:        eval time =    8705.94 ms /    81 runs   (  107.48 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =   23349.15 ms /   276 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: ```json\n",
            "{\n",
            "    \"Classification\": false,\n",
            "    \"Explanation\": \"The dialogue is not humorously intended as it touches on a serious matter of sexual intercourse and the speaker does not provide any humorous commentary or context to make it so. The mention of Bryan Adams is also unrelated to the topic and serves no comedic purpose.\"\n",
            "}\n",
            "```\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:16:29:060000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Listen, neither of us are neuroscientists, but we both understand the biochemistry of sex. I mean, dopamine in our brains is released across synapses, causing pleasure. You stick electrodes in a rat's brain, give him an orgasm button, he'll push that thing until he starves to death.\"\n",
            "00:12:03:110000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"My equations, someone's tampered with my equations.\"\n",
            "Dialogue: Okay, sweetie, I know you think you're explaing yourself, but you're really not.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      27.39 ms /    48 runs   (    0.57 ms per token,  1752.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =   16151.87 ms /   228 tokens (   70.84 ms per token,    14.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4709.33 ms /    47 runs   (  100.20 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =   21117.32 ms /   275 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: ```json\n",
            "{\n",
            "    \"Classification\": False,\n",
            "    \"Explanation\": \"The dialogue is not humorous as it is a serious conversation between two people discussing a matter of concern.\"\n",
            "}\n",
            "```\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:17:23:100000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"Dr. What?\"\n",
            "00:03:49:060000. The scene is The stairwell of the apartment building.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"As in, Look, Leonard and Leslie made Mr. and Mrs. Goldfarb. Aren't they adorable?\"\n",
            "Dialogue: Look. It's Dr. Stud!\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      32.79 ms /    56 runs   (    0.59 ms per token,  1707.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10843.82 ms /   136 tokens (   79.73 ms per token,    12.54 tokens per second)\n",
            "llama_print_timings:        eval time =    5747.82 ms /    56 runs   (  102.64 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =   16851.37 ms /   192 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": \"isHumor: True\",\n",
            "\"Explanation\": \"The dialogue is humorous because it uses a play on words where 'Dr. Stud' sounds like 'Dr. Who', a popular science fiction television series.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: True\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:17:08:050000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Thank you.\"\n",
            "00:17:15:040000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Please. You're smothering me.\"\n",
            "Dialogue: Thank you.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      33.16 ms /    58 runs   (    0.57 ms per token,  1749.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8159.69 ms /   108 tokens (   75.55 ms per token,    13.24 tokens per second)\n",
            "llama_print_timings:        eval time =    6148.88 ms /    57 runs   (  107.88 ms per token,     9.27 tokens per second)\n",
            "llama_print_timings:       total time =   14564.13 ms /   165 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: ```json\n",
            "{\n",
            "    \"Classification\": false,\n",
            "    \"Explanation\": \"The dialogue 'Thank you.' is not humorous in this context. It is a polite response to gratitude or favor, which does not elicit humor.\"\n",
            "}\n",
            "```\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:16:29:060000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Listen, neither of us are neuroscientists, but we both understand the biochemistry of sex. I mean, dopamine in our brains is released across synapses, causing pleasure. You stick electrodes in a rat's brain, give him an orgasm button, he'll push that thing until he starves to death.\"\n",
            "00:06:18:090000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"What can I say? I'm a passionate and impulsive woman.\"\n",
            "Dialogue: How can she take your order when you're too neurotic to talk to her?\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      27.38 ms /    46 runs   (    0.60 ms per token,  1680.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =   17189.08 ms /   207 tokens (   83.04 ms per token,    12.04 tokens per second)\n",
            "llama_print_timings:        eval time =    4520.58 ms /    45 runs   (  100.46 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =   21950.18 ms /   252 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": False,\n",
            "\"Explanation\": \"The dialogue is not humorous as it is discussing a serious matter about Leonard's anxiety and his difficulty in communicating with Lesley.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:06:08:120000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"You mean my cello?\"\n",
            "00:07:10:150000. The scene is The apartment living room. The string quartet are practising.. The recipients are Lesley. The speaker is Leonard. Leonard says \"A little musical foreplay. Terrific.\"\n",
            "Dialogue: Maybe sometime you can try that on my instrument.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      72.86 ms /   122 runs   (    0.60 ms per token,  1674.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10406.70 ms /   128 tokens (   81.30 ms per token,    12.30 tokens per second)\n",
            "llama_print_timings:        eval time =   12841.56 ms /   122 runs   (  105.26 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =   23775.91 ms /   250 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": false,\n",
            "\"Explanation\": \"The dialogue between Leonard and Lesley is not necessarily humorous as it lacks any explicit joke or punchline. The context of the scene suggests that the string quartet is rehearsing, and Leonard is suggesting some sort of musical collaboration with Lesley. While the phrase 'musical foreplay' might be interpreted as a flirty or suggestive comment, it doesn't necessarily elicit laughter. Additionally, there isn't any clear indication in the dialogue that the audience should find humor in this exchange.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:15:49:150000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Why are you smashing a flash-frozen banana?\"\n",
            "00:01:13:210000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"I like hamburgers where we usually have them. You can't make the assumption that I'll like them here.\"\n",
            "Dialogue: I'm not sure, but I think I'm about to discover how the banana felt.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      35.82 ms /    61 runs   (    0.59 ms per token,  1702.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12561.12 ms /   165 tokens (   76.13 ms per token,    13.14 tokens per second)\n",
            "llama_print_timings:        eval time =    6045.78 ms /    60 runs   (  100.76 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =   18895.70 ms /   225 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": \"False\",\n",
            "\"Explanation\": \"The dialogue is not humorous because it lacks any clear comedic element or punchline. It seems to be a thoughtful observation made by Leonard, but it does not elicit laughter from the audience.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:13:40:220000. The scene is The hallway.. The recipients are Sheldon, Penny. The speaker is Leonard. Leonard says \"Pretty, very... there's really no objective scale for delineating variations of good. Why do you ask?\"\n",
            "00:05:57:200000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Yeah, I'm good to go.\"\n",
            "Dialogue: Just pretty good? I'd think you were doing very good.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      21.85 ms /    38 runs   (    0.57 ms per token,  1739.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11548.69 ms /   146 tokens (   79.10 ms per token,    12.64 tokens per second)\n",
            "llama_print_timings:        eval time =    3705.99 ms /    37 runs   (  100.16 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =   15448.84 ms /   183 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": false,\n",
            "\"Explanation\": \"The dialogue is not humorous as it is a serious conversation about Leonard's performance in school.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:01:26:100000. The scene is The Cheesecake Factory. The recipients are Leonard, Raj, Howard, Penny. The speaker is Sheldon. Sheldon says \"Can't we just go to Big Boy? They only have one burger... the Big Boy.\"\n",
            "00:19:07:160000. The scene is The Cheesecake Factory.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"You know why this hamburger surpasses the Big Boy?\"\n",
            "Dialogue: This is a single-decker hamburger, whereas the Big Boy is a double-decker. This has a much more satisfying meat-to-bun-to-condiment ratio.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      35.24 ms /    62 runs   (    0.57 ms per token,  1759.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =   13654.93 ms /   183 tokens (   74.62 ms per token,    13.40 tokens per second)\n",
            "llama_print_timings:        eval time =    6772.62 ms /    61 runs   (  111.03 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =   20725.59 ms /   244 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: ```json\n",
            "{\n",
            "    \"Classification\": false,\n",
            "    \"Explanation\": \"The dialogue may not be humorous as it is discussing the differences between two hamburgers and their meat-to-bun-to-condiment ratios.\"\n",
            "}\n",
            "```\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:02:18:110000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"He switched over to high-energy radiation research, had a little mishap, and now the other guys are uncomfortable sitting next to him. You're in?\"\n",
            "00:00:33:000000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj. The speaker is Howard. Howard says \"Shiva and Ganesh, the Hindu gods, against the entire Union army?\"\n",
            "Dialogue: What?\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      72.56 ms /   124 runs   (    0.59 ms per token,  1708.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12327.05 ms /   160 tokens (   77.04 ms per token,    12.98 tokens per second)\n",
            "llama_print_timings:        eval time =   13172.98 ms /   124 runs   (  106.23 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =   26056.56 ms /   284 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: ```json\n",
            "{\n",
            "    \"Classification\": \"isHumor: True\",\n",
            "    \"Explanation\": \"The dialogue is humorous because it uses exaggerated and over-the-top language to express surprise, making a reference to the popular sitcom \"The Big Bang Theory\". The use of phrases like 'mishap' and 'comfortable sitting next to him' are also part of the show's humor. Additionally, the question is phrased in a way that makes it sound like it's a legitimate question, adding to the humor.\"\n",
            "}\n",
            "```\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: True\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:04:32:220000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Well, what do you think?\"\n",
            "00:10:20:100000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are . The speaker is Sheldon. Sheldon says \"Hi, Leonard?\"\n",
            "Dialogue: Hi, Leonard?\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      23.18 ms /    41 runs   (    0.57 ms per token,  1769.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10866.63 ms /   132 tokens (   82.32 ms per token,    12.15 tokens per second)\n",
            "llama_print_timings:        eval time =    4037.77 ms /    40 runs   (  100.94 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =   15105.60 ms /   172 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: ```json\n",
            "{\n",
            "    \"Classification\": false,\n",
            "    \"Explanation\": \"The dialogue does not seem to be humorous in the given context.\"\n",
            "}\n",
            "```\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:14:50:170000. The scene is The hallway.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"You know what? I'm being ridiculous. Who cares what Penny thinks? Leslie is a terrific girl. She's attractive. We like each other. She's extremely intelligent...\"\n",
            "00:03:54:130000. The scene is The stairwell of the apartment building.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"If Penny didn't know that Leslie had turned me down, then it would unambiguously mean that she, Penny, thought I should ask her, Leslie, out, indicating that she had no interest in me asking her, Penny, out. But, because she did know that I had asked Leslie out and that she, Leslie, had turned me down, then she, Penny, could be offering consolation.\"\n",
            "Dialogue: Regardless, I have a chance at a real relationship with Leslie. I'm not going to pass that up for some hypothetical future of happiness with a woman who may or may not want me to be happy, with a woman who is currently making me happy.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      20.11 ms /    35 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =   19153.13 ms /   280 tokens (   68.40 ms per token,    14.62 tokens per second)\n",
            "llama_print_timings:        eval time =    4089.01 ms /    35 runs   (  116.83 ms per token,     8.56 tokens per second)\n",
            "llama_print_timings:       total time =   23474.52 ms /   315 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": \"isHumor: False\",\n",
            "\"Explanation\": \"The dialogue is serious and emotional rather than humorous.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:02:18:110000. The scene is The Cheesecake Factory. The recipients are Sheldon, Leonard, Raj, Howard, Penny. The speaker is Lesley. Lesley says \"He switched over to high-energy radiation research, had a little mishap, and now the other guys are uncomfortable sitting next to him. You're in?\"\n",
            "00:12:16:020000. The scene is The hallway, Sheldon scuttles out of apartment door and crosses to Penny’s. Knocks on it urgently.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"Are you insane? Are you out of your mind? Are you-- Look! That fixes the problem I've been having.\"\n",
            "Dialogue: I noticed it when I got up to get a glass of water. So I fixed it. Now you can show that quarks are asymptotically free at high energies. Pretty cool, huh?\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      60.40 ms /   101 runs   (    0.60 ms per token,  1672.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =   16363.99 ms /   231 tokens (   70.84 ms per token,    14.12 tokens per second)\n",
            "llama_print_timings:        eval time =   10740.43 ms /   100 runs   (  107.40 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =   27582.02 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": \"isHumor: True\",\n",
            "\"Explanation\": \"The dialogue is humorous because of its casual and informal tone, the use of technical language related to physics, and the unexpected twist that the problem Sheldon was having has been fixed. The audience can relate to the idea of fixing something with a simple solution and the humor comes from the contrast between the seriousness of high-energy radiation research and the simplicity of the fix.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: True\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:17:31:120000. The scene is Leonard and Lesley’s lab.. The recipients are Howard, Raj. The speaker is Leonard. Leonard says \"How did it get on the Internet?\"\n",
            "00:16:05:220000. The scene is Leonard and Lesley’s lab.. The recipients are Lesley. The speaker is Leonard. Leonard says \"Just extending the intimacy. Do you want to slip over to the radiation lab and share a decontamination shower?\"\n",
            "Dialogue: I don't know what the protocol is here.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      22.61 ms /    38 runs   (    0.59 ms per token,  1680.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11106.22 ms /   138 tokens (   80.48 ms per token,    12.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3748.70 ms /    37 runs   (  101.32 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =   15047.57 ms /   175 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": false,\n",
            "\"Explanation\": \"This dialogue does not have any humor in it as it lacks any punchline or unexpected twist.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:16:29:060000. The scene is Leonard and Lesley’s lab.. The recipients are Leonard. The speaker is Lesley. Lesley says \"Listen, neither of us are neuroscientists, but we both understand the biochemistry of sex. I mean, dopamine in our brains is released across synapses, causing pleasure. You stick electrodes in a rat's brain, give him an orgasm button, he'll push that thing until he starves to death.\"\n",
            "00:06:54:230000. The scene is The apartment living room. The string quartet are practising.. The recipients are Leonard. The speaker is Lesley. Lesley says \"So you're open to a sexual relationship?\"\n",
            "Dialogue: Just so we're clear, you understand that me hanging back to practice with you is a pretext for letting you know that I'm sexually available.\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      35.37 ms /    60 runs   (    0.59 ms per token,  1696.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =   16963.46 ms /   215 tokens (   78.90 ms per token,    12.67 tokens per second)\n",
            "llama_print_timings:        eval time =    6620.38 ms /    59 runs   (  112.21 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =   23889.37 ms /   274 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: ```json\n",
            "{\n",
            "    \"Classification\": false,\n",
            "    \"Explanation\": \"The dialogue is not humorous as it deals with serious and potentially inappropriate topics. It is more of a suggestive or flirty statement than a joke.\"\n",
            "}\n",
            "```\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m<s>[INST] You are a humor/joke classification assistant for a sitcom show. You will be provided a dialogue from a sitcom and you must analyze whether it is humorous or not. \n",
            "Evaluate the dialogue below from context below. For the classification, you must output `isHumor: True` if you think the dialogue is funny or `isHumor: False`. Return the 'Classification' (isHumor = True or isHumor = False) and 'Explanation' in JSON format.\n",
            "\n",
            "\n",
            "Context: 00:15:01:230000. The scene is The hallway.. The recipients are Leonard. The speaker is Sheldon. Sheldon says \"She's not that intelligent.\"\n",
            "00:19:19:100000. The scene is The Cheesecake Factory.. The recipients are Sheldon. The speaker is Leonard. Leonard says \"Are you even listening to me?\"\n",
            "Dialogue: It's me, Sheldon...\n",
            "[/INST] </s>\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3030.02 ms\n",
            "llama_print_timings:      sample time =      21.66 ms /    38 runs   (    0.57 ms per token,  1754.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6533.61 ms /   114 tokens (   57.31 ms per token,    17.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4213.97 ms /    37 runs   (  113.89 ms per token,     8.78 tokens per second)\n",
            "llama_print_timings:       total time =   10931.54 ms /   151 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "<class 'str'>\n",
            "Predicted: {\n",
            "\"Classification\": False,\n",
            "\"Explanation\": \"The dialogue provided does not contain any humor or jokes. It is simply a conversation between two characters.\"\n",
            "}\n",
            "Actual: Humorous\n",
            "\n",
            "Prediction Correct: False\n",
            "\n",
            "Correct Predictions: 4\n",
            "Total Predictions: 20\n",
            "Accuracy: 0.20\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc2583b8d98c4a9a84de4a55df7eb213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de08df75dd7444a6ae7b7f1681f41e25",
              "IPY_MODEL_a17932a9c97f4ca38c6a1d44347f876e",
              "IPY_MODEL_c2d3ef9dc25a4d2ba739d16b4a428e82"
            ],
            "layout": "IPY_MODEL_5cbb34a9f15d410d87780bf467204818"
          }
        },
        "de08df75dd7444a6ae7b7f1681f41e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e61ac3bbc743369812910c7f1a9786",
            "placeholder": "​",
            "style": "IPY_MODEL_a79e6e8b8e1d4c8b961f89b97a0b9a3d",
            "value": "modules.json: 100%"
          }
        },
        "a17932a9c97f4ca38c6a1d44347f876e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51cd3246310f4ebdb6dd8595404595f7",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4a911f0477a46da9295795972038c51",
            "value": 349
          }
        },
        "c2d3ef9dc25a4d2ba739d16b4a428e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49b88074634e41589642809a24c601aa",
            "placeholder": "​",
            "style": "IPY_MODEL_e8c5f4f3e15e4637917dddbb94387c13",
            "value": " 349/349 [00:00&lt;00:00, 30.3kB/s]"
          }
        },
        "5cbb34a9f15d410d87780bf467204818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e61ac3bbc743369812910c7f1a9786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79e6e8b8e1d4c8b961f89b97a0b9a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51cd3246310f4ebdb6dd8595404595f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a911f0477a46da9295795972038c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49b88074634e41589642809a24c601aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8c5f4f3e15e4637917dddbb94387c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8169d5aedd624987b3b7419699a3c591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b680e38830134d86bdda56d5575e8476",
              "IPY_MODEL_e6f53479438344788902ccee4455db0b",
              "IPY_MODEL_72430ed20f7e43cea21de3707580a798"
            ],
            "layout": "IPY_MODEL_e618f7c6974b49a48a6dc09781d51ae6"
          }
        },
        "b680e38830134d86bdda56d5575e8476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_818e012547744980b2ff5adc358d70bc",
            "placeholder": "​",
            "style": "IPY_MODEL_3e76b5b8e0a64266a8ad290826ce47bc",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "e6f53479438344788902ccee4455db0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b610955208434a27bf5b7696a90e7743",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_261385358bf34a4a8a7b039ed527c911",
            "value": 116
          }
        },
        "72430ed20f7e43cea21de3707580a798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0544a9ef7bde4454887e7a25c59bef41",
            "placeholder": "​",
            "style": "IPY_MODEL_cc2b50b63ac54ea5960ea8438c784027",
            "value": " 116/116 [00:00&lt;00:00, 10.9kB/s]"
          }
        },
        "e618f7c6974b49a48a6dc09781d51ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "818e012547744980b2ff5adc358d70bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e76b5b8e0a64266a8ad290826ce47bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b610955208434a27bf5b7696a90e7743": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261385358bf34a4a8a7b039ed527c911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0544a9ef7bde4454887e7a25c59bef41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc2b50b63ac54ea5960ea8438c784027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87e8f581fb1a42c0ba9c1e1b3360970a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcf25931506a47aa842e171fa4fb9451",
              "IPY_MODEL_cdcc1983de8042558cee968c8b1a5e1d",
              "IPY_MODEL_ce4e5321930b430489c024c1f5d52835"
            ],
            "layout": "IPY_MODEL_96d8e44c26024f9baea68eea609e8b6a"
          }
        },
        "bcf25931506a47aa842e171fa4fb9451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa71e9af55e349d9b3ddba49f74dc706",
            "placeholder": "​",
            "style": "IPY_MODEL_f27be08a60c04a8687095c578b17fac1",
            "value": "README.md: 100%"
          }
        },
        "cdcc1983de8042558cee968c8b1a5e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5207036509f246b1a6f08ad6397b76b5",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dac664cc0c9543c4a37ad008e5fa9fb3",
            "value": 10659
          }
        },
        "ce4e5321930b430489c024c1f5d52835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7a2462be02343b19a460d50d3db7d3c",
            "placeholder": "​",
            "style": "IPY_MODEL_554422d893214085879d7022777e9bcc",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 997kB/s]"
          }
        },
        "96d8e44c26024f9baea68eea609e8b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa71e9af55e349d9b3ddba49f74dc706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f27be08a60c04a8687095c578b17fac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5207036509f246b1a6f08ad6397b76b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac664cc0c9543c4a37ad008e5fa9fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7a2462be02343b19a460d50d3db7d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "554422d893214085879d7022777e9bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e66a345d67924f57bc541831f18a0fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08bfaf697b2e4187aa76761eedc578fe",
              "IPY_MODEL_3c59bf699b48494ca8c6c20df7269316",
              "IPY_MODEL_73d3f42eebba46f5a56f0dbc181f3bd4"
            ],
            "layout": "IPY_MODEL_761f75f1434f46618ae9a6b77d8ad0ea"
          }
        },
        "08bfaf697b2e4187aa76761eedc578fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0620ce3850eb4c46a89bc8bd414e6d81",
            "placeholder": "​",
            "style": "IPY_MODEL_56265e0cba9f4301964193c3e588cc19",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "3c59bf699b48494ca8c6c20df7269316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cdc21a258464eee94e45ca63f7ecfd0",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_112417cc4ec946fda0a637201ae2103b",
            "value": 53
          }
        },
        "73d3f42eebba46f5a56f0dbc181f3bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455ef55f35be413382eaac906823200f",
            "placeholder": "​",
            "style": "IPY_MODEL_7e26b08fc10c4b669cd62baf950758ee",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.82kB/s]"
          }
        },
        "761f75f1434f46618ae9a6b77d8ad0ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0620ce3850eb4c46a89bc8bd414e6d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56265e0cba9f4301964193c3e588cc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cdc21a258464eee94e45ca63f7ecfd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "112417cc4ec946fda0a637201ae2103b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "455ef55f35be413382eaac906823200f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e26b08fc10c4b669cd62baf950758ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf801805a6b84cc99230f7dbede5fb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48bd9b3a28cc4d14bc4952ac9f887e57",
              "IPY_MODEL_669d3790625c40db9b4d648e195d9ba4",
              "IPY_MODEL_64ad0b0bb0a641f29f03f22ca31fb8ef"
            ],
            "layout": "IPY_MODEL_840ad6169e514c71addb62613143b5fb"
          }
        },
        "48bd9b3a28cc4d14bc4952ac9f887e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc73f8dc13944e299cad73500daaf33",
            "placeholder": "​",
            "style": "IPY_MODEL_bc55e106a2184a2e97365fd0f4f792fd",
            "value": "config.json: 100%"
          }
        },
        "669d3790625c40db9b4d648e195d9ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_729ea6f94b7943cfa7eddda57dc723e0",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1d3d701e078446da6d899c978c1e1ff",
            "value": 612
          }
        },
        "64ad0b0bb0a641f29f03f22ca31fb8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c977a7e0cf6d4d8a9351842914acc636",
            "placeholder": "​",
            "style": "IPY_MODEL_4cb1490f22704fe3877ce9d11ee16086",
            "value": " 612/612 [00:00&lt;00:00, 58.9kB/s]"
          }
        },
        "840ad6169e514c71addb62613143b5fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc73f8dc13944e299cad73500daaf33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc55e106a2184a2e97365fd0f4f792fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "729ea6f94b7943cfa7eddda57dc723e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d3d701e078446da6d899c978c1e1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c977a7e0cf6d4d8a9351842914acc636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb1490f22704fe3877ce9d11ee16086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4e3cd70f7a2425c9b6a1983d1e7f1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3be74ea7881c4bc78fa13b7b7e54ed50",
              "IPY_MODEL_581b492c32924ff5bd8c0150c4a84369",
              "IPY_MODEL_0635f7f497d344e09332215a038d8f64"
            ],
            "layout": "IPY_MODEL_0acde0c799884942b8d01e9d57f200fa"
          }
        },
        "3be74ea7881c4bc78fa13b7b7e54ed50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12e8e3d16a3248debc7685768ec80955",
            "placeholder": "​",
            "style": "IPY_MODEL_4cfaf64529b147e892f4b9341191bcfa",
            "value": "model.safetensors: 100%"
          }
        },
        "581b492c32924ff5bd8c0150c4a84369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16cdfb10622e4f8f9c5342d18d45c16e",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b45a8491af854a2d98e46d4f30ef429a",
            "value": 90868376
          }
        },
        "0635f7f497d344e09332215a038d8f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b730fa6fc26440a19f30a2263d5c17ac",
            "placeholder": "​",
            "style": "IPY_MODEL_f8fc0bfbac92406ca0dd57bce2f128aa",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 232MB/s]"
          }
        },
        "0acde0c799884942b8d01e9d57f200fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e8e3d16a3248debc7685768ec80955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cfaf64529b147e892f4b9341191bcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16cdfb10622e4f8f9c5342d18d45c16e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b45a8491af854a2d98e46d4f30ef429a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b730fa6fc26440a19f30a2263d5c17ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fc0bfbac92406ca0dd57bce2f128aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dad1403f92f2435abfa3b02e4301791a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f27550658964e16aedc509e2ba22caa",
              "IPY_MODEL_395929e14a044aefac6b4579c5646b8c",
              "IPY_MODEL_1ed7e70e0e834a2495e687970d5d9589"
            ],
            "layout": "IPY_MODEL_14bd88e855f5401f81bb3fb491c27ce1"
          }
        },
        "5f27550658964e16aedc509e2ba22caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2bca6aea8c5454a8e8dd0186251527e",
            "placeholder": "​",
            "style": "IPY_MODEL_9f33f9f00755459bb0ffe1cc7ad6fe39",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "395929e14a044aefac6b4579c5646b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdad808c4054cf5bc30d290a8825251",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aec731d4e84447c9042172abb1e1a6f",
            "value": 350
          }
        },
        "1ed7e70e0e834a2495e687970d5d9589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a4fb25fb3cf42679b2acb79eed79286",
            "placeholder": "​",
            "style": "IPY_MODEL_2c24fb6ebeb345249a1509fa44e39efd",
            "value": " 350/350 [00:00&lt;00:00, 34.7kB/s]"
          }
        },
        "14bd88e855f5401f81bb3fb491c27ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2bca6aea8c5454a8e8dd0186251527e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f33f9f00755459bb0ffe1cc7ad6fe39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fdad808c4054cf5bc30d290a8825251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aec731d4e84447c9042172abb1e1a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a4fb25fb3cf42679b2acb79eed79286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c24fb6ebeb345249a1509fa44e39efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04bed6f03f62416fb04a6dfb62d9b30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41ca13ea59ce4d27bb1d6db23c77fd69",
              "IPY_MODEL_730b459a89d94b4a85eb60e935342af4",
              "IPY_MODEL_6fe2b6282aa640219a7848b009df7432"
            ],
            "layout": "IPY_MODEL_2eb6adee4e134dd699b7bea4793b79a6"
          }
        },
        "41ca13ea59ce4d27bb1d6db23c77fd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff3f19dc82f44e5ac5c69c595307a75",
            "placeholder": "​",
            "style": "IPY_MODEL_8257185e87ff4195afc85f666fde8616",
            "value": "vocab.txt: 100%"
          }
        },
        "730b459a89d94b4a85eb60e935342af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3626de066c94416da77dd157bac6b180",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_247e4d8708fa41aa844f1010229b6cf7",
            "value": 231508
          }
        },
        "6fe2b6282aa640219a7848b009df7432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fb3ed5d0e0a49f19d90eb05c95dddb7",
            "placeholder": "​",
            "style": "IPY_MODEL_6c390bbdf28b46d1a42e3e4dafd5b3a4",
            "value": " 232k/232k [00:00&lt;00:00, 7.32MB/s]"
          }
        },
        "2eb6adee4e134dd699b7bea4793b79a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff3f19dc82f44e5ac5c69c595307a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8257185e87ff4195afc85f666fde8616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3626de066c94416da77dd157bac6b180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "247e4d8708fa41aa844f1010229b6cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fb3ed5d0e0a49f19d90eb05c95dddb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c390bbdf28b46d1a42e3e4dafd5b3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98e3596756b541339fd609c2491095a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdf260e098044425b07167487a39efbd",
              "IPY_MODEL_8a962fe0336f443cb666b05d374c95ef",
              "IPY_MODEL_87b6d2674b79435da211bd166049b8eb"
            ],
            "layout": "IPY_MODEL_47d0ff6c8d2e4970a4a75bbbe8b03c7d"
          }
        },
        "fdf260e098044425b07167487a39efbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8206026963f6497f83e870c5e52a1508",
            "placeholder": "​",
            "style": "IPY_MODEL_ad8eb0df7c3b436eb76399cb802faa81",
            "value": "tokenizer.json: 100%"
          }
        },
        "8a962fe0336f443cb666b05d374c95ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0790db2667c45ea9799c4be7598447a",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7994fb9fd66443a18585234bd1129faf",
            "value": 466247
          }
        },
        "87b6d2674b79435da211bd166049b8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff8a6e55c5a0461e969630a464bee0ff",
            "placeholder": "​",
            "style": "IPY_MODEL_fa121c15ea4d4318a8af9b0f942237ed",
            "value": " 466k/466k [00:00&lt;00:00, 3.52MB/s]"
          }
        },
        "47d0ff6c8d2e4970a4a75bbbe8b03c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8206026963f6497f83e870c5e52a1508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8eb0df7c3b436eb76399cb802faa81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0790db2667c45ea9799c4be7598447a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7994fb9fd66443a18585234bd1129faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff8a6e55c5a0461e969630a464bee0ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa121c15ea4d4318a8af9b0f942237ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f264850d7353445bba622026498c7d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9596c3a11bda43198a9d874a4badd55b",
              "IPY_MODEL_3dcbe74fe48f4ddfba021aac5ebfaf00",
              "IPY_MODEL_17aecfdbb7784b8a9cfa4f44a6e773ec"
            ],
            "layout": "IPY_MODEL_fc26f860940741298164852270e744a1"
          }
        },
        "9596c3a11bda43198a9d874a4badd55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c63caab2c3ad48a78369f733aab1388a",
            "placeholder": "​",
            "style": "IPY_MODEL_bc4fffd534db4479bcde248fd32edd41",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3dcbe74fe48f4ddfba021aac5ebfaf00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ef450f2ba548258bbb5ab5a0ded239",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c240bd7b0757426dbadb4481dd575001",
            "value": 112
          }
        },
        "17aecfdbb7784b8a9cfa4f44a6e773ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddafb609e15e4145956c4bbdecc3b4ab",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa06823cf9540d383abfeeea9d23d85",
            "value": " 112/112 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "fc26f860940741298164852270e744a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c63caab2c3ad48a78369f733aab1388a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc4fffd534db4479bcde248fd32edd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ef450f2ba548258bbb5ab5a0ded239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c240bd7b0757426dbadb4481dd575001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddafb609e15e4145956c4bbdecc3b4ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa06823cf9540d383abfeeea9d23d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ef69ff77a8a4e7bbd3b5a5c06aae89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6eef1054b3ed48da953a816a5136b891",
              "IPY_MODEL_8474bafbd9a1454caac38a75e5fee5e2",
              "IPY_MODEL_7203798c2c504cdc892a757ddd290091"
            ],
            "layout": "IPY_MODEL_e7b201022b5043ec8e146d6554568af7"
          }
        },
        "6eef1054b3ed48da953a816a5136b891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_913492face674de3a847de96a02e19ec",
            "placeholder": "​",
            "style": "IPY_MODEL_32e0c3756d754e34aa7e7d228e4b54d0",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "8474bafbd9a1454caac38a75e5fee5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51bd207594154983a8e7fefbfdbf0cae",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56986e2e4d914eac9ba338aff2d3d882",
            "value": 190
          }
        },
        "7203798c2c504cdc892a757ddd290091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0bb9bb358704eb4ab209b5ef6eab583",
            "placeholder": "​",
            "style": "IPY_MODEL_a0baef9851de4341aa708082cd9bedae",
            "value": " 190/190 [00:00&lt;00:00, 15.8kB/s]"
          }
        },
        "e7b201022b5043ec8e146d6554568af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913492face674de3a847de96a02e19ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e0c3756d754e34aa7e7d228e4b54d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51bd207594154983a8e7fefbfdbf0cae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56986e2e4d914eac9ba338aff2d3d882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0bb9bb358704eb4ab209b5ef6eab583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0baef9851de4341aa708082cd9bedae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}