{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adc257/info4940-sitcom/blob/main/0nContext_LLAMA_Attempting_flipping_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U-WsE7AlB33",
        "outputId": "a256b000-ba49-4180-848c-d4e7e2118976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X6d94esWlNn7"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "import random\n",
        "import json\n",
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiCa_A65lKVN",
        "outputId": "17adafe4-7a8f-4c4c-84ba-56cafb5fe991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'info4940-sitcom'...\n",
            "remote: Enumerating objects: 1136, done.\u001b[K\n",
            "remote: Counting objects: 100% (1136/1136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (216/216), done.\u001b[K\n",
            "remote: Total 1136 (delta 980), reused 1046 (delta 917), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1136/1136), 14.88 MiB | 10.01 MiB/s, done.\n",
            "Resolving deltas: 100% (980/980), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/adc257/info4940-sitcom.git\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwyri_r4mFhe"
      },
      "source": [
        "# Defining some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BT2c3Cm_mFuB"
      },
      "outputs": [],
      "source": [
        "def list_files(start_path):\n",
        "    file_paths = []\n",
        "    for root, dirs, files in os.walk(start_path):\n",
        "        for file in files:\n",
        "            file_paths.append(os.path.join(root, file))\n",
        "\n",
        "    file_paths.sort()\n",
        "    return file_paths\n",
        "\n",
        "def fPathList_TO_DialogueWithContext(filePathList, nSentenceContext):\n",
        "  humorous_inputs = []\n",
        "  non_humorous_inputs = []\n",
        "\n",
        "  # formatted_inputs = []\n",
        "  # labels = []\n",
        "\n",
        "  for episodePath in filePathList:\n",
        "\n",
        "    with open(episodePath, 'r') as file:\n",
        "      data = json.load(file)\n",
        "      data = [info for (_, info) in data.items()]\n",
        "\n",
        "\n",
        "      i = nSentenceContext\n",
        "      while i < len(data):\n",
        "        context = [data[j] for j in range(i-nSentenceContext, i)]\n",
        "        target = data[i]\n",
        "\n",
        "        if 'isHumor' in target:\n",
        "          humorous_inputs.append(transformInput(context, target))\n",
        "        else:\n",
        "          non_humorous_inputs.append(transformInput(context, target))\n",
        "\n",
        "        i += 1\n",
        "\n",
        "  return humorous_inputs, non_humorous_inputs\n",
        "\n",
        "def sampleEven(positiveData, negativeData, sample_size_per_class, rand_seed):\n",
        "  sample_size_per_class = min(sample_size_per_class, len(humorousData), len(nonHumorousData))\n",
        "\n",
        "  sample_inputs = []\n",
        "  sample_labels = []\n",
        "\n",
        "  data = positiveData\n",
        "  test_size = (len(data) - sample_size_per_class) / len(data)\n",
        "  sample, _ = train_test_split(data, test_size=test_size, random_state=rand_seed)\n",
        "  sample_inputs += sample\n",
        "  sample_labels += [1]*len(sample)\n",
        "\n",
        "\n",
        "  data = negativeData\n",
        "  test_size = (len(data) - sample_size_per_class) / len(data)\n",
        "  sample, _ = train_test_split(data, test_size=test_size, random_state=rand_seed)\n",
        "  sample_inputs += sample\n",
        "  sample_labels += [0]*len(sample)\n",
        "\n",
        "  return sample_inputs, sample_labels\n",
        "\n",
        "def createBatches(data, batch_size):\n",
        "  return [data[i:i+batch_size] for i in range(0, len(data), batch_size)]\n",
        "\n",
        "def testLLAMA(inputs, labels, printResultsEveryN=50):\n",
        "  resultsData = {\n",
        "      \"truePos\": [],\n",
        "      \"trueNeg\": [],\n",
        "      \"falsePos\": [],\n",
        "      \"falseNeg\": [],\n",
        "      \"other\": [],\n",
        "  }\n",
        "\n",
        "  results = {\n",
        "      \"truePos\": 0,\n",
        "      \"trueNeg\": 0,\n",
        "      \"falsePos\": 0,\n",
        "      \"falseNeg\": 0,\n",
        "      \"other\": 0,\n",
        "  }\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  pred = []\n",
        "\n",
        "  terminators = [\n",
        "      tokenizer.eos_token_id,\n",
        "      tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "\n",
        "  for i in range(len(inputs)):\n",
        "    input = inputs[i]\n",
        "    label = labels[i]\n",
        "\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "      input,\n",
        "      add_generation_prompt=True,\n",
        "      return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "      input_ids,\n",
        "      max_new_tokens=50,\n",
        "      eos_token_id=terminators,\n",
        "      do_sample=True,\n",
        "      temperature=0.6,\n",
        "      top_p=0.9,\n",
        "      num_return_sequences=1,\n",
        "    )\n",
        "\n",
        "    response = outputs[0][input_ids.shape[-1]:]\n",
        "    response = tokenizer.decode(response, skip_special_tokens=True)\n",
        "    modelInput = tokenizer.decode(input_ids[0], skip_special_tokens=False)\n",
        "\n",
        "    resultsDict = {\n",
        "        \"input\": modelInput,\n",
        "        \"output\": response,\n",
        "    }\n",
        "\n",
        "\n",
        "    if str(response) == str(label):\n",
        "      # true\n",
        "      if str(label) == \"1\":\n",
        "        # pos\n",
        "        resultsData[\"truePos\"].append(resultsDict)\n",
        "        results[\"truePos\"] += 1\n",
        "      elif str(label) == \"0\":\n",
        "        # neg\n",
        "        resultsData[\"trueNeg\"].append(resultsDict)\n",
        "        results[\"trueNeg\"] += 1\n",
        "      else:\n",
        "        # other\n",
        "        resultsData[\"other\"].append(resultsDict)\n",
        "        results[\"other\"] += 1\n",
        "\n",
        "      correct += 1\n",
        "\n",
        "    else:\n",
        "      # false\n",
        "      if str(label) == \"1\":\n",
        "        # pos, pred neg\n",
        "        resultsData[\"falseNeg\"].append(resultsDict)\n",
        "        results[\"falseNeg\"] += 1\n",
        "      elif str(label) == \"0\":\n",
        "        # neg, pred pos\n",
        "        resultsData[\"falsePos\"].append(resultsDict)\n",
        "        results[\"falsePos\"] += 1\n",
        "      else:\n",
        "        # other\n",
        "        resultsData[\"other\"].append(resultsDict)\n",
        "        results[\"other\"] += 1\n",
        "\n",
        "    pred.append(response)\n",
        "    total += 1\n",
        "\n",
        "    if i % printResultsEveryN == 0:\n",
        "      print(f\"Test: {i+1} of  {len(inputs)}\")\n",
        "      print(f\"Success rate: {correct / total:.2%}\\n\")\n",
        "      print(\"results data:\", results)\n",
        "\n",
        "\n",
        "  print(f\"Final success rate: {correct / total:.2%}\")\n",
        "\n",
        "  # true = [str(i) for i in labels]\n",
        "  # report = classification_report(y_pred=pred, y_true=true, target_names=[\"Non-Humorous\",\"Humorous\"])\n",
        "  report = None\n",
        "\n",
        "  return results, resultsData, pred, report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testLLAMAScaleOutput(inputs, labels, scale, printResultsEveryN=50):\n",
        "  # resultsData = {\n",
        "  #     \"truePos\": [],\n",
        "  #     \"trueNeg\": [],\n",
        "  #     \"falsePos\": [],\n",
        "  #     \"falseNeg\": [],\n",
        "  # }\n",
        "\n",
        "  # results = {\n",
        "  #     \"truePos\": 0,\n",
        "  #     \"trueNeg\": 0,\n",
        "  #     \"falsePos\": 0,\n",
        "  #     \"falseNeg\": 0,\n",
        "  # }\n",
        "\n",
        "  # blankResultsData = {str(i): [] for i in range(scale[0], scale[1]+1)}\n",
        "\n",
        "  resultsData = {\n",
        "      \"truePos\": {str(i): [] for i in range(scale[0], scale[1]+1)},\n",
        "      \"trueNeg\": {str(i): [] for i in range(scale[0], scale[1]+1)},\n",
        "      \"other\": []\n",
        "  }\n",
        "\n",
        "  # blankResults = {str(i): 0 for i in range(scale[0], scale[1]+1)}\n",
        "\n",
        "  results = {\n",
        "      \"truePos\": {str(i): 0 for i in range(scale[0], scale[1]+1)},\n",
        "      \"trueNeg\": {str(i): 0 for i in range(scale[0], scale[1]+1)},\n",
        "      \"other\": 0\n",
        "  }\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  pred = []\n",
        "\n",
        "  terminators = [\n",
        "      tokenizer.eos_token_id,\n",
        "      tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "\n",
        "  for i in range(len(inputs)):\n",
        "    input = inputs[i]\n",
        "    label = labels[i]\n",
        "\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "      input,\n",
        "      add_generation_prompt=True,\n",
        "      return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "      input_ids,\n",
        "      max_new_tokens=50,\n",
        "      eos_token_id=terminators,\n",
        "      do_sample=True,\n",
        "      temperature=0.6,\n",
        "      top_p=0.9,\n",
        "      num_return_sequences=1,\n",
        "    )\n",
        "\n",
        "    response = outputs[0][input_ids.shape[-1]:]\n",
        "    response = tokenizer.decode(response, skip_special_tokens=True)\n",
        "    modelInput = tokenizer.decode(input_ids[0], skip_special_tokens=False)\n",
        "\n",
        "    resultsDict = {\n",
        "        \"input\": modelInput,\n",
        "        \"output\": response,\n",
        "    }\n",
        "\n",
        "    responseInt = str(response)\n",
        "\n",
        "    if not responseInt.isdigit():\n",
        "      resultsData[\"other\"].append(resultsDict)\n",
        "      results[\"other\"] += 1\n",
        "    else:\n",
        "      if str(label) == \"1\":\n",
        "        resultsData[\"truePos\"][responseInt].append(resultsDict)\n",
        "        results[\"truePos\"][responseInt] += 1\n",
        "      elif str(label) == \"0\":\n",
        "        resultsData[\"trueNeg\"][responseInt].append(resultsDict)\n",
        "        results[\"trueNeg\"][responseInt] += 1\n",
        "      else:\n",
        "        resultsData[\"other\"].append(resultsDict)\n",
        "        results[\"other\"] += 1\n",
        "\n",
        "    pred.append(response)\n",
        "    total += 1\n",
        "\n",
        "    if i % printResultsEveryN == 0:\n",
        "      print(f\"Test: {i+1} of  {len(inputs)}\")\n",
        "      # print(f\"Success rate: {correct / total:.2%}\\n\")\n",
        "      print(\"results data:\", results)\n",
        "\n",
        "\n",
        "  # print(f\"Final success rate: {correct / total:.2%}\")\n",
        "  print(f\"Final results\", results)\n",
        "\n",
        "  # true = [str(i) for i in labels]\n",
        "  # report = classification_report(y_pred=pred, y_true=true, target_names=[\"Non-Humorous\",\"Humorous\"])\n",
        "  report = None\n",
        "\n",
        "  return results, resultsData, pred, report"
      ],
      "metadata": {
        "id": "J0XwxrBltoHa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV9T5H7RoN2y"
      },
      "source": [
        "## Defining input formatters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3o6erjKqoOGl"
      },
      "outputs": [],
      "source": [
        "def transformInput(context, target):\n",
        "  # if not context:\n",
        "  #   return transformInputNoContext(target)\n",
        "\n",
        "  messages = []\n",
        "\n",
        "  separator = \"\\n\"\n",
        "  quotation_token = '\"'\n",
        "\n",
        "  # formatted_input = \"\"\n",
        "\n",
        "  systemPrmpt = {\n",
        "      'role': 'system',\n",
        "      'content': \"\"\n",
        "  }\n",
        "\n",
        "  # if len(context) > 0:\n",
        "  #   systemPrmpt['content'] += \"You are humor classification model, determine whether the target dialogue is humorous using the previous dialogue as context. RESTRICTION: ONLY RESPOND 1 (for humorous) OR 0 (for not humorous).\"\n",
        "  # else:\n",
        "  #   systemPrmpt['content'] += \"You are humor classification model, determine whether the target dialogue is humorous. RESTRICTION: ONLY RESPOND 1 (for humorous) OR 0 (for not humorous).\"\n",
        "\n",
        "  if len(context) > 0:\n",
        "    systemPrmpt['content'] += \"You are humor classification model, determine whether the target dialogue is funny using the previous dialogue as context. RESTRICTION: ONLY RESPOND 0 (for funny) OR 1 (for serious).\"\n",
        "  else:\n",
        "    systemPrmpt['content'] += \"You are humor classification model, determine whether the target dialogue is funny. RESTRICTION: ONLY RESPOND 0 (for funny) OR 1 (for serious).\"\n",
        "\n",
        "\n",
        "  # append systemPrmpt\n",
        "  messages.append(systemPrmpt)\n",
        "\n",
        "  # systemPrmpt2 = {\n",
        "  #     'role': 'system',\n",
        "  #     'content': \"\"\n",
        "  # }\n",
        "  userPrmpt = {\n",
        "      'role': 'user',\n",
        "      'content': \"\"\n",
        "  }\n",
        "  # userPrmpt2 = {\n",
        "  #     'role': 'user',\n",
        "  #     'content': \"\"\n",
        "  # }\n",
        "  # asstPrmpt = {\n",
        "  #     'role': 'assistant',\n",
        "  #     'content': \"\"\n",
        "  # }\n",
        "\n",
        "\n",
        "  if len(context) > 0:\n",
        "    # CONTEXT\n",
        "    userPrmpt['content'] += \"Context:\" + separator\n",
        "\n",
        "    # if entry['Scene'] != current_scene:\n",
        "    #   current_scene = entry[\"Scene\"]\n",
        "    #   userPrmpt2['content'] += \"The scene changes to: \"\n",
        "    # else:\n",
        "    #   userPrmpt2['content'] += \"The Scene is still: \"\n",
        "\n",
        "    # userPrmpt2['content'] += current_scene + separator\n",
        "\n",
        "    for entry in context:\n",
        "      # if current_scene != entry['Scene']:\n",
        "      #   current_scene = entry[\"Scene\"]\n",
        "      #   userPrmpt2['content'] += \"The scene changes to: \" + current_scene + separator\n",
        "\n",
        "      recipients = entry['Recipients']\n",
        "      recipients = [i for i in recipients if i != \"\"]\n",
        "\n",
        "      recipients_str = \"\"\n",
        "      if len(recipients) == 0:\n",
        "        recipients_str += \"to themselves\"\n",
        "      elif len(recipients) == 1:\n",
        "        recipients_str += recipients[0]\n",
        "      else:\n",
        "        recipients_str += \", \".join(recipients[:-1]) + \" and \" + recipients[-1]\n",
        "\n",
        "      userPrmpt['content'] += f\"{entry['Speaker']} says {quotation_token}{entry['Dialogue']}{quotation_token} to {recipients_str}.\" + separator\n",
        "\n",
        "  # TARGET LINE\n",
        "  userPrmpt['content'] += separator + \"Target:\" + separator\n",
        "\n",
        "  # current_scene = context[0]['Scene']\n",
        "  # userPrmpt['content'] += \"Is the following target_moment from the sitcom, the Big Bang Theory, humorous or not humorous? Only respond '1' for humorous or '0' for not humorous:\"\n",
        "  # userPrmpt['content'] += separator*2\n",
        "\n",
        "  entry = target\n",
        "\n",
        "  # if entry['Scene'] != current_scene:\n",
        "  #   current_scene = entry[\"Scene\"]\n",
        "  #   userPrmpt['content'] += \"The scene changes to: \"\n",
        "  # else:\n",
        "  #   userPrmpt['content'] += \"The Scene is still: \"\n",
        "  # userPrmpt['content'] += current_scene + separator\n",
        "\n",
        "  recipients = entry['Recipients']\n",
        "  recipients = [i for i in recipients if i != \"\"]\n",
        "  recipients_str = \"\"\n",
        "  if len(recipients) == 0:\n",
        "    recipients_str += \"to themselves\"\n",
        "  elif len(recipients) == 1:\n",
        "    recipients_str += recipients[0]\n",
        "  else:\n",
        "    recipients_str += \", \".join(recipients[:-1]) + \" and \" + recipients[-1]\n",
        "\n",
        "\n",
        "  userPrmpt['content'] += f\"{entry['Speaker']} says {quotation_token}{entry['Dialogue']}{quotation_token} to {recipients_str}.\" + separator\n",
        "\n",
        "  userPrmpt['content'] += separator*2 + \"Is the target dialogue funny (return 0) or serious (return 1)?\"\n",
        "  # userPrmpt['content'] += separator*2 + \"Rate the target dialogue on a scale of 1 (not humorous) to 5 (humorous).\"\n",
        "\n",
        "\n",
        "  # systemPrmpt2['content'] += \"Using the context provided, return '1' if the target_moment was humorous or '0' if the target_moment was not humorous?\"\n",
        "  # append userPrmpt\n",
        "  messages.append(userPrmpt)\n",
        "\n",
        "  # asstPrmpt['content'] += \"Can you provide some context to help me with this decision?\"\n",
        "  # append asstPrmpt\n",
        "  # messages.append(asstPrmpt)\n",
        "\n",
        "  # userPrmpt['content'] += \"Context:\" + separator\n",
        "\n",
        "  # if entry['Scene'] != current_scene:\n",
        "  #   current_scene = entry[\"Scene\"]\n",
        "  #   userPrmpt2['content'] += \"The scene changes to: \"\n",
        "  # else:\n",
        "  #   userPrmpt2['content'] += \"The Scene is still: \"\n",
        "\n",
        "  # userPrmpt2['content'] += current_scene + separator\n",
        "\n",
        "  # for entry in context:\n",
        "  #   if current_scene != entry['Scene']:\n",
        "  #     current_scene = entry[\"Scene\"]\n",
        "  #     userPrmpt2['content'] += \"The scene changes to: \" + current_scene + separator\n",
        "\n",
        "  #   recipients = entry['Recipients']\n",
        "  #   recipients = [i for i in recipients if i != \"\"]\n",
        "\n",
        "  #   recipients_str = \"\"\n",
        "  #   if len(recipients) == 0:\n",
        "  #     recipients_str += \"to themselves\"\n",
        "  #   elif len(recipients) == 1:\n",
        "  #     recipients_str += recipients[0]\n",
        "  #   else:\n",
        "  #     recipients_str += \", \".join(recipients[:-1]) + \" and \" + recipients[-1]\n",
        "\n",
        "  #   userPrmpt2['content'] += f\"{entry['Speaker']} says {quotation_token}{entry['Dialogue']}{quotation_token} to {recipients_str}.\"\n",
        "  #   userPrmpt2['content'] += separator\n",
        "\n",
        "  # # append userPrmpt2\n",
        "  # messages.append(userPrmpt2)\n",
        "\n",
        "  # userPrmpt2['content'] += separator + \"-\" *20 + separator*2\n",
        "\n",
        "  # systemPrmpt2['content'] += \"Using the context provided, return '1' if the target_moment was humorous or '0' if the target_moment was not humorous?\"\n",
        "\n",
        "  # append systemPrmpt2\n",
        "  # messages.append(systemPrmpt2)\n",
        "\n",
        "  # messages = [systemPrmpt, userPrmpt, asstPrmpt, ]\n",
        "\n",
        "  return messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHEvS-HLacCQ"
      },
      "source": [
        "### Some nShot specific formatters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1pT_-AzdWTty"
      },
      "outputs": [],
      "source": [
        "def fPathList_TO_ContextsTargetsLabels(filePathList, nSentenceContext):\n",
        "  humorEntries = []\n",
        "  nonHumorEntries = []\n",
        "\n",
        "  for episodePath in filePathList:\n",
        "    with open(episodePath, 'r') as file:\n",
        "      data = json.load(file)\n",
        "      data = [info for (_, info) in data.items()]\n",
        "\n",
        "\n",
        "      i = nSentenceContext\n",
        "      while i < len(data):\n",
        "        entry = {}\n",
        "\n",
        "        entry['context'] = [data[j] for j in range(i-nSentenceContext, i)]\n",
        "        entry['target'] = data[i]\n",
        "        if 'isHumor' in data[i]:\n",
        "          entry['label'] = 1\n",
        "          humorEntries.append(entry)\n",
        "        else:\n",
        "          entry['label'] = 0\n",
        "          nonHumorEntries.append(entry)\n",
        "        i += 1\n",
        "\n",
        "  return humorEntries, nonHumorEntries\n",
        "\n",
        "def transformInputNShot(entries, labels):\n",
        "  # if (len(contexts) != len(targets)) & (len(contexts) != len(labels)):\n",
        "  #   print(\"TRANSFORMINPUT nSHOT ERROR, CONTEXTS, TARGETS, LABELS NOT EQUAL LENGTHS\")\n",
        "  #   return\n",
        "\n",
        "  # if not context:\n",
        "  #   return transformInputNoContext(target)\n",
        "\n",
        "\n",
        "  separator = \"\\n\"\n",
        "  quotation_token = '\"'\n",
        "\n",
        "  formatted_input = \"Here are some examples of the task:\\n\"\n",
        "\n",
        "  for i in range(len(entries)):\n",
        "    context = entries[i]['context']\n",
        "    target = entries[i]['target']\n",
        "    label = labels[i]\n",
        "\n",
        "    current_scene = context[-1]['Scene']\n",
        "\n",
        "    formatted_input += separator*2 + f\"Example {i + 1}:\" + separator\n",
        "\n",
        "    # formatted_input += \"User: Is the following target_moment from the sitcom, the Big Bang Theory, humorous or not humorous? Only respond '1' for humorous or '0' for not humorous:\"\n",
        "\n",
        "    formatted_input += \"Target moment:\" + separator\n",
        "\n",
        "    entry = target\n",
        "    if entry['Scene'] != current_scene:\n",
        "      current_scene = entry[\"Scene\"]\n",
        "      formatted_input += \"The scene changes to: \"\n",
        "    else:\n",
        "      formatted_input += \"The Scene is still: \"\n",
        "\n",
        "    formatted_input += current_scene + separator\n",
        "\n",
        "\n",
        "    recipients = entry['Recipients']\n",
        "    recipients = [i for i in recipients if i != \"\"]\n",
        "\n",
        "    recipients_str = \"\"\n",
        "    if len(recipients) == 0:\n",
        "      recipients_str += \"to themselves\"\n",
        "    elif len(recipients) == 1:\n",
        "      recipients_str += recipients[0]\n",
        "    else:\n",
        "      recipients_str += \", \".join(recipients[:-1]) + \" and \" + recipients[-1]\n",
        "\n",
        "    formatted_input += f\"{entry['Speaker']} says {quotation_token}{entry['Dialogue']}{quotation_token} to {recipients_str}.\" + separator\n",
        "\n",
        "    # formatted_input += \"Assistant: Can you provide some context to help me with this decision?\" + separator\n",
        "\n",
        "    # formatted_input += \"User: Yes, use the following as context:\" + separator*2\n",
        "\n",
        "    formatted_input += \"-\"*20 + separator + \"Context:\" + separator\n",
        "\n",
        "    if entry['Scene'] != current_scene:\n",
        "      current_scene = entry[\"Scene\"]\n",
        "      formatted_input += \"The scene changes to: \"\n",
        "    else:\n",
        "      formatted_input += \"The Scene is still: \"\n",
        "\n",
        "    formatted_input += current_scene + separator\n",
        "\n",
        "    for entry in context:\n",
        "      if current_scene != entry['Scene']:\n",
        "        current_scene = entry[\"Scene\"]\n",
        "        formatted_input += \"The scene changes to: \" + current_scene + separator\n",
        "\n",
        "      recipients = entry['Recipients']\n",
        "      recipients = [i for i in recipients if i != \"\"]\n",
        "      recipients_str = \"\"\n",
        "      if len(recipients) == 0:\n",
        "        recipients_str += \"to themselves\"\n",
        "      elif len(recipients) == 1:\n",
        "        recipients_str += recipients[0]\n",
        "      else:\n",
        "        recipients_str += \", \".join(recipients[:-1]) + \" and \" + recipients[-1]\n",
        "\n",
        "      formatted_input += f\"{entry['Speaker']} says {quotation_token}{entry['Dialogue']}{quotation_token} to {recipients_str}.\" + separator\n",
        "\n",
        "    formatted_input += \"-\"*20 + separator\n",
        "    formatted_input += f\"Correct Output: {label}\"\n",
        "\n",
        "  return formatted_input\n",
        "\n",
        "def addNShotText(input, nShotText):\n",
        "  returnInput = deepcopy(input)\n",
        "\n",
        "  if input[0]['role'] != \"system\":\n",
        "    print(\"ERROR: first message in input is not assigned\")\n",
        "    return\n",
        "\n",
        "  returnInput[0]['content'] += \"\\n\\n\" + nShotText\n",
        "\n",
        "  return returnInput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl-I2IVHmZd3"
      },
      "source": [
        "# Creating sample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vIvtflQ5mYca"
      },
      "outputs": [],
      "source": [
        "filePaths = []\n",
        "for i in range(5):\n",
        "  fPath = '/content/info4940-sitcom/cleaned-data/S' + str(i+1)\n",
        "  filePaths += list_files(fPath)\n",
        "\n",
        "# getting random number for random state for consistency?\n",
        "rand_seed1 = 64 # random.randint(1,100)\n",
        "rand_seed2 = 94 # random.randint(1,100)\n",
        "rand_seed3 = 69 # random.randint(1,100)\n",
        "rand_seed4 = 74 # random.randint(1,100)\n",
        "\n",
        "\n",
        "# print([rand_seed1,rand_seed2,rand_seed3])\n",
        "\n",
        "# sampling 10 episodes\n",
        "nSamples = 10\n",
        "test_size = (len(filePaths) - nSamples) / len(filePaths)\n",
        "samplePaths, nShotSamplePaths = train_test_split(filePaths, test_size=test_size, random_state=rand_seed1)\n",
        "\n",
        "# cleaning/transforming inputs\n",
        "nContext = 0\n",
        "humorousData, nonHumorousData = fPathList_TO_DialogueWithContext(samplePaths, nContext)\n",
        "sample_inputs, sample_labels = sampleEven(positiveData=humorousData, negativeData=nonHumorousData, sample_size_per_class=250, rand_seed=rand_seed2)\n",
        "\n",
        "# shuffling, not necessary but helpful for watching in-progress results\n",
        "rand_order = [i for i in range(len(sample_inputs))]\n",
        "random.seed(rand_seed3)\n",
        "random.shuffle(rand_order)\n",
        "random.seed(random.randint(1,100))\n",
        "\n",
        "inputs = [sample_inputs[i] for i in rand_order]\n",
        "labels = [sample_labels[i] for i in rand_order]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-TSp_v8bVCS"
      },
      "source": [
        "## Creating nShotText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NNXASuAbVOL"
      },
      "outputs": [],
      "source": [
        "nShot = 16\n",
        "\n",
        "random.shuffle(nShotSamplePaths)\n",
        "nShotSamplePaths = nShotSamplePaths[:3]\n",
        "\n",
        "nShotHumorEntries, nShotNonHumorEntries = fPathList_TO_ContextsTargetsLabels(nShotSamplePaths, nContext)\n",
        "nShot_sample_entries, nShot_sample_labels = sampleEven(positiveData=nShotHumorEntries, negativeData=nShotNonHumorEntries, sample_size_per_class=math.ceil(nShot/2), rand_seed=rand_seed4)\n",
        "\n",
        "rand_order = [i for i in range(len(nShot_sample_entries))]\n",
        "random.shuffle(rand_order)\n",
        "\n",
        "nShot_sample_entries = [nShot_sample_entries[i] for i in rand_order]\n",
        "nShot_sample_labels = [nShot_sample_labels[i] for i in rand_order]\n",
        "\n",
        "\n",
        "nShotText = transformInputNShot(entries=nShot_sample_entries, labels=nShot_sample_labels)\n",
        "# inputs = [addNShotText(input, nShotText) for input in inputs]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W9oprDic_j2"
      },
      "source": [
        "### Sample nShot Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGswHG9-gQRr"
      },
      "outputs": [],
      "source": [
        "# nShot_sample_entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILXdE08Ac-r3"
      },
      "outputs": [],
      "source": [
        "# print(nShotText)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwRiMi5goqTN"
      },
      "source": [
        "## Sample Raw and Cleaned Formats:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "4BqYgUVUopXp",
        "outputId": "f94b5a4a-44d4-4d8d-ff9f-b6907a29dfa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example raw entry:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'EpisodeID': 'The Big Bang_S0101',\n",
              " 'Scene': 'A corridor at a sperm bank.',\n",
              " 'Recipients': ['Leonard'],\n",
              " 'Speaker': 'Sheldon',\n",
              " 'Dialogue': \"So if a photon is directed through a plane with two slits in it and either slit is observed, it will not go through both slits. If it's unobserved, it will. However, if it's observed after it's left the plane but before it hits its target, it won't have gone through both slits.\",\n",
              " 'Dialogue Start Time': '00:00:00:140000',\n",
              " 'Dialogue End Time': '00:00:12:140000'}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Example formatted entry (0context) (0-shot):\n",
            "\n",
            "Role: system | Content:\n",
            "You are humor classification model, determine whether the target dialogue is funny. RESTRICTION: ONLY RESPOND 0 (for funny) OR 1 (for serious).\n",
            "\n",
            "Role: user | Content:\n",
            "\n",
            "Target:\n",
            "Sheldon says \"So if a photon is directed through a plane with two slits in it and either slit is observed, it will not go through both slits. If it's unobserved, it will. However, if it's observed after it's left the plane but before it hits its target, it won't have gone through both slits.\" to Leonard.\n",
            "\n",
            "\n",
            "Is the target dialogue funny (return 0) or serious (return 1)?\n",
            "\n",
            "Actual: False\n"
          ]
        }
      ],
      "source": [
        "filePath = \"/content/info4940-sitcom/cleaned-data/S1/The Big Bang_S0101.json\"\n",
        "nSentenceContext = nContext\n",
        "\n",
        "with open(filePath, 'r') as file:\n",
        "  data = json.load(file)\n",
        "  data = [info for (_, info) in data.items()]\n",
        "\n",
        "print(f\"Example raw entry:\")\n",
        "display(data[nSentenceContext])\n",
        "\n",
        "print(f\"\\n\\nExample formatted entry ({nSentenceContext}context) (0-shot):\\n\")\n",
        "input = transformInput(context=data[:nSentenceContext], target=data[nSentenceContext])\n",
        "for i in input:\n",
        "  print(f\"Role: {i['role']} | Content:\\n{i['content']}\\n\")\n",
        "\n",
        "print(f'Actual: {(\"isHumor\" in data[3])}')\n",
        "\n",
        "\n",
        "# print(f\"\\n\\nExample formatted entry ({nSentenceContext}context) (4-shot):\\n\")\n",
        "# input = transformInput(context=data[:nSentenceContext], target=data[nSentenceContext])\n",
        "# input = addNShotText(input, nShotText)\n",
        "\n",
        "\n",
        "# for i in input:\n",
        "#   print(f\"Role: {i['role']} | Content:\\n{i['content']}\\n\")\n",
        "\n",
        "# print(f'Actual: {(\"isHumor\" in data[nScentenceContext])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUQoH8FxlbSy"
      },
      "source": [
        "# The LLAMA 3 8B instruct model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t3T_Wls4WTD",
        "outputId": "c5ce87ac-3b62-4e6a-e08c-408457cc4356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKShkdG63ed9"
      },
      "outputs": [],
      "source": [
        "# quantization_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_compute_dtype=torch.float16,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "# )\n",
        "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id,\n",
        "#                                           token=userdata.get('HF_TOKEN'),\n",
        "#                                           low_cpu_mem_usage=True,\n",
        "#                                           quantization_config=quantization_config,\n",
        "#                                           )\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_id,\n",
        "#     torch_dtype=torch.bfloat16,\n",
        "#     device_map=\"auto\",\n",
        "#     token=userdata.get('HF_TOKEN')\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Yq2-pyv6nSA"
      },
      "outputs": [],
      "source": [
        "# # Saves Model to Drive\n",
        "\n",
        "# model_path = '/content/drive/My Drive/INFO4940_humor/LLAMA3_8b_instruct_Quantized_4bit'\n",
        "\n",
        "# model.save_pretrained(model_path)\n",
        "\n",
        "# tokenizer_path = '/content/drive/My Drive/INFO4940_humor/LLAMA3_8b_instruct_Quantized_4bit_tokenizer'\n",
        "\n",
        "# tokenizer.save_pretrained(tokenizer_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "40c6529b569b4064ad243312635170d3",
            "9ad992ef2b7f4830bfa1d1d5b9ac92ec",
            "e7154766c98a459b942fedaa09cd83af",
            "6bbfb1ee8cbb4d2cb1fbf4619ecf84f1",
            "35a3a40935134e3596ddfd24710273f6",
            "c8a702feba7a4b5b85d8446179316112",
            "e98e4292986b4214b784c034d680d2ba",
            "6e88a65ac66344c191d234c996d92fc5",
            "edc85d1cf2b74039b71675d7d0001dc7",
            "ae8438722d02460882004ccaf1376335",
            "3a76cf2d65234cad97d77e2eb70d3d36",
            "baffbc5110b44767a2d87e036249f286",
            "f48fd91dd1c24a49ab808a11f83988f9",
            "fbec55381edd440cbb47fbb4a5505869",
            "5f52479f86b94636ac45f3d25d0b84a2",
            "235761dc54ec463f954e92644b0c56a5",
            "bd3125f4d3ff47f3a2fb0e88ab19898e",
            "69abc0b81ccb4d30a06d32900c908a8c",
            "bad8d27d3ab64c0994858a353268deae",
            "5c521fb81e4c409bb0140e01991e3491",
            "ed646086e25b42cf9e0fe4d6461f07e4",
            "2ba38459f01840b1848dcbe2383fa360",
            "f2d2b1eb4d9e419b9e3271f34abc0aec",
            "fe1e3548368d4fb0b35756e90ee2cab6",
            "46b64f6b8505413ba21cfabfe637cc1c",
            "9dde0f1a9ed147b9adade0346da3a75e",
            "ff78d025e45f49d2ba89149c5383827c",
            "128501b50a974214a0231dc816b1360f",
            "7d6b0d46a28e4a3cbe45b73009b58b88",
            "b55cf9ebe58143ddb72ef0e0a7f3f1f3",
            "733447d8e6204a149f4569790924bda1",
            "cef246084f314b569713f0c3180fcd01",
            "a8b3f1e9437c49f8a9c0873c443dddfc",
            "84bf23f4979f4ac6abce79fbaa647794",
            "20f40da5e5b24d3fa65c7247b5fc1e67",
            "6f32527d186b4a61826efcb46a9314ce",
            "41c5085bc3314189a117856c1b4da3e5",
            "bd434b5f5a7b4ac19d9cdd52f7bf3c6a",
            "7aad55b14b0d4e98a7cdcad6cb811747",
            "3a23c589d6484fc2a749eb9e3f0752e9",
            "2f2d165333384c14bb4cfbadc00885fc",
            "c3a84624bf174cf7bac18a21d08b440e",
            "2d4ac3b081624576b459857a498ad2c2",
            "60459bc016bd4866a1a7c952f2d09798"
          ]
        },
        "id": "LLuyjqjR5hva",
        "outputId": "b95345fa-6ab7-4dfb-d308-2c0dfc78c937"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40c6529b569b4064ad243312635170d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "baffbc5110b44767a2d87e036249f286"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2d2b1eb4d9e419b9e3271f34abc0aec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84bf23f4979f4ac6abce79fbaa647794"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Loads Model from Drive\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,\n",
        "                                          token=userdata.get('HF_TOKEN'),\n",
        "                                          low_cpu_mem_usage=True,\n",
        "                                          quantization_config=quantization_config,\n",
        "                                          )\n",
        "\n",
        "model_path = '/content/drive/My Drive/INFO4940_humor/LLAMA3_8b_instruct_Quantized_4bit'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxbtspidmnqi"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkuB2zXkuvOq",
        "outputId": "e4d2782c-18c0-4bb2-dfa5-2b5ed970d3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "terminators = [\n",
        "    tokenizer.eos_token_id,\n",
        "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "\n",
        "input = inputs[0]\n",
        "label = labels[0]\n",
        "\n",
        "\n",
        "# syscont = 'You are humor classification model, determine whether the target dialogue is humorous using the previous dialogue as context. RESTRICTION: ONLY RESPOND INTEGERS 1 THRU 5, WHERE 1 MEANS NOT HUMOROUS AND 5 MEANS HUMOROUS.'\n",
        "# input[0]['content'] = syscont\n",
        "\n",
        "input_ids = tokenizer.apply_chat_template(\n",
        "  input,\n",
        "  add_generation_prompt=True,\n",
        "  return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "  input_ids,\n",
        "  max_new_tokens=10,\n",
        "  eos_token_id=terminators,\n",
        "  do_sample=True,\n",
        "  temperature=0.5,\n",
        "  top_p=0.9,\n",
        "  num_return_sequences=10,\n",
        ")\n",
        "\n",
        "response = outputs[0][input_ids.shape[-1]:]\n",
        "response = tokenizer.decode(response, skip_special_tokens=True)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(len(outputs)):\n",
        "  print(tokenizer.decode(outputs[i][input_ids.shape[-1]:], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeThztrW1reM",
        "outputId": "09fb1ffc-26f7-4352-a444-ae8c9e0f777f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o05AB3PyjuSv",
        "outputId": "2f97568d-174e-4fed-94b0-039c6afed9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are humor classification model, determine whether the target dialogue is funny. RESTRICTION: ONLY RESPOND 0 (for funny) OR 1 (for serious).<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Target:\n",
            "Mrs Wolowitz says \"She's a lovely girl! Cute as a button!\" to Howard and MrsWolowitz.\n",
            "\n",
            "\n",
            "Is the target dialogue funny (return 0) or serious (return 1)?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(input_ids[0], skip_special_tokens=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohh4tsCdvotI",
        "outputId": "3907094b-ef70-42b8-85b3-f3527f187b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You are humor classification model, determine whether the target dialogue is funny. RESTRICTION: ONLY RESPOND 0 (for funny) OR 1 (for serious).'}, {'role': 'user', 'content': '\\nTarget:\\nMrs Wolowitz says \"She\\'s a lovely girl! Cute as a button!\" to Howard and MrsWolowitz.\\n\\n\\nIs the target dialogue funny (return 0) or serious (return 1)?'}]\n",
            "expected: 0, model: 0\n",
            "You are humor classification model, determine whether the target dialogue is funny. RESTRICTION: ONLY RESPOND 0 (for funny) OR 1 (for serious).\n",
            "\n",
            "Target:\n",
            "Mrs Wolowitz says \"She's a lovely girl! Cute as a button!\" to Howard and MrsWolowitz.\n",
            "\n",
            "\n",
            "Is the target dialogue funny (return 0) or serious (return 1)?\n"
          ]
        }
      ],
      "source": [
        "print(input)\n",
        "print(f'expected: {label}, model: {response}')\n",
        "\n",
        "\n",
        "for i in input:\n",
        "  print(i['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "upyEZeGMmn3X",
        "outputId": "af2e32df-c6f9-480e-d58e-5b78ced9891e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 1 of  500\n",
            "Success rate: 100.00%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 1, 'falsePos': 0, 'falseNeg': 0, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 11 of  500\n",
            "Success rate: 36.36%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 4, 'falsePos': 0, 'falseNeg': 7, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 21 of  500\n",
            "Success rate: 52.38%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 11, 'falsePos': 0, 'falseNeg': 10, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 31 of  500\n",
            "Success rate: 48.39%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 15, 'falsePos': 0, 'falseNeg': 16, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 41 of  500\n",
            "Success rate: 53.66%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 22, 'falsePos': 0, 'falseNeg': 19, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 51 of  500\n",
            "Success rate: 52.94%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 27, 'falsePos': 0, 'falseNeg': 24, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 61 of  500\n",
            "Success rate: 52.46%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 32, 'falsePos': 0, 'falseNeg': 29, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 71 of  500\n",
            "Success rate: 50.70%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 36, 'falsePos': 0, 'falseNeg': 35, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 81 of  500\n",
            "Success rate: 46.91%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 38, 'falsePos': 0, 'falseNeg': 43, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 91 of  500\n",
            "Success rate: 46.15%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 42, 'falsePos': 0, 'falseNeg': 49, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 101 of  500\n",
            "Success rate: 47.52%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 48, 'falsePos': 0, 'falseNeg': 53, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 111 of  500\n",
            "Success rate: 45.95%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 51, 'falsePos': 0, 'falseNeg': 60, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 121 of  500\n",
            "Success rate: 45.45%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 55, 'falsePos': 0, 'falseNeg': 66, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 131 of  500\n",
            "Success rate: 44.27%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 58, 'falsePos': 0, 'falseNeg': 73, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 141 of  500\n",
            "Success rate: 45.39%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 64, 'falsePos': 0, 'falseNeg': 77, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 151 of  500\n",
            "Success rate: 45.70%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 69, 'falsePos': 0, 'falseNeg': 82, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 161 of  500\n",
            "Success rate: 47.20%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 76, 'falsePos': 0, 'falseNeg': 85, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 171 of  500\n",
            "Success rate: 48.54%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 83, 'falsePos': 0, 'falseNeg': 88, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 181 of  500\n",
            "Success rate: 49.72%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 90, 'falsePos': 0, 'falseNeg': 91, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 191 of  500\n",
            "Success rate: 50.79%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 97, 'falsePos': 0, 'falseNeg': 94, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 201 of  500\n",
            "Success rate: 50.25%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 101, 'falsePos': 0, 'falseNeg': 100, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 211 of  500\n",
            "Success rate: 51.18%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 108, 'falsePos': 0, 'falseNeg': 103, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 221 of  500\n",
            "Success rate: 51.58%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 114, 'falsePos': 0, 'falseNeg': 107, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 231 of  500\n",
            "Success rate: 51.52%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 119, 'falsePos': 0, 'falseNeg': 112, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 241 of  500\n",
            "Success rate: 51.45%\n",
            "\n",
            "results data: {'truePos': 0, 'trueNeg': 124, 'falsePos': 0, 'falseNeg': 117, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 251 of  500\n",
            "Success rate: 51.39%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 128, 'falsePos': 0, 'falseNeg': 122, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 261 of  500\n",
            "Success rate: 50.96%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 132, 'falsePos': 0, 'falseNeg': 128, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 271 of  500\n",
            "Success rate: 51.29%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 138, 'falsePos': 0, 'falseNeg': 132, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 281 of  500\n",
            "Success rate: 51.25%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 143, 'falsePos': 0, 'falseNeg': 137, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 291 of  500\n",
            "Success rate: 50.86%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 147, 'falsePos': 0, 'falseNeg': 143, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 301 of  500\n",
            "Success rate: 51.16%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 153, 'falsePos': 0, 'falseNeg': 147, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 311 of  500\n",
            "Success rate: 51.13%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 158, 'falsePos': 0, 'falseNeg': 152, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 321 of  500\n",
            "Success rate: 50.47%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 161, 'falsePos': 0, 'falseNeg': 159, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 331 of  500\n",
            "Success rate: 49.85%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 164, 'falsePos': 0, 'falseNeg': 166, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 341 of  500\n",
            "Success rate: 50.15%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 170, 'falsePos': 1, 'falseNeg': 169, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 351 of  500\n",
            "Success rate: 49.86%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 174, 'falsePos': 1, 'falseNeg': 175, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 361 of  500\n",
            "Success rate: 50.42%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 181, 'falsePos': 1, 'falseNeg': 178, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 371 of  500\n",
            "Success rate: 50.94%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 188, 'falsePos': 1, 'falseNeg': 181, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 381 of  500\n",
            "Success rate: 50.66%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 192, 'falsePos': 1, 'falseNeg': 187, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 391 of  500\n",
            "Success rate: 50.90%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 198, 'falsePos': 1, 'falseNeg': 191, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 401 of  500\n",
            "Success rate: 50.87%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 203, 'falsePos': 1, 'falseNeg': 196, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 411 of  500\n",
            "Success rate: 51.09%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 209, 'falsePos': 1, 'falseNeg': 200, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 421 of  500\n",
            "Success rate: 50.36%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 211, 'falsePos': 1, 'falseNeg': 208, 'other': 0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 431 of  500\n",
            "Success rate: 50.81%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 218, 'falsePos': 1, 'falseNeg': 211, 'other': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: 441 of  500\n",
            "Success rate: 49.89%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 219, 'falsePos': 1, 'falseNeg': 220, 'other': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: 451 of  500\n",
            "Success rate: 49.89%\n",
            "\n",
            "results data: {'truePos': 1, 'trueNeg': 224, 'falsePos': 1, 'falseNeg': 225, 'other': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-eac13b7a11f3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultsData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestLLAMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintResultsEveryN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# results, resultsData, pred, report = testLLAMAScaleOutput(inputs, labels, (1,5), printResultsEveryN=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-ea3d5e1f3716>\u001b[0m in \u001b[0;36mtestLLAMA\u001b[0;34m(inputs, labels, printResultsEveryN)\u001b[0m\n\u001b[1;32m     96\u001b[0m     ).to(model.device)\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     outputs = model.generate(\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1622\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   1623\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2790\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2791\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2792\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2793\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1209\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 )\n\u001b[1;32m   1017\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1019\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "results, resultsData, pred, report = testLLAMA(inputs, labels, printResultsEveryN=10)\n",
        "\n",
        "# results, resultsData, pred, report = testLLAMAScaleOutput(inputs, labels, (1,5), printResultsEveryN=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in resultsData[\"other\"]:\n",
        "  print(\"input\", i['input'])\n",
        "  print(\"output\", i['output'])"
      ],
      "metadata": {
        "id": "-xAEb-EHx8tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AwWpdkzfzMUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4ZFvuQXwzQrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posData = results['truePos']\n",
        "negData = results['trueNeg']"
      ],
      "metadata": {
        "id": "UOSW2tJ6zvH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posData, negData"
      ],
      "metadata": {
        "id": "qtiPhyhe0EKt",
        "outputId": "5c287666-5177-45f1-84da-3bb6fdae5fa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(243, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_values = sorted(posData.keys(), key=int)\n",
        "counts1 = [posData[k] for k in response_values]\n",
        "counts2 = [negData[k] for k in response_values]\n",
        "\n",
        "# X-axis positions\n",
        "indices = np.arange(len(response_values))\n",
        "\n",
        "# Plot width\n",
        "width = 0.35\n",
        "\n",
        "# Creating the figure and axes objects\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)  # Two subplots side by side\n",
        "\n",
        "# Plotting for Data 1\n",
        "ax1.bar(indices, counts1, width, color='b', label='Data 1')\n",
        "ax1.set_xlabel('Response Value')\n",
        "ax1.set_ylabel('Counts')\n",
        "ax1.set_title('Distribution of Pos data')\n",
        "ax1.set_xticks(indices)\n",
        "ax1.set_xticklabels(response_values)\n",
        "ax1.legend()\n",
        "\n",
        "# Plotting for Data 2\n",
        "ax2.bar(indices, counts2, width, color='r', label='Data 2')\n",
        "ax2.set_xlabel('Response Value')\n",
        "ax2.set_ylabel('Counts')\n",
        "ax2.set_title('Distribution of Neg data')\n",
        "ax2.set_xticks(indices)\n",
        "ax2.set_xticklabels(response_values)\n",
        "ax2.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()  # Adjusts plot to ensure everything fits without overlap\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "p-w8zxEpxwhv",
        "outputId": "4adf91e4-1016-4a97-c80b-cf668b262a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTOENous0jpv",
        "outputId": "daff7037-d68b-423c-d32a-3c39589f3891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 2, 1, 26, 156, 56, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4h4fzZYxuUB",
        "outputId": "e417f02b-0f72-4e03-93ac-63f34f28e0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 0, 9, 137, 95, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpgFpcZRZHGO"
      },
      "outputs": [],
      "source": [
        "true = [str(i) for i in labels]\n",
        "report = classification_report(y_pred=pred, y_true=true, target_names=[\"Non-Humorous\",\"Humorous\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP0keIzyZUTc",
        "outputId": "04526e50-98f7-4fff-933e-0e59b9a7a84a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are humor classification model, determine whether the target dialogue is humorous. RESTRICTION: ONLY RESPOND 1 (for humorous) OR 0 (for not humorous).<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Target:\n",
            "Mrs Wolowitz says \"She's a lovely girl! Cute as a button!\" to Howard and MrsWolowitz.\n",
            "\n",
            "\n",
            "Rate the target dialogue on a scale of 1 (not humorous) to 5 (humorous).<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(resultsData['falsePos'][0]['input'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c0xTX238bqm",
        "outputId": "828787ac-07e7-40b0-d32d-5ad59dc8b461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-Humorous       0.73      0.08      0.14       250\n",
            "    Humorous       0.51      0.97      0.67       250\n",
            "\n",
            "    accuracy                           0.52       500\n",
            "   macro avg       0.62      0.52      0.40       500\n",
            "weighted avg       0.62      0.52      0.40       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOJHzK6f2J4g"
      },
      "source": [
        "# Some interesting outputs along the way:\n",
        "\n",
        "## user: \"**What do you know about the sitcom the Big Bang Theory?**\"\n",
        "\n",
        "A popular and iconic sitcom! The Big Bang Theory is a American sitcom that originally aired from 2007 to 2019. Created by Chuck Lorre and Bill Prady, the show is a comedy about a group of socially awkward and intellectually brilliant scientists and their neighbor, a waitress and aspiring actress.\n",
        "\n",
        "The show revolves around the lives of five main characters:\n",
        "\n",
        "1. Sheldon Cooper (played by Jim Parsons), a theoretical physicist with Asperger's syndrome and a strict adherence to routine.\n",
        "2. Leonard Hofstadter (played by Johnny Galecki), an experimental physicist and Sheldon's roommate and best friend.\n",
        "3. Howard Wolowitz (played by Simon Helberg), an aerospace engineer and fellow physicist who lives across the hall from Leonard and Sheldon.\n",
        "4. Rajesh \"Raj\" Koothrappali (played by Kunal Nayyar), an astrophysicist who is unable to speak in the presence of women unless he drinks alcohol.\n",
        "5. Penny (played by Kaley Cuoco), a waitress and aspiring actress who lives across the hall from Leonard and Sheldon.\n",
        "\n",
        "Throughout the show's 12 seasons, the characters navigate their personal and professional lives, often finding themselves in humorous and absurd situations. The show explores themes such as friendship, love, and the [cut off]\n",
        "\n",
        "-------------------\n",
        "\n",
        "## Prompt:\n",
        "system: \"You are humor classification model that takes a given line (the target) along with several precending lines (the context), and determines whether the target line was humorous (return '1') or not humorous (return '0'). RESTRICTION: ONLY RESPOND 1 OR 0.\"\n",
        "\n",
        "user: 'Is the following target_moment from the sitcom, the Big Bang Theory, humorous or not humorous? Only respond '1' for humorous or '0' for not humorous:\n",
        "\n",
        "The Scene is still: The Cafeteria\n",
        "Sheldon says \"It's not what it looks like.\" to Leonard.'\n",
        "\n",
        "assistant: 'Can you provide some context to help me with this decision?'\n",
        "\n",
        "user: 'Yes, use the following as context:\n",
        "\n",
        "The Scene is still: The Cafeteria\n",
        "Priya says \"My brother-- he's got a big crush on Bernadette.\" to Leonard.\n",
        "Leonard says \"You're moving back to India?\" to Priya.\n",
        "Leonard says \"What's going on?\" to Raj, Penny, Raj and Howard.\n",
        "Penny says \"It's-It's not what it looks like.\" to Raj, Leonard, Raj and Howard.Sheldon says \"What does it look like?\" to Raj, Leonard, Raj and Howard.\n",
        "\n",
        "\n",
        "## Model's Response:\n",
        "\n",
        "Based on the context, I would classify the target moment as humorous. The phrase \"It's not what it looks like\" is a common idiomatic expression, but in this scene, it's being used in a way that's reminiscent of a soap opera or a melodrama, which adds a layer of humor to the situation. The fact that Sheldon is asking \"What does it look like?\" also implies that he's being obtuse and unaware of the obvious, which is a characteristic that's often played for comedic effect in the show.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7HvXap3Jth5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40c6529b569b4064ad243312635170d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ad992ef2b7f4830bfa1d1d5b9ac92ec",
              "IPY_MODEL_e7154766c98a459b942fedaa09cd83af",
              "IPY_MODEL_6bbfb1ee8cbb4d2cb1fbf4619ecf84f1"
            ],
            "layout": "IPY_MODEL_35a3a40935134e3596ddfd24710273f6"
          }
        },
        "9ad992ef2b7f4830bfa1d1d5b9ac92ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a702feba7a4b5b85d8446179316112",
            "placeholder": "​",
            "style": "IPY_MODEL_e98e4292986b4214b784c034d680d2ba",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e7154766c98a459b942fedaa09cd83af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e88a65ac66344c191d234c996d92fc5",
            "max": 50982,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edc85d1cf2b74039b71675d7d0001dc7",
            "value": 50982
          }
        },
        "6bbfb1ee8cbb4d2cb1fbf4619ecf84f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae8438722d02460882004ccaf1376335",
            "placeholder": "​",
            "style": "IPY_MODEL_3a76cf2d65234cad97d77e2eb70d3d36",
            "value": " 51.0k/51.0k [00:00&lt;00:00, 4.12MB/s]"
          }
        },
        "35a3a40935134e3596ddfd24710273f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a702feba7a4b5b85d8446179316112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98e4292986b4214b784c034d680d2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e88a65ac66344c191d234c996d92fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc85d1cf2b74039b71675d7d0001dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae8438722d02460882004ccaf1376335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a76cf2d65234cad97d77e2eb70d3d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baffbc5110b44767a2d87e036249f286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f48fd91dd1c24a49ab808a11f83988f9",
              "IPY_MODEL_fbec55381edd440cbb47fbb4a5505869",
              "IPY_MODEL_5f52479f86b94636ac45f3d25d0b84a2"
            ],
            "layout": "IPY_MODEL_235761dc54ec463f954e92644b0c56a5"
          }
        },
        "f48fd91dd1c24a49ab808a11f83988f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd3125f4d3ff47f3a2fb0e88ab19898e",
            "placeholder": "​",
            "style": "IPY_MODEL_69abc0b81ccb4d30a06d32900c908a8c",
            "value": "tokenizer.json: 100%"
          }
        },
        "fbec55381edd440cbb47fbb4a5505869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad8d27d3ab64c0994858a353268deae",
            "max": 9085698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c521fb81e4c409bb0140e01991e3491",
            "value": 9085698
          }
        },
        "5f52479f86b94636ac45f3d25d0b84a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed646086e25b42cf9e0fe4d6461f07e4",
            "placeholder": "​",
            "style": "IPY_MODEL_2ba38459f01840b1848dcbe2383fa360",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 12.5MB/s]"
          }
        },
        "235761dc54ec463f954e92644b0c56a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3125f4d3ff47f3a2fb0e88ab19898e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69abc0b81ccb4d30a06d32900c908a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bad8d27d3ab64c0994858a353268deae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c521fb81e4c409bb0140e01991e3491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed646086e25b42cf9e0fe4d6461f07e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba38459f01840b1848dcbe2383fa360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2d2b1eb4d9e419b9e3271f34abc0aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe1e3548368d4fb0b35756e90ee2cab6",
              "IPY_MODEL_46b64f6b8505413ba21cfabfe637cc1c",
              "IPY_MODEL_9dde0f1a9ed147b9adade0346da3a75e"
            ],
            "layout": "IPY_MODEL_ff78d025e45f49d2ba89149c5383827c"
          }
        },
        "fe1e3548368d4fb0b35756e90ee2cab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_128501b50a974214a0231dc816b1360f",
            "placeholder": "​",
            "style": "IPY_MODEL_7d6b0d46a28e4a3cbe45b73009b58b88",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "46b64f6b8505413ba21cfabfe637cc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b55cf9ebe58143ddb72ef0e0a7f3f1f3",
            "max": 73,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_733447d8e6204a149f4569790924bda1",
            "value": 73
          }
        },
        "9dde0f1a9ed147b9adade0346da3a75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef246084f314b569713f0c3180fcd01",
            "placeholder": "​",
            "style": "IPY_MODEL_a8b3f1e9437c49f8a9c0873c443dddfc",
            "value": " 73.0/73.0 [00:00&lt;00:00, 6.58kB/s]"
          }
        },
        "ff78d025e45f49d2ba89149c5383827c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "128501b50a974214a0231dc816b1360f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6b0d46a28e4a3cbe45b73009b58b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b55cf9ebe58143ddb72ef0e0a7f3f1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "733447d8e6204a149f4569790924bda1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cef246084f314b569713f0c3180fcd01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b3f1e9437c49f8a9c0873c443dddfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84bf23f4979f4ac6abce79fbaa647794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20f40da5e5b24d3fa65c7247b5fc1e67",
              "IPY_MODEL_6f32527d186b4a61826efcb46a9314ce",
              "IPY_MODEL_41c5085bc3314189a117856c1b4da3e5"
            ],
            "layout": "IPY_MODEL_bd434b5f5a7b4ac19d9cdd52f7bf3c6a"
          }
        },
        "20f40da5e5b24d3fa65c7247b5fc1e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aad55b14b0d4e98a7cdcad6cb811747",
            "placeholder": "​",
            "style": "IPY_MODEL_3a23c589d6484fc2a749eb9e3f0752e9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6f32527d186b4a61826efcb46a9314ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f2d165333384c14bb4cfbadc00885fc",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3a84624bf174cf7bac18a21d08b440e",
            "value": 4
          }
        },
        "41c5085bc3314189a117856c1b4da3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d4ac3b081624576b459857a498ad2c2",
            "placeholder": "​",
            "style": "IPY_MODEL_60459bc016bd4866a1a7c952f2d09798",
            "value": " 4/4 [05:04&lt;00:00, 65.11s/it]"
          }
        },
        "bd434b5f5a7b4ac19d9cdd52f7bf3c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aad55b14b0d4e98a7cdcad6cb811747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a23c589d6484fc2a749eb9e3f0752e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f2d165333384c14bb4cfbadc00885fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a84624bf174cf7bac18a21d08b440e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d4ac3b081624576b459857a498ad2c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60459bc016bd4866a1a7c952f2d09798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}